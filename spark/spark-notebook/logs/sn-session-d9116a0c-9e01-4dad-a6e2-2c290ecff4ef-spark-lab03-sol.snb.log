2017-07-01 17:50:41,450  INFO [main] (notebook.kernel.pfork.BetterFork$) - Remote process starting
2017-07-01 17:50:42,446  INFO [Remote-akka.actor.default-dispatcher-6] (akka.event.slf4j.Slf4jLogger) - Slf4jLogger started
2017-07-01 17:50:42,552  INFO [Remote-akka.actor.default-dispatcher-6] (Remoting) - Starting remoting
2017-07-01 17:50:42,942  INFO [Remote-akka.actor.default-dispatcher-6] (Remoting) - Remoting started; listening on addresses :[akka.tcp://Remote@127.0.0.1:55897]
2017-07-01 17:50:42,970  INFO [Remote-akka.actor.default-dispatcher-6] (Remoting) - Remoting now listens on addresses: [akka.tcp://Remote@127.0.0.1:55897]
2017-07-01 17:50:44,031  INFO [Remote-akka.actor.default-dispatcher-4] (notebook.client.ReplCalculator) - ReplCalculator preStart
2017-07-01 17:50:44,039  INFO [Remote-akka.actor.default-dispatcher-4] (notebook.client.ReplCalculator) -  INIT SCRIPT: dummy
2017-07-01 17:50:45,579  WARN [Remote-akka.actor.default-dispatcher-6] (org.apache.hadoop.util.NativeCodeLoader) - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-07-01 17:50:45,975  INFO [Remote-akka.actor.default-dispatcher-6] (org.apache.spark.SecurityManager) - Changing view acls to: turmasabado
2017-07-01 17:50:45,987  INFO [Remote-akka.actor.default-dispatcher-6] (org.apache.spark.SecurityManager) - Changing modify acls to: turmasabado
2017-07-01 17:50:45,988  INFO [Remote-akka.actor.default-dispatcher-6] (org.apache.spark.SecurityManager) - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(turmasabado); users with modify permissions: Set(turmasabado)
2017-07-01 17:50:46,595  INFO [Remote-akka.actor.default-dispatcher-6] (org.apache.spark.HttpServer) - Starting HTTP Server
2017-07-01 17:50:46,753  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.Server) - jetty-8.y.z-SNAPSHOT
2017-07-01 17:50:46,797  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.AbstractConnector) - Started SocketConnector@0.0.0.0:33928
2017-07-01 17:50:46,800  INFO [Remote-akka.actor.default-dispatcher-6] (org.apache.spark.util.Utils) - Successfully started service 'HTTP server' on port 33928.
2017-07-01 17:50:58,978  WARN [Remote-akka.actor.default-dispatcher-6] (org.apache.spark.util.Utils) - Your hostname, globalcode-labs resolves to a loopback address: 127.0.1.1; using 192.168.1.114 instead (on interface wlan0)
2017-07-01 17:50:58,981  WARN [Remote-akka.actor.default-dispatcher-6] (org.apache.spark.util.Utils) - Set SPARK_LOCAL_IP if you need to bind to another address
2017-07-01 17:50:59,708  INFO [Remote-akka.actor.default-dispatcher-4] (notebook.client.ReplCalculator) - Init script processed successfully
2017-07-01 17:50:59,709  INFO [Remote-akka.actor.default-dispatcher-4] (notebook.client.ReplCalculator) -  INIT SCRIPT: class server
2017-07-01 17:51:00,091  INFO [Remote-akka.actor.default-dispatcher-4] (notebook.client.ReplCalculator) - Init script processed successfully
2017-07-01 17:51:00,098  INFO [Remote-akka.actor.default-dispatcher-4] (notebook.client.ReplCalculator) -  INIT SCRIPT: deps
2017-07-01 17:51:01,209  INFO [Remote-akka.actor.default-dispatcher-4] (notebook.client.ReplCalculator) - Init script processed successfully
2017-07-01 17:51:01,211  INFO [Remote-akka.actor.default-dispatcher-4] (notebook.client.ReplCalculator) -  INIT SCRIPT: imports
2017-07-01 17:51:01,213  INFO [Remote-akka.actor.default-dispatcher-4] (notebook.client.ReplCalculator) -  INIT SCRIPT: custom conf
2017-07-01 17:51:02,357  INFO [Remote-akka.actor.default-dispatcher-4] (notebook.client.ReplCalculator) - Init script processed successfully
2017-07-01 17:51:02,360  INFO [Remote-akka.actor.default-dispatcher-4] (notebook.client.ReplCalculator) -  INIT SCRIPT: jar:file:/home/turmasabado/spark-notebook/lib/nooostab.spark-notebook-0.6.3-scala-2.11.7-spark-1.6.1-hadoop-2.6.4-with-hive-with-parquet.jar!/scripts/init.sc
2017-07-01 17:51:07,670  INFO [Remote-akka.actor.default-dispatcher-6] (org.apache.spark.SparkContext) - Running Spark version 1.6.1
2017-07-01 17:51:07,757  INFO [Remote-akka.actor.default-dispatcher-6] (org.apache.spark.SecurityManager) - Changing view acls to: turmasabado
2017-07-01 17:51:07,758  INFO [Remote-akka.actor.default-dispatcher-6] (org.apache.spark.SecurityManager) - Changing modify acls to: turmasabado
2017-07-01 17:51:07,759  INFO [Remote-akka.actor.default-dispatcher-6] (org.apache.spark.SecurityManager) - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(turmasabado); users with modify permissions: Set(turmasabado)
2017-07-01 17:51:08,439  INFO [Remote-akka.actor.default-dispatcher-6] (org.apache.spark.util.Utils) - Successfully started service 'sparkDriver' on port 33545.
2017-07-01 17:51:08,532  INFO [sparkDriverActorSystem-akka.actor.default-dispatcher-2] (akka.event.slf4j.Slf4jLogger) - Slf4jLogger started
2017-07-01 17:51:08,540  INFO [sparkDriverActorSystem-akka.actor.default-dispatcher-4] (Remoting) - Starting remoting
2017-07-01 17:51:08,604  INFO [sparkDriverActorSystem-akka.actor.default-dispatcher-4] (Remoting) - Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.1.114:46791]
2017-07-01 17:51:08,604  INFO [Remote-akka.actor.default-dispatcher-6] (org.apache.spark.util.Utils) - Successfully started service 'sparkDriverActorSystem' on port 46791.
2017-07-01 17:51:08,623  INFO [Remote-akka.actor.default-dispatcher-6] (org.apache.spark.SparkEnv) - Registering MapOutputTracker
2017-07-01 17:51:08,801  INFO [Remote-akka.actor.default-dispatcher-6] (org.apache.spark.SparkEnv) - Registering BlockManagerMaster
2017-07-01 17:51:08,850  INFO [Remote-akka.actor.default-dispatcher-6] (org.apache.spark.storage.DiskBlockManager) - Created local directory at /tmp/blockmgr-cb184004-5d5e-4dcb-bf96-d2cb23d108e4
2017-07-01 17:51:08,863  INFO [Remote-akka.actor.default-dispatcher-6] (org.apache.spark.storage.MemoryStore) - MemoryStore started with capacity 116.4 MB
2017-07-01 17:51:08,981  INFO [Remote-akka.actor.default-dispatcher-6] (org.apache.spark.SparkEnv) - Registering OutputCommitCoordinator
2017-07-01 17:51:10,000  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.Server) - jetty-8.y.z-SNAPSHOT
2017-07-01 17:51:10,047  WARN [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.util.component.AbstractLifeCycle) - FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Endereço já em uso
java.net.BindException: Endereço já em uso
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:252)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1988)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:166)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1979)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:262)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:481)
	at $line7.$read$$iw$$iw$$anon$1.reset(<console>:147)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at $line7.$read$$iw$$iw.<init>(<console>:158)
	at $line7.$read$$iw.<init>(<console>:185)
	at $line7.$read.<init>(<console>:187)
	at $line7.$read$.<init>(<console>:191)
	at $line7.$read$.<clinit>(<console>)
	at $line7.$eval$.$print$lzycompute(<console>:7)
	at $line7.$eval$.$print(<console>:6)
	at $line7.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at scala.tools.nsc.interpreter.IMain$ReadEvalPrint.call(IMain.scala:784)
	at scala.tools.nsc.interpreter.IMain$Request.loadAndRun(IMain.scala:1039)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:636)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:635)
	at scala.reflect.internal.util.ScalaClassLoader$class.asContext(ScalaClassLoader.scala:31)
	at scala.reflect.internal.util.AbstractFileClassLoader.asContext(AbstractFileClassLoader.scala:19)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest.loadAndRunReq(IMain.scala:635)
	at scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:567)
	at scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:563)
	at notebook.kernel.Repl$$anonfun$7.apply(Repl.scala:207)
	at notebook.kernel.Repl$$anonfun$7.apply(Repl.scala:207)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at scala.Console$.withOut(Console.scala:65)
	at notebook.kernel.Repl.evaluate(Repl.scala:206)
	at notebook.client.ReplCalculator.notebook$client$ReplCalculator$$eval$1(ReplCalculator.scala:463)
	at notebook.client.ReplCalculator$$anonfun$preStartLogic$2.apply(ReplCalculator.scala:477)
	at notebook.client.ReplCalculator$$anonfun$preStartLogic$2.apply(ReplCalculator.scala:475)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:778)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:777)
	at notebook.client.ReplCalculator.preStartLogic(ReplCalculator.scala:475)
	at notebook.client.ReplCalculator.preStart(ReplCalculator.scala:482)
	at akka.actor.Actor$class.aroundPreStart(Actor.scala:472)
	at notebook.client.ReplCalculator.aroundPreStart(ReplCalculator.scala:27)
	at akka.actor.ActorCell.create(ActorCell.scala:580)
	at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:456)
	at akka.actor.ActorCell.systemInvoke(ActorCell.scala:478)
	at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:263)
	at akka.dispatch.Mailbox.run(Mailbox.scala:219)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2017-07-01 17:51:10,059  WARN [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.util.component.AbstractLifeCycle) - FAILED org.spark-project.jetty.server.Server@fa103: java.net.BindException: Endereço já em uso
java.net.BindException: Endereço já em uso
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:252)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1988)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:166)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1979)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:262)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:481)
	at $line7.$read$$iw$$iw$$anon$1.reset(<console>:147)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at $line7.$read$$iw$$iw.<init>(<console>:158)
	at $line7.$read$$iw.<init>(<console>:185)
	at $line7.$read.<init>(<console>:187)
	at $line7.$read$.<init>(<console>:191)
	at $line7.$read$.<clinit>(<console>)
	at $line7.$eval$.$print$lzycompute(<console>:7)
	at $line7.$eval$.$print(<console>:6)
	at $line7.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at scala.tools.nsc.interpreter.IMain$ReadEvalPrint.call(IMain.scala:784)
	at scala.tools.nsc.interpreter.IMain$Request.loadAndRun(IMain.scala:1039)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:636)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:635)
	at scala.reflect.internal.util.ScalaClassLoader$class.asContext(ScalaClassLoader.scala:31)
	at scala.reflect.internal.util.AbstractFileClassLoader.asContext(AbstractFileClassLoader.scala:19)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest.loadAndRunReq(IMain.scala:635)
	at scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:567)
	at scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:563)
	at notebook.kernel.Repl$$anonfun$7.apply(Repl.scala:207)
	at notebook.kernel.Repl$$anonfun$7.apply(Repl.scala:207)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at scala.Console$.withOut(Console.scala:65)
	at notebook.kernel.Repl.evaluate(Repl.scala:206)
	at notebook.client.ReplCalculator.notebook$client$ReplCalculator$$eval$1(ReplCalculator.scala:463)
	at notebook.client.ReplCalculator$$anonfun$preStartLogic$2.apply(ReplCalculator.scala:477)
	at notebook.client.ReplCalculator$$anonfun$preStartLogic$2.apply(ReplCalculator.scala:475)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:778)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:777)
	at notebook.client.ReplCalculator.preStartLogic(ReplCalculator.scala:475)
	at notebook.client.ReplCalculator.preStart(ReplCalculator.scala:482)
	at akka.actor.Actor$class.aroundPreStart(Actor.scala:472)
	at notebook.client.ReplCalculator.aroundPreStart(ReplCalculator.scala:27)
	at akka.actor.ActorCell.create(ActorCell.scala:580)
	at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:456)
	at akka.actor.ActorCell.systemInvoke(ActorCell.scala:478)
	at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:263)
	at akka.dispatch.Mailbox.run(Mailbox.scala:219)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2017-07-01 17:51:10,073  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2017-07-01 17:51:10,074  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/api,null}
2017-07-01 17:51:10,077  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/,null}
2017-07-01 17:51:10,077  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/static,null}
2017-07-01 17:51:10,078  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2017-07-01 17:51:10,078  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2017-07-01 17:51:10,078  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2017-07-01 17:51:10,078  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/executors,null}
2017-07-01 17:51:10,078  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2017-07-01 17:51:10,078  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/environment,null}
2017-07-01 17:51:10,079  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2017-07-01 17:51:10,079  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2017-07-01 17:51:10,079  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2017-07-01 17:51:10,079  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/storage,null}
2017-07-01 17:51:10,079  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2017-07-01 17:51:10,079  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2017-07-01 17:51:10,080  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2017-07-01 17:51:10,080  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2017-07-01 17:51:10,080  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2017-07-01 17:51:10,080  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages,null}
2017-07-01 17:51:10,080  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2017-07-01 17:51:10,080  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2017-07-01 17:51:10,080  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2017-07-01 17:51:10,081  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2017-07-01 17:51:10,181  WARN [Remote-akka.actor.default-dispatcher-6] (org.apache.spark.util.Utils) - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2017-07-01 17:51:10,193  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.Server) - jetty-8.y.z-SNAPSHOT
2017-07-01 17:51:10,235  WARN [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.util.component.AbstractLifeCycle) - FAILED SelectChannelConnector@0.0.0.0:4041: java.net.BindException: Endereço já em uso
java.net.BindException: Endereço já em uso
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:252)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1988)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:166)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1979)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:262)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:481)
	at $line7.$read$$iw$$iw$$anon$1.reset(<console>:147)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at $line7.$read$$iw$$iw.<init>(<console>:158)
	at $line7.$read$$iw.<init>(<console>:185)
	at $line7.$read.<init>(<console>:187)
	at $line7.$read$.<init>(<console>:191)
	at $line7.$read$.<clinit>(<console>)
	at $line7.$eval$.$print$lzycompute(<console>:7)
	at $line7.$eval$.$print(<console>:6)
	at $line7.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at scala.tools.nsc.interpreter.IMain$ReadEvalPrint.call(IMain.scala:784)
	at scala.tools.nsc.interpreter.IMain$Request.loadAndRun(IMain.scala:1039)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:636)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:635)
	at scala.reflect.internal.util.ScalaClassLoader$class.asContext(ScalaClassLoader.scala:31)
	at scala.reflect.internal.util.AbstractFileClassLoader.asContext(AbstractFileClassLoader.scala:19)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest.loadAndRunReq(IMain.scala:635)
	at scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:567)
	at scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:563)
	at notebook.kernel.Repl$$anonfun$7.apply(Repl.scala:207)
	at notebook.kernel.Repl$$anonfun$7.apply(Repl.scala:207)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at scala.Console$.withOut(Console.scala:65)
	at notebook.kernel.Repl.evaluate(Repl.scala:206)
	at notebook.client.ReplCalculator.notebook$client$ReplCalculator$$eval$1(ReplCalculator.scala:463)
	at notebook.client.ReplCalculator$$anonfun$preStartLogic$2.apply(ReplCalculator.scala:477)
	at notebook.client.ReplCalculator$$anonfun$preStartLogic$2.apply(ReplCalculator.scala:475)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:778)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:777)
	at notebook.client.ReplCalculator.preStartLogic(ReplCalculator.scala:475)
	at notebook.client.ReplCalculator.preStart(ReplCalculator.scala:482)
	at akka.actor.Actor$class.aroundPreStart(Actor.scala:472)
	at notebook.client.ReplCalculator.aroundPreStart(ReplCalculator.scala:27)
	at akka.actor.ActorCell.create(ActorCell.scala:580)
	at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:456)
	at akka.actor.ActorCell.systemInvoke(ActorCell.scala:478)
	at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:263)
	at akka.dispatch.Mailbox.run(Mailbox.scala:219)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2017-07-01 17:51:10,258  WARN [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.util.component.AbstractLifeCycle) - FAILED org.spark-project.jetty.server.Server@458ee2: java.net.BindException: Endereço já em uso
java.net.BindException: Endereço já em uso
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:252)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1988)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:166)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1979)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:262)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:481)
	at $line7.$read$$iw$$iw$$anon$1.reset(<console>:147)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at $line7.$read$$iw$$iw.<init>(<console>:158)
	at $line7.$read$$iw.<init>(<console>:185)
	at $line7.$read.<init>(<console>:187)
	at $line7.$read$.<init>(<console>:191)
	at $line7.$read$.<clinit>(<console>)
	at $line7.$eval$.$print$lzycompute(<console>:7)
	at $line7.$eval$.$print(<console>:6)
	at $line7.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at scala.tools.nsc.interpreter.IMain$ReadEvalPrint.call(IMain.scala:784)
	at scala.tools.nsc.interpreter.IMain$Request.loadAndRun(IMain.scala:1039)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:636)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:635)
	at scala.reflect.internal.util.ScalaClassLoader$class.asContext(ScalaClassLoader.scala:31)
	at scala.reflect.internal.util.AbstractFileClassLoader.asContext(AbstractFileClassLoader.scala:19)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest.loadAndRunReq(IMain.scala:635)
	at scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:567)
	at scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:563)
	at notebook.kernel.Repl$$anonfun$7.apply(Repl.scala:207)
	at notebook.kernel.Repl$$anonfun$7.apply(Repl.scala:207)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at scala.Console$.withOut(Console.scala:65)
	at notebook.kernel.Repl.evaluate(Repl.scala:206)
	at notebook.client.ReplCalculator.notebook$client$ReplCalculator$$eval$1(ReplCalculator.scala:463)
	at notebook.client.ReplCalculator$$anonfun$preStartLogic$2.apply(ReplCalculator.scala:477)
	at notebook.client.ReplCalculator$$anonfun$preStartLogic$2.apply(ReplCalculator.scala:475)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:778)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:777)
	at notebook.client.ReplCalculator.preStartLogic(ReplCalculator.scala:475)
	at notebook.client.ReplCalculator.preStart(ReplCalculator.scala:482)
	at akka.actor.Actor$class.aroundPreStart(Actor.scala:472)
	at notebook.client.ReplCalculator.aroundPreStart(ReplCalculator.scala:27)
	at akka.actor.ActorCell.create(ActorCell.scala:580)
	at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:456)
	at akka.actor.ActorCell.systemInvoke(ActorCell.scala:478)
	at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:263)
	at akka.dispatch.Mailbox.run(Mailbox.scala:219)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2017-07-01 17:51:10,264  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2017-07-01 17:51:10,264  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/api,null}
2017-07-01 17:51:10,264  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/,null}
2017-07-01 17:51:10,264  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/static,null}
2017-07-01 17:51:10,277  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2017-07-01 17:51:10,278  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2017-07-01 17:51:10,278  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2017-07-01 17:51:10,278  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/executors,null}
2017-07-01 17:51:10,283  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2017-07-01 17:51:10,287  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/environment,null}
2017-07-01 17:51:10,287  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2017-07-01 17:51:10,288  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2017-07-01 17:51:10,288  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2017-07-01 17:51:10,288  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/storage,null}
2017-07-01 17:51:10,288  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2017-07-01 17:51:10,288  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2017-07-01 17:51:10,288  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2017-07-01 17:51:10,288  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2017-07-01 17:51:10,288  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2017-07-01 17:51:10,289  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages,null}
2017-07-01 17:51:10,289  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2017-07-01 17:51:10,289  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2017-07-01 17:51:10,289  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2017-07-01 17:51:10,305  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2017-07-01 17:51:10,359  WARN [Remote-akka.actor.default-dispatcher-6] (org.apache.spark.util.Utils) - Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
2017-07-01 17:51:10,365  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.Server) - jetty-8.y.z-SNAPSHOT
2017-07-01 17:51:10,393  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.AbstractConnector) - Started SelectChannelConnector@0.0.0.0:4042
2017-07-01 17:51:10,393  INFO [Remote-akka.actor.default-dispatcher-6] (org.apache.spark.util.Utils) - Successfully started service 'SparkUI' on port 4042.
2017-07-01 17:51:10,410  INFO [Remote-akka.actor.default-dispatcher-6] (org.apache.spark.ui.SparkUI) - Started SparkUI at http://192.168.1.114:4042
2017-07-01 17:51:10,506  INFO [Remote-akka.actor.default-dispatcher-6] (org.apache.spark.HttpFileServer) - HTTP File server directory is /tmp/spark-f6c047ca-ab83-47c8-b3ad-d994b0d5c50e/httpd-4700cb92-1b0c-4820-8297-f509d557a827
2017-07-01 17:51:10,506  INFO [Remote-akka.actor.default-dispatcher-6] (org.apache.spark.HttpServer) - Starting HTTP Server
2017-07-01 17:51:10,508  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.Server) - jetty-8.y.z-SNAPSHOT
2017-07-01 17:51:10,511  INFO [Remote-akka.actor.default-dispatcher-6] (org.spark-project.jetty.server.AbstractConnector) - Started SocketConnector@0.0.0.0:54021
2017-07-01 17:51:10,516  INFO [Remote-akka.actor.default-dispatcher-6] (org.apache.spark.util.Utils) - Successfully started service 'HTTP file server' on port 54021.
2017-07-01 17:51:10,534 ERROR [Remote-akka.actor.default-dispatcher-6] (org.apache.spark.SparkContext) - Error adding jar (java.lang.IllegalArgumentException: /home/turmasabado/spark-notebook cannot be a directory.), was the --addJars option used?
2017-07-01 17:51:10,649  INFO [Remote-akka.actor.default-dispatcher-6] (org.apache.spark.SparkContext) - Added JAR file:/home/turmasabado/spark-notebook/lib/common.common-0.6.3-scala-2.11.7-spark-1.6.1-hadoop-2.6.4-with-hive-with-parquet.jar at http://192.168.1.114:54021/jars/common.common-0.6.3-scala-2.11.7-spark-1.6.1-hadoop-2.6.4-with-hive-with-parquet.jar with timestamp 1498942270648
2017-07-01 17:51:11,045  INFO [Remote-akka.actor.default-dispatcher-6] (org.apache.spark.executor.Executor) - Starting executor ID driver on host localhost
2017-07-01 17:51:11,077  INFO [Remote-akka.actor.default-dispatcher-6] (org.apache.spark.executor.Executor) - Using REPL class URI: http://192.168.1.114:33928
2017-07-01 17:51:11,186  INFO [Remote-akka.actor.default-dispatcher-6] (org.apache.spark.util.Utils) - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56220.
2017-07-01 17:51:11,189  INFO [Remote-akka.actor.default-dispatcher-6] (org.apache.spark.network.netty.NettyBlockTransferService) - Server created on 56220
2017-07-01 17:51:11,200  INFO [Remote-akka.actor.default-dispatcher-6] (org.apache.spark.storage.BlockManagerMaster) - Trying to register BlockManager
2017-07-01 17:51:11,209  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerMasterEndpoint) - Registering block manager localhost:56220 with 116.4 MB RAM, BlockManagerId(driver, localhost, 56220)
2017-07-01 17:51:11,215  INFO [Remote-akka.actor.default-dispatcher-6] (org.apache.spark.storage.BlockManagerMaster) - Registered BlockManager
2017-07-01 17:51:15,707  INFO [Remote-akka.actor.default-dispatcher-4] (notebook.client.ReplCalculator) - Init script processed successfully
2017-07-01 18:19:17,441  INFO [Remote-akka.actor.default-dispatcher-16] (org.apache.spark.sql.execution.datasources.json.JSONRelation) - Listing file:/home/turmasabado/spark-notebook/produtos.json on driver
2017-07-01 18:19:19,146  WARN [Remote-akka.actor.default-dispatcher-16] (org.apache.spark.util.SizeEstimator) - Failed to check whether UseCompressedOops is set; assuming yes
2017-07-01 18:19:19,420  INFO [Remote-akka.actor.default-dispatcher-16] (org.apache.spark.storage.MemoryStore) - Block broadcast_0 stored as values in memory (estimated size 188.0 KB, free 188.0 KB)
2017-07-01 18:19:19,652  INFO [Remote-akka.actor.default-dispatcher-16] (org.apache.spark.storage.MemoryStore) - Block broadcast_0_piece0 stored as bytes in memory (estimated size 19.6 KB, free 207.6 KB)
2017-07-01 18:19:19,660  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_0_piece0 in memory on localhost:56220 (size: 19.6 KB, free: 116.4 MB)
2017-07-01 18:19:19,711  INFO [Remote-akka.actor.default-dispatcher-16] (org.apache.spark.SparkContext) - Created broadcast 0 from json at <console>:58
2017-07-01 18:19:20,350  INFO [Remote-akka.actor.default-dispatcher-16] (org.apache.hadoop.mapred.FileInputFormat) - Total input paths to process : 1
2017-07-01 18:19:20,639  INFO [Remote-akka.actor.default-dispatcher-16] (org.apache.spark.SparkContext) - Starting job: json at <console>:58
2017-07-01 18:19:20,742  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 0 (json at <console>:58) with 2 output partitions
2017-07-01 18:19:20,744  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 0 (json at <console>:58)
2017-07-01 18:19:20,747  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2017-07-01 18:19:20,764  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2017-07-01 18:19:20,793  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 0 (MapPartitionsRDD[3] at json at <console>:58), which has no missing parents
2017-07-01 18:19:20,897  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_1 stored as values in memory (estimated size 4.2 KB, free 211.9 KB)
2017-07-01 18:19:20,908  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.4 KB, free 214.3 KB)
2017-07-01 18:19:20,910  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_1_piece0 in memory on localhost:56220 (size: 2.4 KB, free: 116.4 MB)
2017-07-01 18:19:20,918  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2017-07-01 18:19:20,947  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at json at <console>:58)
2017-07-01 18:19:20,953  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 0.0 with 2 tasks
2017-07-01 18:19:21,272  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2198 bytes)
2017-07-01 18:19:21,277  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2198 bytes)
2017-07-01 18:19:21,342  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 0.0 (TID 0)
2017-07-01 18:19:21,342  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 0.0 (TID 1)
2017-07-01 18:19:21,368  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Fetching http://192.168.1.114:54021/jars/common.common-0.6.3-scala-2.11.7-spark-1.6.1-hadoop-2.6.4-with-hive-with-parquet.jar with timestamp 1498942270648
2017-07-01 18:19:22,114  INFO [Executor task launch worker-1] (org.apache.spark.util.Utils) - Fetching http://192.168.1.114:54021/jars/common.common-0.6.3-scala-2.11.7-spark-1.6.1-hadoop-2.6.4-with-hive-with-parquet.jar to /tmp/spark-f6c047ca-ab83-47c8-b3ad-d994b0d5c50e/userFiles-649ce264-d99f-44db-abe8-e4298a7407db/fetchFileTemp1218523464278103703.tmp
2017-07-01 18:19:22,397  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Adding file:/tmp/spark-f6c047ca-ab83-47c8-b3ad-d994b0d5c50e/userFiles-649ce264-d99f-44db-abe8-e4298a7407db/common.common-0.6.3-scala-2.11.7-spark-1.6.1-hadoop-2.6.4-with-hive-with-parquet.jar to class loader
2017-07-01 18:19:22,511  INFO [Executor task launch worker-1] (org.apache.spark.rdd.HadoopRDD) - Input split: file:/home/turmasabado/spark-notebook/produtos.json:500+501
2017-07-01 18:19:22,511  INFO [Executor task launch worker-0] (org.apache.spark.rdd.HadoopRDD) - Input split: file:/home/turmasabado/spark-notebook/produtos.json:0+500
2017-07-01 18:19:22,653  INFO [Executor task launch worker-0] (org.apache.hadoop.conf.Configuration.deprecation) - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2017-07-01 18:19:22,654  INFO [Executor task launch worker-0] (org.apache.hadoop.conf.Configuration.deprecation) - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2017-07-01 18:19:22,654  INFO [Executor task launch worker-0] (org.apache.hadoop.conf.Configuration.deprecation) - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2017-07-01 18:19:22,655  INFO [Executor task launch worker-0] (org.apache.hadoop.conf.Configuration.deprecation) - mapred.job.id is deprecated. Instead, use mapreduce.job.id
2017-07-01 18:19:22,654  INFO [Executor task launch worker-1] (org.apache.hadoop.conf.Configuration.deprecation) - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2017-07-01 18:19:22,839  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 0.0 (TID 1). 2389 bytes result sent to driver
2017-07-01 18:19:22,921  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 0.0 (TID 1) in 1595 ms on localhost (1/2)
2017-07-01 18:19:22,928  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 0.0 (TID 0). 3293 bytes result sent to driver
2017-07-01 18:19:22,940  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 0 (json at <console>:58) finished in 1,952 s
2017-07-01 18:19:22,942  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 0.0 (TID 0) in 1854 ms on localhost (2/2)
2017-07-01 18:19:22,956  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2017-07-01 18:19:22,961  INFO [Remote-akka.actor.default-dispatcher-16] (org.apache.spark.scheduler.DAGScheduler) - Job 0 finished: json at <console>:58, took 2,322053 s
2017-07-01 18:19:24,874  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_1_piece0 on localhost:56220 in memory (size: 2.4 KB, free: 116.4 MB)
2017-07-01 18:19:24,902  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 1
2017-07-01 18:19:24,904  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_0_piece0 on localhost:56220 in memory (size: 19.6 KB, free: 116.4 MB)
2017-07-01 18:19:29,388  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.storage.MemoryStore) - Block broadcast_2 stored as values in memory (estimated size 56.5 KB, free 56.5 KB)
2017-07-01 18:19:29,494  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.storage.MemoryStore) - Block broadcast_2_piece0 stored as bytes in memory (estimated size 19.5 KB, free 76.0 KB)
2017-07-01 18:19:29,496  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_2_piece0 in memory on localhost:56220 (size: 19.5 KB, free: 116.4 MB)
2017-07-01 18:19:29,498  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.SparkContext) - Created broadcast 2 from show at <console>:62
2017-07-01 18:19:29,606  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.storage.MemoryStore) - Block broadcast_3 stored as values in memory (estimated size 188.0 KB, free 264.0 KB)
2017-07-01 18:19:29,633  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.storage.MemoryStore) - Block broadcast_3_piece0 stored as bytes in memory (estimated size 19.6 KB, free 283.7 KB)
2017-07-01 18:19:29,637  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_3_piece0 in memory on localhost:56220 (size: 19.6 KB, free: 116.4 MB)
2017-07-01 18:19:29,647  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.SparkContext) - Created broadcast 3 from show at <console>:62
2017-07-01 18:19:29,986  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.hadoop.mapred.FileInputFormat) - Total input paths to process : 1
2017-07-01 18:19:30,015  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.SparkContext) - Starting job: show at <console>:62
2017-07-01 18:19:30,019  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 1 (show at <console>:62) with 1 output partitions
2017-07-01 18:19:30,019  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 1 (show at <console>:62)
2017-07-01 18:19:30,019  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2017-07-01 18:19:30,019  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2017-07-01 18:19:30,019  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 1 (MapPartitionsRDD[9] at show at <console>:62), which has no missing parents
2017-07-01 18:19:30,030  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 290.0 KB)
2017-07-01 18:19:30,036  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.6 KB, free 293.6 KB)
2017-07-01 18:19:30,042  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_4_piece0 in memory on localhost:56220 (size: 3.6 KB, free: 116.4 MB)
2017-07-01 18:19:30,045  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 4 from broadcast at DAGScheduler.scala:1006
2017-07-01 18:19:30,045  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at show at <console>:62)
2017-07-01 18:19:30,045  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 1.0 with 1 tasks
2017-07-01 18:19:30,047  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 1.0 (TID 2, localhost, partition 0,PROCESS_LOCAL, 2198 bytes)
2017-07-01 18:19:30,047  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 1.0 (TID 2)
2017-07-01 18:19:30,053  INFO [Executor task launch worker-0] (org.apache.spark.rdd.HadoopRDD) - Input split: file:/home/turmasabado/spark-notebook/produtos.json:0+500
2017-07-01 18:19:31,084  INFO [Executor task launch worker-0] (org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection) - Code generated in 807.168473 ms
2017-07-01 18:19:31,176  INFO [Executor task launch worker-0] (org.apache.spark.sql.catalyst.expressions.codegen.GenerateSafeProjection) - Code generated in 36.285143 ms
2017-07-01 18:19:31,215  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 1.0 (TID 2). 3560 bytes result sent to driver
2017-07-01 18:19:31,224  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 1 (show at <console>:62) finished in 1,178 s
2017-07-01 18:19:31,226  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.scheduler.DAGScheduler) - Job 1 finished: show at <console>:62, took 1,208639 s
2017-07-01 18:19:31,230  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 1.0 (TID 2) in 1178 ms on localhost (1/1)
2017-07-01 18:19:31,230  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2017-07-01 18:19:31,239  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.SparkContext) - Starting job: show at <console>:62
2017-07-01 18:19:31,242  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 2 (show at <console>:62) with 1 output partitions
2017-07-01 18:19:31,242  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 2 (show at <console>:62)
2017-07-01 18:19:31,242  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2017-07-01 18:19:31,242  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2017-07-01 18:19:31,242  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 2 (MapPartitionsRDD[9] at show at <console>:62), which has no missing parents
2017-07-01 18:19:31,244  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_5 stored as values in memory (estimated size 6.4 KB, free 300.0 KB)
2017-07-01 18:19:31,252  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.6 KB, free 303.5 KB)
2017-07-01 18:19:31,253  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_5_piece0 in memory on localhost:56220 (size: 3.6 KB, free: 116.4 MB)
2017-07-01 18:19:31,254  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 5 from broadcast at DAGScheduler.scala:1006
2017-07-01 18:19:31,254  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[9] at show at <console>:62)
2017-07-01 18:19:31,254  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 2.0 with 1 tasks
2017-07-01 18:19:31,256  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 2.0 (TID 3, localhost, partition 1,PROCESS_LOCAL, 2198 bytes)
2017-07-01 18:19:31,256  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 2.0 (TID 3)
2017-07-01 18:19:31,260  INFO [Executor task launch worker-0] (org.apache.spark.rdd.HadoopRDD) - Input split: file:/home/turmasabado/spark-notebook/produtos.json:500+501
2017-07-01 18:19:31,268  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 2.0 (TID 3). 2069 bytes result sent to driver
2017-07-01 18:19:31,271  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 2 (show at <console>:62) finished in 0,016 s
2017-07-01 18:19:31,272  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.scheduler.DAGScheduler) - Job 2 finished: show at <console>:62, took 0,032297 s
2017-07-01 18:19:31,275  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 2.0 (TID 3) in 16 ms on localhost (1/1)
2017-07-01 18:19:31,276  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2017-07-01 18:19:31,423  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_2_piece0 on localhost:56220 in memory (size: 19.5 KB, free: 116.4 MB)
2017-07-01 18:19:31,424  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_5_piece0 on localhost:56220 in memory (size: 3.6 KB, free: 116.4 MB)
2017-07-01 18:19:31,425  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 3
2017-07-01 18:19:31,426  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_4_piece0 on localhost:56220 in memory (size: 3.6 KB, free: 116.4 MB)
2017-07-01 18:19:31,427  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 2
2017-07-01 18:19:31,436  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_3_piece0 on localhost:56220 in memory (size: 19.6 KB, free: 116.4 MB)
2017-07-01 18:19:35,417  INFO [Remote-akka.actor.default-dispatcher-16] (org.apache.spark.storage.MemoryStore) - Block broadcast_6 stored as values in memory (estimated size 187.4 KB, free 187.4 KB)
2017-07-01 18:19:35,445  INFO [Remote-akka.actor.default-dispatcher-16] (org.apache.spark.storage.MemoryStore) - Block broadcast_6_piece0 stored as bytes in memory (estimated size 19.5 KB, free 206.9 KB)
2017-07-01 18:19:35,447  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_6_piece0 in memory on localhost:56220 (size: 19.5 KB, free: 116.4 MB)
2017-07-01 18:19:35,451  INFO [Remote-akka.actor.default-dispatcher-16] (org.apache.spark.SparkContext) - Created broadcast 6 from show at <console>:61
2017-07-01 18:19:35,486  INFO [Remote-akka.actor.default-dispatcher-16] (org.apache.spark.storage.MemoryStore) - Block broadcast_7 stored as values in memory (estimated size 188.0 KB, free 394.9 KB)
2017-07-01 18:19:35,512  INFO [Remote-akka.actor.default-dispatcher-16] (org.apache.spark.storage.MemoryStore) - Block broadcast_7_piece0 stored as bytes in memory (estimated size 19.6 KB, free 414.5 KB)
2017-07-01 18:19:35,513  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_7_piece0 in memory on localhost:56220 (size: 19.6 KB, free: 116.4 MB)
2017-07-01 18:19:35,517  INFO [Remote-akka.actor.default-dispatcher-16] (org.apache.spark.SparkContext) - Created broadcast 7 from show at <console>:61
2017-07-01 18:19:35,613  INFO [Remote-akka.actor.default-dispatcher-16] (org.apache.hadoop.mapred.FileInputFormat) - Total input paths to process : 1
2017-07-01 18:19:35,622  INFO [Remote-akka.actor.default-dispatcher-16] (org.apache.spark.SparkContext) - Starting job: show at <console>:61
2017-07-01 18:19:35,625  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 3 (show at <console>:61) with 1 output partitions
2017-07-01 18:19:35,625  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 3 (show at <console>:61)
2017-07-01 18:19:35,625  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2017-07-01 18:19:35,627  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2017-07-01 18:19:35,627  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 3 (MapPartitionsRDD[16] at show at <console>:61), which has no missing parents
2017-07-01 18:19:35,640  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_8 stored as values in memory (estimated size 8.5 KB, free 423.1 KB)
2017-07-01 18:19:35,645  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_8_piece0 stored as bytes in memory (estimated size 4.5 KB, free 427.5 KB)
2017-07-01 18:19:35,646  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_8_piece0 in memory on localhost:56220 (size: 4.5 KB, free: 116.4 MB)
2017-07-01 18:19:35,650  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 8 from broadcast at DAGScheduler.scala:1006
2017-07-01 18:19:35,650  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[16] at show at <console>:61)
2017-07-01 18:19:35,650  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 3.0 with 1 tasks
2017-07-01 18:19:35,655  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 3.0 (TID 4, localhost, partition 0,PROCESS_LOCAL, 2198 bytes)
2017-07-01 18:19:35,655  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 3.0 (TID 4)
2017-07-01 18:19:35,662  INFO [Executor task launch worker-0] (org.apache.spark.rdd.HadoopRDD) - Input split: file:/home/turmasabado/spark-notebook/produtos.json:0+500
2017-07-01 18:19:35,805  INFO [Executor task launch worker-0] (org.apache.spark.sql.catalyst.expressions.codegen.GeneratePredicate) - Code generated in 122.867031 ms
2017-07-01 18:19:35,829  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 3.0 (TID 4). 3221 bytes result sent to driver
2017-07-01 18:19:35,978  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 3.0 (TID 4) in 324 ms on localhost (1/1)
2017-07-01 18:19:35,978  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2017-07-01 18:19:35,980  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 3 (show at <console>:61) finished in 0,326 s
2017-07-01 18:19:35,980  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_6_piece0 on localhost:56220 in memory (size: 19.5 KB, free: 116.4 MB)
2017-07-01 18:19:35,982  INFO [Remote-akka.actor.default-dispatcher-16] (org.apache.spark.scheduler.DAGScheduler) - Job 3 finished: show at <console>:61, took 0,359214 s
2017-07-01 18:19:35,991  INFO [Remote-akka.actor.default-dispatcher-16] (org.apache.spark.SparkContext) - Starting job: show at <console>:61
2017-07-01 18:19:35,993  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 4 (show at <console>:61) with 1 output partitions
2017-07-01 18:19:35,994  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 4 (show at <console>:61)
2017-07-01 18:19:35,994  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2017-07-01 18:19:35,994  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2017-07-01 18:19:35,995  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 4 (MapPartitionsRDD[16] at show at <console>:61), which has no missing parents
2017-07-01 18:19:36,000  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_9 stored as values in memory (estimated size 8.5 KB, free 229.2 KB)
2017-07-01 18:19:36,004  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_9_piece0 stored as bytes in memory (estimated size 4.5 KB, free 233.6 KB)
2017-07-01 18:19:36,006  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_9_piece0 in memory on localhost:56220 (size: 4.5 KB, free: 116.4 MB)
2017-07-01 18:19:36,007  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 9 from broadcast at DAGScheduler.scala:1006
2017-07-01 18:19:36,008  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[16] at show at <console>:61)
2017-07-01 18:19:36,018  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 4.0 with 1 tasks
2017-07-01 18:19:36,021  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 4.0 (TID 5, localhost, partition 1,PROCESS_LOCAL, 2198 bytes)
2017-07-01 18:19:36,022  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 4.0 (TID 5)
2017-07-01 18:19:36,028  INFO [Executor task launch worker-0] (org.apache.spark.rdd.HadoopRDD) - Input split: file:/home/turmasabado/spark-notebook/produtos.json:500+501
2017-07-01 18:19:36,047  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 4.0 (TID 5). 2283 bytes result sent to driver
2017-07-01 18:19:36,049  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 4.0 (TID 5) in 28 ms on localhost (1/1)
2017-07-01 18:19:36,050  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2017-07-01 18:19:36,050  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 4 (show at <console>:61) finished in 0,020 s
2017-07-01 18:19:36,051  INFO [Remote-akka.actor.default-dispatcher-16] (org.apache.spark.scheduler.DAGScheduler) - Job 4 finished: show at <console>:61, took 0,058505 s
2017-07-01 18:19:37,499  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_9_piece0 on localhost:56220 in memory (size: 4.5 KB, free: 116.4 MB)
2017-07-01 18:19:37,501  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 8
2017-07-01 18:19:37,506  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_8_piece0 on localhost:56220 in memory (size: 4.5 KB, free: 116.4 MB)
2017-07-01 18:19:37,508  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 7
2017-07-01 18:19:37,508  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 6
2017-07-01 18:19:37,508  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 5
2017-07-01 18:19:37,509  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_7_piece0 on localhost:56220 in memory (size: 19.6 KB, free: 116.4 MB)
2017-07-01 18:19:37,949  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.storage.MemoryStore) - Block broadcast_10 stored as values in memory (estimated size 187.4 KB, free 187.4 KB)
2017-07-01 18:19:37,977  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.storage.MemoryStore) - Block broadcast_10_piece0 stored as bytes in memory (estimated size 19.5 KB, free 206.9 KB)
2017-07-01 18:19:37,980  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_10_piece0 in memory on localhost:56220 (size: 19.5 KB, free: 116.4 MB)
2017-07-01 18:19:37,983  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.SparkContext) - Created broadcast 10 from show at <console>:61
2017-07-01 18:19:38,002  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.storage.MemoryStore) - Block broadcast_11 stored as values in memory (estimated size 188.0 KB, free 394.9 KB)
2017-07-01 18:19:38,029  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.storage.MemoryStore) - Block broadcast_11_piece0 stored as bytes in memory (estimated size 19.6 KB, free 414.5 KB)
2017-07-01 18:19:38,034  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_11_piece0 in memory on localhost:56220 (size: 19.6 KB, free: 116.4 MB)
2017-07-01 18:19:38,038  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.SparkContext) - Created broadcast 11 from show at <console>:61
2017-07-01 18:19:38,090  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.hadoop.mapred.FileInputFormat) - Total input paths to process : 1
2017-07-01 18:19:38,106  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.SparkContext) - Starting job: show at <console>:61
2017-07-01 18:19:38,107  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 5 (show at <console>:61) with 1 output partitions
2017-07-01 18:19:38,107  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 5 (show at <console>:61)
2017-07-01 18:19:38,107  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2017-07-01 18:19:38,107  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2017-07-01 18:19:38,108  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 5 (MapPartitionsRDD[23] at show at <console>:61), which has no missing parents
2017-07-01 18:19:38,110  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_12 stored as values in memory (estimated size 8.7 KB, free 423.2 KB)
2017-07-01 18:19:38,114  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_12_piece0 stored as bytes in memory (estimated size 4.5 KB, free 427.7 KB)
2017-07-01 18:19:38,122  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_12_piece0 in memory on localhost:56220 (size: 4.5 KB, free: 116.4 MB)
2017-07-01 18:19:38,124  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 12 from broadcast at DAGScheduler.scala:1006
2017-07-01 18:19:38,125  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[23] at show at <console>:61)
2017-07-01 18:19:38,126  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 5.0 with 1 tasks
2017-07-01 18:19:38,127  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 5.0 (TID 6, localhost, partition 0,PROCESS_LOCAL, 2198 bytes)
2017-07-01 18:19:38,128  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 5.0 (TID 6)
2017-07-01 18:19:38,138  INFO [Executor task launch worker-0] (org.apache.spark.rdd.HadoopRDD) - Input split: file:/home/turmasabado/spark-notebook/produtos.json:0+500
2017-07-01 18:19:38,202  INFO [Executor task launch worker-0] (org.apache.spark.sql.catalyst.expressions.codegen.GeneratePredicate) - Code generated in 46.036222 ms
2017-07-01 18:19:38,221  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 5.0 (TID 6). 3055 bytes result sent to driver
2017-07-01 18:19:38,223  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 5.0 (TID 6) in 96 ms on localhost (1/1)
2017-07-01 18:19:38,223  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2017-07-01 18:19:38,224  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 5 (show at <console>:61) finished in 0,097 s
2017-07-01 18:19:38,224  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.scheduler.DAGScheduler) - Job 5 finished: show at <console>:61, took 0,117896 s
2017-07-01 18:19:38,238  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.SparkContext) - Starting job: show at <console>:61
2017-07-01 18:19:38,241  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 6 (show at <console>:61) with 1 output partitions
2017-07-01 18:19:38,241  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 6 (show at <console>:61)
2017-07-01 18:19:38,241  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2017-07-01 18:19:38,242  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2017-07-01 18:19:38,242  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 6 (MapPartitionsRDD[23] at show at <console>:61), which has no missing parents
2017-07-01 18:19:38,243  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_13 stored as values in memory (estimated size 8.7 KB, free 436.4 KB)
2017-07-01 18:19:38,249  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_13_piece0 stored as bytes in memory (estimated size 4.5 KB, free 440.9 KB)
2017-07-01 18:19:38,252  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_13_piece0 in memory on localhost:56220 (size: 4.5 KB, free: 116.4 MB)
2017-07-01 18:19:38,254  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 13 from broadcast at DAGScheduler.scala:1006
2017-07-01 18:19:38,254  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[23] at show at <console>:61)
2017-07-01 18:19:38,255  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 6.0 with 1 tasks
2017-07-01 18:19:38,256  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 6.0 (TID 7, localhost, partition 1,PROCESS_LOCAL, 2198 bytes)
2017-07-01 18:19:38,257  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 6.0 (TID 7)
2017-07-01 18:19:38,264  INFO [Executor task launch worker-0] (org.apache.spark.rdd.HadoopRDD) - Input split: file:/home/turmasabado/spark-notebook/produtos.json:500+501
2017-07-01 18:19:38,279  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 6.0 (TID 7). 2283 bytes result sent to driver
2017-07-01 18:19:38,284  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 6.0 (TID 7) in 29 ms on localhost (1/1)
2017-07-01 18:19:38,284  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2017-07-01 18:19:38,284  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 6 (show at <console>:61) finished in 0,029 s
2017-07-01 18:19:38,285  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.scheduler.DAGScheduler) - Job 6 finished: show at <console>:61, took 0,046613 s
2017-07-01 18:19:38,960  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_10_piece0 on localhost:56220 in memory (size: 19.5 KB, free: 116.4 MB)
2017-07-01 18:19:38,966  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_11_piece0 on localhost:56220 in memory (size: 19.6 KB, free: 116.4 MB)
2017-07-01 18:19:38,967  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 9
2017-07-01 18:19:38,969  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 10
2017-07-01 18:19:38,970  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 11
2017-07-01 18:19:38,973  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_13_piece0 on localhost:56220 in memory (size: 4.5 KB, free: 116.4 MB)
2017-07-01 18:19:38,974  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 12
2017-07-01 18:19:38,976  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_12_piece0 on localhost:56220 in memory (size: 4.5 KB, free: 116.4 MB)
2017-07-01 18:19:40,114  INFO [Remote-akka.actor.default-dispatcher-16] (org.apache.spark.storage.MemoryStore) - Block broadcast_14 stored as values in memory (estimated size 187.4 KB, free 187.4 KB)
2017-07-01 18:19:40,140  INFO [Remote-akka.actor.default-dispatcher-16] (org.apache.spark.storage.MemoryStore) - Block broadcast_14_piece0 stored as bytes in memory (estimated size 19.5 KB, free 206.9 KB)
2017-07-01 18:19:40,143  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_14_piece0 in memory on localhost:56220 (size: 19.5 KB, free: 116.4 MB)
2017-07-01 18:19:40,145  INFO [Remote-akka.actor.default-dispatcher-16] (org.apache.spark.SparkContext) - Created broadcast 14 from show at <console>:62
2017-07-01 18:19:40,194  INFO [Remote-akka.actor.default-dispatcher-16] (org.apache.spark.storage.MemoryStore) - Block broadcast_15 stored as values in memory (estimated size 188.0 KB, free 394.9 KB)
2017-07-01 18:19:40,300  INFO [Remote-akka.actor.default-dispatcher-16] (org.apache.spark.storage.MemoryStore) - Block broadcast_15_piece0 stored as bytes in memory (estimated size 19.6 KB, free 414.5 KB)
2017-07-01 18:19:40,301  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_15_piece0 in memory on localhost:56220 (size: 19.6 KB, free: 116.4 MB)
2017-07-01 18:19:40,306  INFO [Remote-akka.actor.default-dispatcher-16] (org.apache.spark.SparkContext) - Created broadcast 15 from show at <console>:62
2017-07-01 18:19:40,508  INFO [Remote-akka.actor.default-dispatcher-16] (org.apache.hadoop.mapred.FileInputFormat) - Total input paths to process : 1
2017-07-01 18:19:40,516  INFO [Remote-akka.actor.default-dispatcher-16] (org.apache.spark.SparkContext) - Starting job: show at <console>:62
2017-07-01 18:19:40,518  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 7 (show at <console>:62) with 2 output partitions
2017-07-01 18:19:40,518  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 7 (show at <console>:62)
2017-07-01 18:19:40,518  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2017-07-01 18:19:40,518  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2017-07-01 18:19:40,519  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 7 (MapPartitionsRDD[31] at show at <console>:62), which has no missing parents
2017-07-01 18:19:40,532  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_16 stored as values in memory (estimated size 9.5 KB, free 424.0 KB)
2017-07-01 18:19:40,537  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_16_piece0 stored as bytes in memory (estimated size 4.9 KB, free 428.9 KB)
2017-07-01 18:19:40,538  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_16_piece0 in memory on localhost:56220 (size: 4.9 KB, free: 116.4 MB)
2017-07-01 18:19:40,541  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 16 from broadcast at DAGScheduler.scala:1006
2017-07-01 18:19:40,542  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 7 (MapPartitionsRDD[31] at show at <console>:62)
2017-07-01 18:19:40,544  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 7.0 with 2 tasks
2017-07-01 18:19:40,547  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 7.0 (TID 8, localhost, partition 0,PROCESS_LOCAL, 2198 bytes)
2017-07-01 18:19:40,548  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 7.0 (TID 9, localhost, partition 1,PROCESS_LOCAL, 2198 bytes)
2017-07-01 18:19:40,548  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 7.0 (TID 9)
2017-07-01 18:19:40,548  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 7.0 (TID 8)
2017-07-01 18:19:40,561  INFO [Executor task launch worker-1] (org.apache.spark.rdd.HadoopRDD) - Input split: file:/home/turmasabado/spark-notebook/produtos.json:500+501
2017-07-01 18:19:40,561  INFO [Executor task launch worker-0] (org.apache.spark.rdd.HadoopRDD) - Input split: file:/home/turmasabado/spark-notebook/produtos.json:0+500
2017-07-01 18:19:40,595  INFO [Executor task launch worker-0] (org.apache.spark.sql.catalyst.expressions.codegen.GeneratePredicate) - Code generated in 22.46925 ms
2017-07-01 18:19:40,730  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 7.0 (TID 8). 4435 bytes result sent to driver
2017-07-01 18:19:40,735  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 7.0 (TID 8) in 188 ms on localhost (1/2)
2017-07-01 18:19:40,785  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 7.0 (TID 9). 3327 bytes result sent to driver
2017-07-01 18:19:40,787  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 7.0 (TID 9) in 239 ms on localhost (2/2)
2017-07-01 18:19:40,788  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2017-07-01 18:19:40,788  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 7 (show at <console>:62) finished in 0,241 s
2017-07-01 18:19:40,791  INFO [Remote-akka.actor.default-dispatcher-16] (org.apache.spark.scheduler.DAGScheduler) - Job 7 finished: show at <console>:62, took 0,274171 s
2017-07-01 18:19:42,040  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_16_piece0 on localhost:56220 in memory (size: 4.9 KB, free: 116.4 MB)
2017-07-01 18:19:42,041  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 15
2017-07-01 18:19:42,041  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 14
2017-07-01 18:19:42,041  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 13
2017-07-01 18:19:42,042  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_15_piece0 on localhost:56220 in memory (size: 19.6 KB, free: 116.4 MB)
2017-07-01 18:19:42,044  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_14_piece0 on localhost:56220 in memory (size: 19.5 KB, free: 116.4 MB)
2017-07-01 18:19:42,833  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.storage.MemoryStore) - Block broadcast_17 stored as values in memory (estimated size 187.4 KB, free 187.4 KB)
2017-07-01 18:19:42,860  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.storage.MemoryStore) - Block broadcast_17_piece0 stored as bytes in memory (estimated size 19.5 KB, free 206.9 KB)
2017-07-01 18:19:42,860  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_17_piece0 in memory on localhost:56220 (size: 19.5 KB, free: 116.4 MB)
2017-07-01 18:19:42,865  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.SparkContext) - Created broadcast 17 from show at <console>:63
2017-07-01 18:19:42,876  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.storage.MemoryStore) - Block broadcast_18 stored as values in memory (estimated size 188.0 KB, free 394.9 KB)
2017-07-01 18:19:42,902  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.storage.MemoryStore) - Block broadcast_18_piece0 stored as bytes in memory (estimated size 19.6 KB, free 414.5 KB)
2017-07-01 18:19:42,903  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_18_piece0 in memory on localhost:56220 (size: 19.6 KB, free: 116.4 MB)
2017-07-01 18:19:42,906  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.SparkContext) - Created broadcast 18 from show at <console>:63
2017-07-01 18:19:43,113  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.hadoop.mapred.FileInputFormat) - Total input paths to process : 1
2017-07-01 18:19:43,174  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.SparkContext) - Starting job: show at <console>:63
2017-07-01 18:19:43,181  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Registering RDD 37 (show at <console>:63)
2017-07-01 18:19:43,187  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 8 (show at <console>:63) with 1 output partitions
2017-07-01 18:19:43,193  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 9 (show at <console>:63)
2017-07-01 18:19:43,194  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List(ShuffleMapStage 8)
2017-07-01 18:19:43,195  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List(ShuffleMapStage 8)
2017-07-01 18:19:43,202  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ShuffleMapStage 8 (MapPartitionsRDD[37] at show at <console>:63), which has no missing parents
2017-07-01 18:19:43,223  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_19 stored as values in memory (estimated size 11.2 KB, free 425.7 KB)
2017-07-01 18:19:43,307  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_19_piece0 stored as bytes in memory (estimated size 5.7 KB, free 431.4 KB)
2017-07-01 18:19:43,309  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_19_piece0 in memory on localhost:56220 (size: 5.7 KB, free: 116.4 MB)
2017-07-01 18:19:43,310  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 19 from broadcast at DAGScheduler.scala:1006
2017-07-01 18:19:43,311  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_17_piece0 on localhost:56220 in memory (size: 19.5 KB, free: 116.4 MB)
2017-07-01 18:19:43,315  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[37] at show at <console>:63)
2017-07-01 18:19:43,316  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 8.0 with 2 tasks
2017-07-01 18:19:43,319  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 8.0 (TID 10, localhost, partition 0,PROCESS_LOCAL, 2187 bytes)
2017-07-01 18:19:43,319  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 8.0 (TID 11, localhost, partition 1,PROCESS_LOCAL, 2187 bytes)
2017-07-01 18:19:43,320  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 8.0 (TID 10)
2017-07-01 18:19:43,320  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 8.0 (TID 11)
2017-07-01 18:19:43,354  INFO [Executor task launch worker-1] (org.apache.spark.rdd.HadoopRDD) - Input split: file:/home/turmasabado/spark-notebook/produtos.json:0+500
2017-07-01 18:19:43,357  INFO [Executor task launch worker-0] (org.apache.spark.rdd.HadoopRDD) - Input split: file:/home/turmasabado/spark-notebook/produtos.json:500+501
2017-07-01 18:19:43,408  INFO [Executor task launch worker-0] (org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection) - Code generated in 43.073927 ms
2017-07-01 18:19:43,463  INFO [Executor task launch worker-0] (org.apache.spark.sql.catalyst.expressions.codegen.GenerateMutableProjection) - Code generated in 25.921248 ms
2017-07-01 18:19:43,502  INFO [Executor task launch worker-1] (org.apache.spark.sql.catalyst.expressions.codegen.GenerateMutableProjection) - Code generated in 41.172196 ms
2017-07-01 18:19:43,558  INFO [Executor task launch worker-1] (org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection) - Code generated in 28.135156 ms
2017-07-01 18:19:43,655  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 8.0 (TID 11). 2702 bytes result sent to driver
2017-07-01 18:19:43,679  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 8.0 (TID 11) in 360 ms on localhost (1/2)
2017-07-01 18:19:43,712  INFO [Executor task launch worker-1] (org.apache.spark.sql.catalyst.expressions.codegen.GenerateMutableProjection) - Code generated in 28.909712 ms
2017-07-01 18:19:43,783  INFO [Executor task launch worker-1] (org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeRowJoiner) - Code generated in 42.870193 ms
2017-07-01 18:19:43,810  INFO [Executor task launch worker-1] (org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection) - Code generated in 12.075576 ms
2017-07-01 18:19:43,832  INFO [Executor task launch worker-1] (org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection) - Code generated in 11.572566 ms
2017-07-01 18:19:44,114  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 8.0 (TID 10). 2702 bytes result sent to driver
2017-07-01 18:19:44,117  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 8.0 (TID 10) in 799 ms on localhost (2/2)
2017-07-01 18:19:44,117  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2017-07-01 18:19:44,118  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ShuffleMapStage 8 (show at <console>:63) finished in 0,802 s
2017-07-01 18:19:44,392  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - looking for newly runnable stages
2017-07-01 18:19:44,394  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - running: Set()
2017-07-01 18:19:44,416  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - waiting: Set(ResultStage 9)
2017-07-01 18:19:44,418  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - failed: Set()
2017-07-01 18:19:44,442  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 9 (MapPartitionsRDD[41] at show at <console>:63), which has no missing parents
2017-07-01 18:19:44,470  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_20 stored as values in memory (estimated size 13.1 KB, free 237.6 KB)
2017-07-01 18:19:44,478  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_20_piece0 stored as bytes in memory (estimated size 7.0 KB, free 244.6 KB)
2017-07-01 18:19:44,484  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_20_piece0 in memory on localhost:56220 (size: 7.0 KB, free: 116.4 MB)
2017-07-01 18:19:44,487  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 20 from broadcast at DAGScheduler.scala:1006
2017-07-01 18:19:44,487  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[41] at show at <console>:63)
2017-07-01 18:19:44,487  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 9.0 with 1 tasks
2017-07-01 18:19:44,527  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 9.0 (TID 12, localhost, partition 0,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:44,528  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 9.0 (TID 12)
2017-07-01 18:19:44,589  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:44,595  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 21 ms
2017-07-01 18:19:44,713  INFO [Executor task launch worker-1] (org.apache.spark.sql.catalyst.expressions.codegen.GenerateSafeProjection) - Code generated in 43.191377 ms
2017-07-01 18:19:44,759  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 9.0 (TID 12). 1609 bytes result sent to driver
2017-07-01 18:19:44,761  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 9.0 (TID 12) in 238 ms on localhost (1/1)
2017-07-01 18:19:44,761  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2017-07-01 18:19:44,761  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 9 (show at <console>:63) finished in 0,225 s
2017-07-01 18:19:44,763  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.scheduler.DAGScheduler) - Job 8 finished: show at <console>:63, took 1,588757 s
2017-07-01 18:19:44,787  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.SparkContext) - Starting job: show at <console>:63
2017-07-01 18:19:44,844  INFO [dag-scheduler-event-loop] (org.apache.spark.MapOutputTrackerMaster) - Size of output statuses for shuffle 0 is 169 bytes
2017-07-01 18:19:44,860  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 9 (show at <console>:63) with 199 output partitions
2017-07-01 18:19:44,860  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 11 (show at <console>:63)
2017-07-01 18:19:44,860  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List(ShuffleMapStage 10)
2017-07-01 18:19:44,860  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2017-07-01 18:19:44,861  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 11 (MapPartitionsRDD[41] at show at <console>:63), which has no missing parents
2017-07-01 18:19:44,900  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_21 stored as values in memory (estimated size 13.1 KB, free 257.7 KB)
2017-07-01 18:19:44,906  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_21_piece0 stored as bytes in memory (estimated size 7.0 KB, free 264.7 KB)
2017-07-01 18:19:44,906  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_21_piece0 in memory on localhost:56220 (size: 7.0 KB, free: 116.4 MB)
2017-07-01 18:19:44,908  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 21 from broadcast at DAGScheduler.scala:1006
2017-07-01 18:19:44,914  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 199 missing tasks from ResultStage 11 (MapPartitionsRDD[41] at show at <console>:63)
2017-07-01 18:19:44,916  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 11.0 with 199 tasks
2017-07-01 18:19:44,921  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 11.0 (TID 13, localhost, partition 1,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:44,922  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 11.0 (TID 14, localhost, partition 2,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:44,922  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 11.0 (TID 13)
2017-07-01 18:19:44,922  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 11.0 (TID 14)
2017-07-01 18:19:44,938  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:44,946  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 8 ms
2017-07-01 18:19:44,937  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:44,948  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 11 ms
2017-07-01 18:19:44,973  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 11.0 (TID 14). 1609 bytes result sent to driver
2017-07-01 18:19:44,977  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 2.0 in stage 11.0 (TID 15, localhost, partition 3,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:44,979  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 11.0 (TID 14) in 58 ms on localhost (1/199)
2017-07-01 18:19:44,975  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 11.0 (TID 13). 1609 bytes result sent to driver
2017-07-01 18:19:44,984  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 3.0 in stage 11.0 (TID 16, localhost, partition 4,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:44,984  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 11.0 (TID 13) in 63 ms on localhost (2/199)
2017-07-01 18:19:44,986  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 3.0 in stage 11.0 (TID 16)
2017-07-01 18:19:44,989  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 2.0 in stage 11.0 (TID 15)
2017-07-01 18:19:45,004  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,005  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:45,004  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,006  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 5 ms
2017-07-01 18:19:45,008  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 2.0 in stage 11.0 (TID 15). 1609 bytes result sent to driver
2017-07-01 18:19:45,009  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 3.0 in stage 11.0 (TID 16). 1609 bytes result sent to driver
2017-07-01 18:19:45,010  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 4.0 in stage 11.0 (TID 17, localhost, partition 5,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,011  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 4.0 in stage 11.0 (TID 17)
2017-07-01 18:19:45,012  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 5.0 in stage 11.0 (TID 18, localhost, partition 6,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,013  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 5.0 in stage 11.0 (TID 18)
2017-07-01 18:19:45,014  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 3.0 in stage 11.0 (TID 16) in 30 ms on localhost (3/199)
2017-07-01 18:19:45,018  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 2.0 in stage 11.0 (TID 15) in 42 ms on localhost (4/199)
2017-07-01 18:19:45,026  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,026  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:45,026  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,026  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:45,028  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 5.0 in stage 11.0 (TID 18). 1609 bytes result sent to driver
2017-07-01 18:19:45,029  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 4.0 in stage 11.0 (TID 17). 1609 bytes result sent to driver
2017-07-01 18:19:45,035  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 6.0 in stage 11.0 (TID 19, localhost, partition 7,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,036  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 5.0 in stage 11.0 (TID 18) in 25 ms on localhost (5/199)
2017-07-01 18:19:45,037  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 6.0 in stage 11.0 (TID 19)
2017-07-01 18:19:45,039  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 7.0 in stage 11.0 (TID 20, localhost, partition 8,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,045  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 4.0 in stage 11.0 (TID 17) in 34 ms on localhost (6/199)
2017-07-01 18:19:45,048  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,048  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:19:45,048  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 7.0 in stage 11.0 (TID 20)
2017-07-01 18:19:45,054  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 6.0 in stage 11.0 (TID 19). 1609 bytes result sent to driver
2017-07-01 18:19:45,055  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 8.0 in stage 11.0 (TID 21, localhost, partition 9,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,055  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 6.0 in stage 11.0 (TID 19) in 20 ms on localhost (7/199)
2017-07-01 18:19:45,058  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 8.0 in stage 11.0 (TID 21)
2017-07-01 18:19:45,078  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,080  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:19:45,078  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,081  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:19:45,083  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 7.0 in stage 11.0 (TID 20). 1609 bytes result sent to driver
2017-07-01 18:19:45,086  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 9.0 in stage 11.0 (TID 22, localhost, partition 10,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,086  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 9.0 in stage 11.0 (TID 22)
2017-07-01 18:19:45,086  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 7.0 in stage 11.0 (TID 20) in 48 ms on localhost (8/199)
2017-07-01 18:19:45,092  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,093  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:45,084  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 8.0 in stage 11.0 (TID 21). 1609 bytes result sent to driver
2017-07-01 18:19:45,096  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 10.0 in stage 11.0 (TID 23, localhost, partition 11,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,096  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 8.0 in stage 11.0 (TID 21) in 41 ms on localhost (9/199)
2017-07-01 18:19:45,097  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 10.0 in stage 11.0 (TID 23)
2017-07-01 18:19:45,100  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 9.0 in stage 11.0 (TID 22). 1609 bytes result sent to driver
2017-07-01 18:19:45,101  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 11.0 in stage 11.0 (TID 24, localhost, partition 12,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,101  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 9.0 in stage 11.0 (TID 22) in 16 ms on localhost (10/199)
2017-07-01 18:19:45,102  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 11.0 in stage 11.0 (TID 24)
2017-07-01 18:19:45,109  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,112  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:19:45,112  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,113  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:19:45,115  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 10.0 in stage 11.0 (TID 23). 1609 bytes result sent to driver
2017-07-01 18:19:45,117  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 12.0 in stage 11.0 (TID 25, localhost, partition 13,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,117  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 10.0 in stage 11.0 (TID 23) in 22 ms on localhost (11/199)
2017-07-01 18:19:45,119  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 12.0 in stage 11.0 (TID 25)
2017-07-01 18:19:45,138  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,139  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:45,139  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 11.0 in stage 11.0 (TID 24). 1609 bytes result sent to driver
2017-07-01 18:19:45,142  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 13.0 in stage 11.0 (TID 26, localhost, partition 14,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,143  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 11.0 in stage 11.0 (TID 24) in 41 ms on localhost (12/199)
2017-07-01 18:19:45,143  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 13.0 in stage 11.0 (TID 26)
2017-07-01 18:19:45,151  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 12.0 in stage 11.0 (TID 25). 1609 bytes result sent to driver
2017-07-01 18:19:45,152  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 14.0 in stage 11.0 (TID 27, localhost, partition 15,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,153  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 12.0 in stage 11.0 (TID 25) in 37 ms on localhost (13/199)
2017-07-01 18:19:45,154  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 14.0 in stage 11.0 (TID 27)
2017-07-01 18:19:45,166  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,170  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:19:45,175  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,176  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:19:45,178  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 14.0 in stage 11.0 (TID 27). 1609 bytes result sent to driver
2017-07-01 18:19:45,183  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 15.0 in stage 11.0 (TID 28, localhost, partition 16,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,184  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 14.0 in stage 11.0 (TID 27) in 33 ms on localhost (14/199)
2017-07-01 18:19:45,184  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 15.0 in stage 11.0 (TID 28)
2017-07-01 18:19:45,192  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,194  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:19:45,198  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 15.0 in stage 11.0 (TID 28). 1609 bytes result sent to driver
2017-07-01 18:19:45,200  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 16.0 in stage 11.0 (TID 29, localhost, partition 17,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,201  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 15.0 in stage 11.0 (TID 28) in 19 ms on localhost (15/199)
2017-07-01 18:19:45,201  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 16.0 in stage 11.0 (TID 29)
2017-07-01 18:19:45,227  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,227  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:19:45,236  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 16.0 in stage 11.0 (TID 29). 1609 bytes result sent to driver
2017-07-01 18:19:45,237  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 17.0 in stage 11.0 (TID 30, localhost, partition 18,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,238  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 17.0 in stage 11.0 (TID 30)
2017-07-01 18:19:45,241  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 16.0 in stage 11.0 (TID 29) in 42 ms on localhost (16/199)
2017-07-01 18:19:45,253  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,253  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:45,255  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 17.0 in stage 11.0 (TID 30). 1609 bytes result sent to driver
2017-07-01 18:19:45,259  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 18.0 in stage 11.0 (TID 31, localhost, partition 19,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,260  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 18.0 in stage 11.0 (TID 31)
2017-07-01 18:19:45,260  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 17.0 in stage 11.0 (TID 30) in 24 ms on localhost (17/199)
2017-07-01 18:19:45,269  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,269  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:19:45,270  INFO [Executor task launch worker-1] (org.apache.spark.sql.catalyst.expressions.codegen.GenerateMutableProjection) - Code generated in 51.301276 ms
2017-07-01 18:19:45,276  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 18.0 in stage 11.0 (TID 31). 1609 bytes result sent to driver
2017-07-01 18:19:45,278  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 19.0 in stage 11.0 (TID 32, localhost, partition 20,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,278  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 18.0 in stage 11.0 (TID 31) in 19 ms on localhost (18/199)
2017-07-01 18:19:45,280  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 19.0 in stage 11.0 (TID 32)
2017-07-01 18:19:45,299  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,301  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:19:45,300  INFO [Executor task launch worker-1] (org.apache.spark.sql.catalyst.expressions.codegen.GenerateMutableProjection) - Code generated in 11.98831 ms
2017-07-01 18:19:45,311  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 19.0 in stage 11.0 (TID 32). 1609 bytes result sent to driver
2017-07-01 18:19:45,314  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 20.0 in stage 11.0 (TID 33, localhost, partition 21,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,314  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 19.0 in stage 11.0 (TID 32) in 37 ms on localhost (19/199)
2017-07-01 18:19:45,315  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 20.0 in stage 11.0 (TID 33)
2017-07-01 18:19:45,322  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,323  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:45,327  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 20.0 in stage 11.0 (TID 33). 1609 bytes result sent to driver
2017-07-01 18:19:45,328  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 21.0 in stage 11.0 (TID 34, localhost, partition 22,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,330  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 21.0 in stage 11.0 (TID 34)
2017-07-01 18:19:45,334  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 20.0 in stage 11.0 (TID 33) in 20 ms on localhost (20/199)
2017-07-01 18:19:45,344  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,344  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:19:45,350  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 21.0 in stage 11.0 (TID 34). 1609 bytes result sent to driver
2017-07-01 18:19:45,353  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 22.0 in stage 11.0 (TID 35, localhost, partition 23,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,353  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 22.0 in stage 11.0 (TID 35)
2017-07-01 18:19:45,355  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 21.0 in stage 11.0 (TID 34) in 27 ms on localhost (21/199)
2017-07-01 18:19:45,363  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,364  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:45,369  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 22.0 in stage 11.0 (TID 35). 1609 bytes result sent to driver
2017-07-01 18:19:45,371  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 23.0 in stage 11.0 (TID 36, localhost, partition 24,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,372  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 22.0 in stage 11.0 (TID 35) in 20 ms on localhost (22/199)
2017-07-01 18:19:45,372  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 23.0 in stage 11.0 (TID 36)
2017-07-01 18:19:45,389  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,391  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:19:45,395  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 23.0 in stage 11.0 (TID 36). 1609 bytes result sent to driver
2017-07-01 18:19:45,397  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 24.0 in stage 11.0 (TID 37, localhost, partition 25,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,397  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 24.0 in stage 11.0 (TID 37)
2017-07-01 18:19:45,398  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 23.0 in stage 11.0 (TID 36) in 28 ms on localhost (23/199)
2017-07-01 18:19:45,405  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,406  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:45,409  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 24.0 in stage 11.0 (TID 37). 1609 bytes result sent to driver
2017-07-01 18:19:45,415  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 25.0 in stage 11.0 (TID 38, localhost, partition 26,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,417  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 25.0 in stage 11.0 (TID 38)
2017-07-01 18:19:45,419  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 24.0 in stage 11.0 (TID 37) in 23 ms on localhost (24/199)
2017-07-01 18:19:45,429  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,430  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:45,434  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 25.0 in stage 11.0 (TID 38). 1609 bytes result sent to driver
2017-07-01 18:19:45,436  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 26.0 in stage 11.0 (TID 39, localhost, partition 27,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,438  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 26.0 in stage 11.0 (TID 39)
2017-07-01 18:19:45,440  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 25.0 in stage 11.0 (TID 38) in 25 ms on localhost (25/199)
2017-07-01 18:19:45,447  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,448  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:45,452  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 26.0 in stage 11.0 (TID 39). 1609 bytes result sent to driver
2017-07-01 18:19:45,454  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 27.0 in stage 11.0 (TID 40, localhost, partition 28,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,456  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 27.0 in stage 11.0 (TID 40)
2017-07-01 18:19:45,459  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 26.0 in stage 11.0 (TID 39) in 23 ms on localhost (26/199)
2017-07-01 18:19:45,462  INFO [Executor task launch worker-1] (org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection) - Code generated in 78.093438 ms
2017-07-01 18:19:45,471  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,471  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:19:45,474  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 27.0 in stage 11.0 (TID 40). 1609 bytes result sent to driver
2017-07-01 18:19:45,477  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 28.0 in stage 11.0 (TID 41, localhost, partition 29,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,477  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 27.0 in stage 11.0 (TID 40) in 23 ms on localhost (27/199)
2017-07-01 18:19:45,477  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 28.0 in stage 11.0 (TID 41)
2017-07-01 18:19:45,483  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,484  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:45,632  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 28.0 in stage 11.0 (TID 41). 1609 bytes result sent to driver
2017-07-01 18:19:45,633  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 29.0 in stage 11.0 (TID 42, localhost, partition 30,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,633  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 29.0 in stage 11.0 (TID 42)
2017-07-01 18:19:45,636  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 28.0 in stage 11.0 (TID 41) in 160 ms on localhost (28/199)
2017-07-01 18:19:45,639  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_20_piece0 on localhost:56220 in memory (size: 7.0 KB, free: 116.4 MB)
2017-07-01 18:19:45,640  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 25
2017-07-01 18:19:45,642  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_19_piece0 on localhost:56220 in memory (size: 5.7 KB, free: 116.4 MB)
2017-07-01 18:19:45,644  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 24
2017-07-01 18:19:45,647  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,649  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:19:45,652  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 29.0 in stage 11.0 (TID 42). 1609 bytes result sent to driver
2017-07-01 18:19:45,656  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 30.0 in stage 11.0 (TID 43, localhost, partition 31,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,657  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 30.0 in stage 11.0 (TID 43)
2017-07-01 18:19:45,659  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 29.0 in stage 11.0 (TID 42) in 26 ms on localhost (29/199)
2017-07-01 18:19:45,667  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,668  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:19:45,671  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 30.0 in stage 11.0 (TID 43). 1609 bytes result sent to driver
2017-07-01 18:19:45,673  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 31.0 in stage 11.0 (TID 44, localhost, partition 32,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,674  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 30.0 in stage 11.0 (TID 43) in 17 ms on localhost (30/199)
2017-07-01 18:19:45,675  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 31.0 in stage 11.0 (TID 44)
2017-07-01 18:19:45,683  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 13.0 in stage 11.0 (TID 26). 1963 bytes result sent to driver
2017-07-01 18:19:45,686  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 32.0 in stage 11.0 (TID 45, localhost, partition 33,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,689  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 13.0 in stage 11.0 (TID 26) in 546 ms on localhost (31/199)
2017-07-01 18:19:45,690  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,691  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:45,693  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 31.0 in stage 11.0 (TID 44). 1609 bytes result sent to driver
2017-07-01 18:19:45,694  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 33.0 in stage 11.0 (TID 46, localhost, partition 34,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,695  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 33.0 in stage 11.0 (TID 46)
2017-07-01 18:19:45,697  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 31.0 in stage 11.0 (TID 44) in 24 ms on localhost (32/199)
2017-07-01 18:19:45,702  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 32.0 in stage 11.0 (TID 45)
2017-07-01 18:19:45,704  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,705  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:19:45,710  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 33.0 in stage 11.0 (TID 46). 1609 bytes result sent to driver
2017-07-01 18:19:45,714  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 34.0 in stage 11.0 (TID 47, localhost, partition 35,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,714  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 33.0 in stage 11.0 (TID 46) in 20 ms on localhost (33/199)
2017-07-01 18:19:45,716  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 34.0 in stage 11.0 (TID 47)
2017-07-01 18:19:45,732  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,733  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:45,733  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,739  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 6 ms
2017-07-01 18:19:45,742  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 34.0 in stage 11.0 (TID 47). 1609 bytes result sent to driver
2017-07-01 18:19:45,747  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 35.0 in stage 11.0 (TID 48, localhost, partition 36,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,748  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 34.0 in stage 11.0 (TID 47) in 35 ms on localhost (34/199)
2017-07-01 18:19:45,750  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 35.0 in stage 11.0 (TID 48)
2017-07-01 18:19:45,760  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,760  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:19:45,764  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 32.0 in stage 11.0 (TID 45). 1963 bytes result sent to driver
2017-07-01 18:19:45,766  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 36.0 in stage 11.0 (TID 49, localhost, partition 37,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,767  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 36.0 in stage 11.0 (TID 49)
2017-07-01 18:19:45,768  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 32.0 in stage 11.0 (TID 45) in 82 ms on localhost (35/199)
2017-07-01 18:19:45,774  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,775  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:45,781  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 35.0 in stage 11.0 (TID 48). 1609 bytes result sent to driver
2017-07-01 18:19:45,781  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 36.0 in stage 11.0 (TID 49). 1609 bytes result sent to driver
2017-07-01 18:19:45,782  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 37.0 in stage 11.0 (TID 50, localhost, partition 38,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,782  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 38.0 in stage 11.0 (TID 51, localhost, partition 39,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,783  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 35.0 in stage 11.0 (TID 48) in 36 ms on localhost (36/199)
2017-07-01 18:19:45,784  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 36.0 in stage 11.0 (TID 49) in 18 ms on localhost (37/199)
2017-07-01 18:19:45,786  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 37.0 in stage 11.0 (TID 50)
2017-07-01 18:19:45,790  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 38.0 in stage 11.0 (TID 51)
2017-07-01 18:19:45,791  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,792  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:45,793  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 37.0 in stage 11.0 (TID 50). 1609 bytes result sent to driver
2017-07-01 18:19:45,794  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 39.0 in stage 11.0 (TID 52, localhost, partition 40,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,794  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 39.0 in stage 11.0 (TID 52)
2017-07-01 18:19:45,794  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 37.0 in stage 11.0 (TID 50) in 12 ms on localhost (38/199)
2017-07-01 18:19:45,802  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,802  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:19:45,804  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 39.0 in stage 11.0 (TID 52). 1609 bytes result sent to driver
2017-07-01 18:19:45,806  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 40.0 in stage 11.0 (TID 53, localhost, partition 41,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,806  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 40.0 in stage 11.0 (TID 53)
2017-07-01 18:19:45,806  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 39.0 in stage 11.0 (TID 52) in 12 ms on localhost (39/199)
2017-07-01 18:19:45,808  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,813  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 5 ms
2017-07-01 18:19:45,815  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 38.0 in stage 11.0 (TID 51). 1609 bytes result sent to driver
2017-07-01 18:19:45,816  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 41.0 in stage 11.0 (TID 54, localhost, partition 42,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,817  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 38.0 in stage 11.0 (TID 51) in 34 ms on localhost (40/199)
2017-07-01 18:19:45,818  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 41.0 in stage 11.0 (TID 54)
2017-07-01 18:19:45,826  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,827  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:45,828  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 40.0 in stage 11.0 (TID 53). 1609 bytes result sent to driver
2017-07-01 18:19:45,832  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,832  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 42.0 in stage 11.0 (TID 55, localhost, partition 43,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,836  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 40.0 in stage 11.0 (TID 53) in 31 ms on localhost (41/199)
2017-07-01 18:19:45,837  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 42.0 in stage 11.0 (TID 55)
2017-07-01 18:19:45,838  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 6 ms
2017-07-01 18:19:45,842  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 41.0 in stage 11.0 (TID 54). 1609 bytes result sent to driver
2017-07-01 18:19:45,845  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 43.0 in stage 11.0 (TID 56, localhost, partition 44,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,845  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 43.0 in stage 11.0 (TID 56)
2017-07-01 18:19:45,852  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,853  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:45,854  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 41.0 in stage 11.0 (TID 54) in 33 ms on localhost (42/199)
2017-07-01 18:19:45,855  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 43.0 in stage 11.0 (TID 56). 1609 bytes result sent to driver
2017-07-01 18:19:45,856  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 44.0 in stage 11.0 (TID 57, localhost, partition 45,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,857  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 43.0 in stage 11.0 (TID 56) in 12 ms on localhost (43/199)
2017-07-01 18:19:45,858  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 44.0 in stage 11.0 (TID 57)
2017-07-01 18:19:45,867  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,868  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:45,871  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 42.0 in stage 11.0 (TID 55). 1609 bytes result sent to driver
2017-07-01 18:19:45,874  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 45.0 in stage 11.0 (TID 58, localhost, partition 46,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,875  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 42.0 in stage 11.0 (TID 55) in 42 ms on localhost (44/199)
2017-07-01 18:19:45,877  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 45.0 in stage 11.0 (TID 58)
2017-07-01 18:19:45,872  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,884  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 12 ms
2017-07-01 18:19:45,886  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,887  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:45,887  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 44.0 in stage 11.0 (TID 57). 1609 bytes result sent to driver
2017-07-01 18:19:45,891  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 46.0 in stage 11.0 (TID 59, localhost, partition 47,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,892  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 44.0 in stage 11.0 (TID 57) in 36 ms on localhost (45/199)
2017-07-01 18:19:45,894  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 46.0 in stage 11.0 (TID 59)
2017-07-01 18:19:45,899  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 45.0 in stage 11.0 (TID 58). 1609 bytes result sent to driver
2017-07-01 18:19:45,901  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 47.0 in stage 11.0 (TID 60, localhost, partition 48,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,902  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 45.0 in stage 11.0 (TID 58) in 29 ms on localhost (46/199)
2017-07-01 18:19:45,902  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 47.0 in stage 11.0 (TID 60)
2017-07-01 18:19:45,908  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,913  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 5 ms
2017-07-01 18:19:45,915  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 46.0 in stage 11.0 (TID 59). 1609 bytes result sent to driver
2017-07-01 18:19:45,917  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 48.0 in stage 11.0 (TID 61, localhost, partition 49,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,919  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 46.0 in stage 11.0 (TID 59) in 27 ms on localhost (47/199)
2017-07-01 18:19:45,920  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 48.0 in stage 11.0 (TID 61)
2017-07-01 18:19:45,926  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,928  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:19:45,927  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,930  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 13 ms
2017-07-01 18:19:45,933  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 47.0 in stage 11.0 (TID 60). 1609 bytes result sent to driver
2017-07-01 18:19:45,938  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 49.0 in stage 11.0 (TID 62, localhost, partition 50,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,940  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 47.0 in stage 11.0 (TID 60) in 39 ms on localhost (48/199)
2017-07-01 18:19:45,941  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 49.0 in stage 11.0 (TID 62)
2017-07-01 18:19:45,949  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 48.0 in stage 11.0 (TID 61). 1609 bytes result sent to driver
2017-07-01 18:19:45,950  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 50.0 in stage 11.0 (TID 63, localhost, partition 51,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,950  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 50.0 in stage 11.0 (TID 63)
2017-07-01 18:19:45,951  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 48.0 in stage 11.0 (TID 61) in 34 ms on localhost (49/199)
2017-07-01 18:19:45,956  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,958  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:19:45,960  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 49.0 in stage 11.0 (TID 62). 1609 bytes result sent to driver
2017-07-01 18:19:45,966  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 51.0 in stage 11.0 (TID 64, localhost, partition 52,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,967  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 49.0 in stage 11.0 (TID 62) in 30 ms on localhost (50/199)
2017-07-01 18:19:45,969  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 51.0 in stage 11.0 (TID 64)
2017-07-01 18:19:45,975  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,976  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:45,978  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 51.0 in stage 11.0 (TID 64). 1609 bytes result sent to driver
2017-07-01 18:19:45,979  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 52.0 in stage 11.0 (TID 65, localhost, partition 53,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,980  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 52.0 in stage 11.0 (TID 65)
2017-07-01 18:19:45,984  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 51.0 in stage 11.0 (TID 64) in 18 ms on localhost (51/199)
2017-07-01 18:19:45,989  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:45,992  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:19:45,996  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 52.0 in stage 11.0 (TID 65). 1609 bytes result sent to driver
2017-07-01 18:19:45,999  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 53.0 in stage 11.0 (TID 66, localhost, partition 54,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:45,999  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 52.0 in stage 11.0 (TID 65) in 20 ms on localhost (52/199)
2017-07-01 18:19:46,000  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 53.0 in stage 11.0 (TID 66)
2017-07-01 18:19:46,007  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:46,008  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:46,012  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 53.0 in stage 11.0 (TID 66). 1609 bytes result sent to driver
2017-07-01 18:19:46,015  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 54.0 in stage 11.0 (TID 67, localhost, partition 55,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:46,015  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 53.0 in stage 11.0 (TID 66) in 17 ms on localhost (53/199)
2017-07-01 18:19:46,018  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 54.0 in stage 11.0 (TID 67)
2017-07-01 18:19:46,028  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:46,030  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:19:46,039  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 54.0 in stage 11.0 (TID 67). 1609 bytes result sent to driver
2017-07-01 18:19:46,040  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 55.0 in stage 11.0 (TID 68, localhost, partition 56,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:46,041  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 55.0 in stage 11.0 (TID 68)
2017-07-01 18:19:46,044  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 54.0 in stage 11.0 (TID 67) in 30 ms on localhost (54/199)
2017-07-01 18:19:46,048  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:46,049  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:46,051  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 55.0 in stage 11.0 (TID 68). 1609 bytes result sent to driver
2017-07-01 18:19:46,054  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 56.0 in stage 11.0 (TID 69, localhost, partition 57,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:46,055  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 56.0 in stage 11.0 (TID 69)
2017-07-01 18:19:46,056  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 55.0 in stage 11.0 (TID 68) in 16 ms on localhost (55/199)
2017-07-01 18:19:46,065  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:46,069  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:19:46,071  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 56.0 in stage 11.0 (TID 69). 1609 bytes result sent to driver
2017-07-01 18:19:46,072  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 57.0 in stage 11.0 (TID 70, localhost, partition 58,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:46,072  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 56.0 in stage 11.0 (TID 69) in 18 ms on localhost (56/199)
2017-07-01 18:19:46,073  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 57.0 in stage 11.0 (TID 70)
2017-07-01 18:19:46,082  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:46,083  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:19:46,086  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 57.0 in stage 11.0 (TID 70). 1609 bytes result sent to driver
2017-07-01 18:19:46,088  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 58.0 in stage 11.0 (TID 71, localhost, partition 59,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:46,089  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 57.0 in stage 11.0 (TID 70) in 18 ms on localhost (57/199)
2017-07-01 18:19:46,091  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 58.0 in stage 11.0 (TID 71)
2017-07-01 18:19:46,101  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:46,102  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:46,104  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 58.0 in stage 11.0 (TID 71). 1609 bytes result sent to driver
2017-07-01 18:19:46,106  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 59.0 in stage 11.0 (TID 72, localhost, partition 60,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:46,107  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 59.0 in stage 11.0 (TID 72)
2017-07-01 18:19:46,109  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 58.0 in stage 11.0 (TID 71) in 21 ms on localhost (58/199)
2017-07-01 18:19:46,114  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:46,115  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:46,118  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 59.0 in stage 11.0 (TID 72). 1609 bytes result sent to driver
2017-07-01 18:19:46,119  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 60.0 in stage 11.0 (TID 73, localhost, partition 61,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:46,120  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 60.0 in stage 11.0 (TID 73)
2017-07-01 18:19:46,124  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 59.0 in stage 11.0 (TID 72) in 18 ms on localhost (59/199)
2017-07-01 18:19:46,130  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:46,136  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 6 ms
2017-07-01 18:19:46,140  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 60.0 in stage 11.0 (TID 73). 1609 bytes result sent to driver
2017-07-01 18:19:46,145  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 61.0 in stage 11.0 (TID 74, localhost, partition 62,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:46,146  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 61.0 in stage 11.0 (TID 74)
2017-07-01 18:19:46,147  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 60.0 in stage 11.0 (TID 73) in 28 ms on localhost (60/199)
2017-07-01 18:19:46,150  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:46,150  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:19:46,152  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 50.0 in stage 11.0 (TID 63). 1609 bytes result sent to driver
2017-07-01 18:19:46,154  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 62.0 in stage 11.0 (TID 75, localhost, partition 63,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:46,155  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 50.0 in stage 11.0 (TID 63) in 206 ms on localhost (61/199)
2017-07-01 18:19:46,161  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:46,164  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:19:46,166  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 62.0 in stage 11.0 (TID 75)
2017-07-01 18:19:46,169  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 61.0 in stage 11.0 (TID 74). 1609 bytes result sent to driver
2017-07-01 18:19:46,176  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 63.0 in stage 11.0 (TID 76, localhost, partition 64,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:46,177  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 63.0 in stage 11.0 (TID 76)
2017-07-01 18:19:46,177  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 61.0 in stage 11.0 (TID 74) in 33 ms on localhost (62/199)
2017-07-01 18:19:46,200  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:46,206  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 6 ms
2017-07-01 18:19:46,210  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:46,212  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:19:46,215  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 63.0 in stage 11.0 (TID 76). 1609 bytes result sent to driver
2017-07-01 18:19:46,218  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 64.0 in stage 11.0 (TID 77, localhost, partition 65,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:46,219  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 63.0 in stage 11.0 (TID 76) in 43 ms on localhost (63/199)
2017-07-01 18:19:46,211  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 62.0 in stage 11.0 (TID 75). 1609 bytes result sent to driver
2017-07-01 18:19:46,222  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 65.0 in stage 11.0 (TID 78, localhost, partition 66,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:46,222  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 65.0 in stage 11.0 (TID 78)
2017-07-01 18:19:46,223  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 62.0 in stage 11.0 (TID 75) in 70 ms on localhost (64/199)
2017-07-01 18:19:46,229  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 64.0 in stage 11.0 (TID 77)
2017-07-01 18:19:46,242  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:46,249  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 7 ms
2017-07-01 18:19:46,252  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 65.0 in stage 11.0 (TID 78). 1609 bytes result sent to driver
2017-07-01 18:19:46,261  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:46,268  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 8 ms
2017-07-01 18:19:46,265  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 66.0 in stage 11.0 (TID 79, localhost, partition 67,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:46,273  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 65.0 in stage 11.0 (TID 78) in 51 ms on localhost (65/199)
2017-07-01 18:19:46,275  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 66.0 in stage 11.0 (TID 79)
2017-07-01 18:19:46,282  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 64.0 in stage 11.0 (TID 77). 1609 bytes result sent to driver
2017-07-01 18:19:46,284  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 67.0 in stage 11.0 (TID 80, localhost, partition 68,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:46,285  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 64.0 in stage 11.0 (TID 77) in 69 ms on localhost (66/199)
2017-07-01 18:19:46,296  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 67.0 in stage 11.0 (TID 80)
2017-07-01 18:19:46,302  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:46,302  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 6 ms
2017-07-01 18:19:46,312  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 66.0 in stage 11.0 (TID 79). 1609 bytes result sent to driver
2017-07-01 18:19:46,320  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 68.0 in stage 11.0 (TID 81, localhost, partition 69,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:46,321  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 66.0 in stage 11.0 (TID 79) in 56 ms on localhost (67/199)
2017-07-01 18:19:46,323  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 68.0 in stage 11.0 (TID 81)
2017-07-01 18:19:46,343  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:46,346  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:19:46,360  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 68.0 in stage 11.0 (TID 81). 1609 bytes result sent to driver
2017-07-01 18:19:46,369  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 69.0 in stage 11.0 (TID 82, localhost, partition 70,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:46,370  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:46,370  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:19:46,372  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 68.0 in stage 11.0 (TID 81) in 52 ms on localhost (68/199)
2017-07-01 18:19:46,373  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 69.0 in stage 11.0 (TID 82)
2017-07-01 18:19:46,376  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 67.0 in stage 11.0 (TID 80). 1609 bytes result sent to driver
2017-07-01 18:19:46,384  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 70.0 in stage 11.0 (TID 83, localhost, partition 71,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:46,384  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 70.0 in stage 11.0 (TID 83)
2017-07-01 18:19:46,390  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:46,391  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:46,392  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 67.0 in stage 11.0 (TID 80) in 106 ms on localhost (69/199)
2017-07-01 18:19:46,395  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:46,395  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:46,397  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 69.0 in stage 11.0 (TID 82). 1609 bytes result sent to driver
2017-07-01 18:19:46,399  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 71.0 in stage 11.0 (TID 84, localhost, partition 72,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:46,399  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 69.0 in stage 11.0 (TID 82) in 37 ms on localhost (70/199)
2017-07-01 18:19:46,401  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 71.0 in stage 11.0 (TID 84)
2017-07-01 18:19:46,403  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 70.0 in stage 11.0 (TID 83). 1609 bytes result sent to driver
2017-07-01 18:19:46,408  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 72.0 in stage 11.0 (TID 85, localhost, partition 73,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:46,409  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 72.0 in stage 11.0 (TID 85)
2017-07-01 18:19:46,411  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 70.0 in stage 11.0 (TID 83) in 28 ms on localhost (71/199)
2017-07-01 18:19:46,427  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:46,434  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 7 ms
2017-07-01 18:19:46,432  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:46,436  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:19:46,443  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 71.0 in stage 11.0 (TID 84). 1609 bytes result sent to driver
2017-07-01 18:19:46,443  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 72.0 in stage 11.0 (TID 85). 1609 bytes result sent to driver
2017-07-01 18:19:46,448  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 73.0 in stage 11.0 (TID 86, localhost, partition 74,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:46,451  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 73.0 in stage 11.0 (TID 86)
2017-07-01 18:19:46,452  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 71.0 in stage 11.0 (TID 84) in 54 ms on localhost (72/199)
2017-07-01 18:19:46,462  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:46,462  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:19:46,464  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 73.0 in stage 11.0 (TID 86). 1609 bytes result sent to driver
2017-07-01 18:19:46,465  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 74.0 in stage 11.0 (TID 87, localhost, partition 75,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:46,471  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 72.0 in stage 11.0 (TID 85) in 63 ms on localhost (73/199)
2017-07-01 18:19:46,473  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 74.0 in stage 11.0 (TID 87)
2017-07-01 18:19:46,481  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 75.0 in stage 11.0 (TID 88, localhost, partition 76,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:46,482  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 73.0 in stage 11.0 (TID 86) in 34 ms on localhost (74/199)
2017-07-01 18:19:46,483  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 75.0 in stage 11.0 (TID 88)
2017-07-01 18:19:46,503  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:46,504  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:46,504  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:46,509  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 5 ms
2017-07-01 18:19:46,510  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 75.0 in stage 11.0 (TID 88). 1609 bytes result sent to driver
2017-07-01 18:19:46,515  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 76.0 in stage 11.0 (TID 89, localhost, partition 77,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:46,515  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 75.0 in stage 11.0 (TID 88) in 34 ms on localhost (75/199)
2017-07-01 18:19:46,516  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 76.0 in stage 11.0 (TID 89)
2017-07-01 18:19:46,512  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 74.0 in stage 11.0 (TID 87). 1609 bytes result sent to driver
2017-07-01 18:19:46,522  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 77.0 in stage 11.0 (TID 90, localhost, partition 78,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:46,523  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 74.0 in stage 11.0 (TID 87) in 59 ms on localhost (76/199)
2017-07-01 18:19:46,525  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 77.0 in stage 11.0 (TID 90)
2017-07-01 18:19:46,526  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:46,530  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:19:46,533  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 76.0 in stage 11.0 (TID 89). 1609 bytes result sent to driver
2017-07-01 18:19:46,536  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 78.0 in stage 11.0 (TID 91, localhost, partition 79,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:46,536  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 78.0 in stage 11.0 (TID 91)
2017-07-01 18:19:46,542  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 76.0 in stage 11.0 (TID 89) in 29 ms on localhost (77/199)
2017-07-01 18:19:46,568  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:46,574  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 7 ms
2017-07-01 18:19:46,578  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:46,578  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:19:46,583  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 77.0 in stage 11.0 (TID 90). 1609 bytes result sent to driver
2017-07-01 18:19:46,587  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 79.0 in stage 11.0 (TID 92, localhost, partition 80,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:46,587  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 79.0 in stage 11.0 (TID 92)
2017-07-01 18:19:46,593  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 77.0 in stage 11.0 (TID 90) in 71 ms on localhost (78/199)
2017-07-01 18:19:46,584  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 78.0 in stage 11.0 (TID 91). 1609 bytes result sent to driver
2017-07-01 18:19:46,595  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 80.0 in stage 11.0 (TID 93, localhost, partition 81,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:46,596  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 78.0 in stage 11.0 (TID 91) in 61 ms on localhost (79/199)
2017-07-01 18:19:46,601  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:46,603  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:19:46,602  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 80.0 in stage 11.0 (TID 93)
2017-07-01 18:19:46,623  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 79.0 in stage 11.0 (TID 92). 1609 bytes result sent to driver
2017-07-01 18:19:46,624  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 81.0 in stage 11.0 (TID 94, localhost, partition 82,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:46,628  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 79.0 in stage 11.0 (TID 92) in 40 ms on localhost (80/199)
2017-07-01 18:19:46,630  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 81.0 in stage 11.0 (TID 94)
2017-07-01 18:19:46,653  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:46,657  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:19:46,660  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:46,670  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 10 ms
2017-07-01 18:19:46,673  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 80.0 in stage 11.0 (TID 93). 1609 bytes result sent to driver
2017-07-01 18:19:46,667  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 81.0 in stage 11.0 (TID 94). 1609 bytes result sent to driver
2017-07-01 18:19:46,678  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 82.0 in stage 11.0 (TID 95, localhost, partition 83,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:46,679  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 80.0 in stage 11.0 (TID 93) in 85 ms on localhost (81/199)
2017-07-01 18:19:46,680  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 82.0 in stage 11.0 (TID 95)
2017-07-01 18:19:46,687  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 83.0 in stage 11.0 (TID 96, localhost, partition 84,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:46,689  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:46,689  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:19:46,691  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 82.0 in stage 11.0 (TID 95). 1609 bytes result sent to driver
2017-07-01 18:19:46,693  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 84.0 in stage 11.0 (TID 97, localhost, partition 85,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:46,694  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 84.0 in stage 11.0 (TID 97)
2017-07-01 18:19:46,691  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Running task 83.0 in stage 11.0 (TID 96)
2017-07-01 18:19:46,699  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 82.0 in stage 11.0 (TID 95) in 20 ms on localhost (82/199)
2017-07-01 18:19:46,699  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 81.0 in stage 11.0 (TID 94) in 75 ms on localhost (83/199)
2017-07-01 18:19:46,722  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:46,725  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:19:46,722  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:46,730  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 8 ms
2017-07-01 18:19:46,731  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 84.0 in stage 11.0 (TID 97). 1609 bytes result sent to driver
2017-07-01 18:19:46,732  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 85.0 in stage 11.0 (TID 98, localhost, partition 86,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:46,736  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 84.0 in stage 11.0 (TID 97) in 44 ms on localhost (84/199)
2017-07-01 18:19:46,737  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 85.0 in stage 11.0 (TID 98)
2017-07-01 18:19:46,747  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:46,748  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:46,749  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 85.0 in stage 11.0 (TID 98). 1609 bytes result sent to driver
2017-07-01 18:19:46,731  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Finished task 83.0 in stage 11.0 (TID 96). 1609 bytes result sent to driver
2017-07-01 18:19:46,762  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 86.0 in stage 11.0 (TID 99, localhost, partition 87,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:46,763  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 85.0 in stage 11.0 (TID 98) in 31 ms on localhost (85/199)
2017-07-01 18:19:46,764  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 86.0 in stage 11.0 (TID 99)
2017-07-01 18:19:46,766  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 87.0 in stage 11.0 (TID 100, localhost, partition 88,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:46,766  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 83.0 in stage 11.0 (TID 96) in 80 ms on localhost (86/199)
2017-07-01 18:19:46,767  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 87.0 in stage 11.0 (TID 100)
2017-07-01 18:19:46,784  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:46,798  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 14 ms
2017-07-01 18:19:46,799  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 87.0 in stage 11.0 (TID 100). 1609 bytes result sent to driver
2017-07-01 18:19:46,793  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:46,802  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 9 ms
2017-07-01 18:19:46,804  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 86.0 in stage 11.0 (TID 99). 1609 bytes result sent to driver
2017-07-01 18:19:46,804  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 88.0 in stage 11.0 (TID 101, localhost, partition 89,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:46,806  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 88.0 in stage 11.0 (TID 101)
2017-07-01 18:19:46,807  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 89.0 in stage 11.0 (TID 102, localhost, partition 90,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:46,807  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Running task 89.0 in stage 11.0 (TID 102)
2017-07-01 18:19:46,810  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 87.0 in stage 11.0 (TID 100) in 44 ms on localhost (87/199)
2017-07-01 18:19:46,810  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 86.0 in stage 11.0 (TID 99) in 48 ms on localhost (88/199)
2017-07-01 18:19:46,816  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:46,816  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:19:46,821  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Finished task 89.0 in stage 11.0 (TID 102). 1609 bytes result sent to driver
2017-07-01 18:19:46,822  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 90.0 in stage 11.0 (TID 103, localhost, partition 91,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:46,823  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 89.0 in stage 11.0 (TID 102) in 17 ms on localhost (89/199)
2017-07-01 18:19:46,824  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 90.0 in stage 11.0 (TID 103)
2017-07-01 18:19:46,840  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:46,845  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 6 ms
2017-07-01 18:19:46,841  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:46,846  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 5 ms
2017-07-01 18:19:46,847  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 88.0 in stage 11.0 (TID 101). 1609 bytes result sent to driver
2017-07-01 18:19:46,848  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 90.0 in stage 11.0 (TID 103). 1609 bytes result sent to driver
2017-07-01 18:19:46,849  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 91.0 in stage 11.0 (TID 104, localhost, partition 92,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:46,850  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Running task 91.0 in stage 11.0 (TID 104)
2017-07-01 18:19:46,850  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 88.0 in stage 11.0 (TID 101) in 46 ms on localhost (90/199)
2017-07-01 18:19:46,860  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 92.0 in stage 11.0 (TID 105, localhost, partition 93,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:46,860  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 90.0 in stage 11.0 (TID 103) in 38 ms on localhost (91/199)
2017-07-01 18:19:46,861  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 92.0 in stage 11.0 (TID 105)
2017-07-01 18:19:46,868  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:46,869  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:46,870  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:46,871  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:46,873  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Finished task 91.0 in stage 11.0 (TID 104). 1609 bytes result sent to driver
2017-07-01 18:19:46,877  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 92.0 in stage 11.0 (TID 105). 1609 bytes result sent to driver
2017-07-01 18:19:46,879  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 93.0 in stage 11.0 (TID 106, localhost, partition 94,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:46,881  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 91.0 in stage 11.0 (TID 104) in 31 ms on localhost (92/199)
2017-07-01 18:19:46,882  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 93.0 in stage 11.0 (TID 106)
2017-07-01 18:19:46,886  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 94.0 in stage 11.0 (TID 107, localhost, partition 95,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:46,887  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 92.0 in stage 11.0 (TID 105) in 28 ms on localhost (93/199)
2017-07-01 18:19:46,888  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 94.0 in stage 11.0 (TID 107)
2017-07-01 18:19:46,899  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:46,899  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:19:46,900  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 94.0 in stage 11.0 (TID 107). 1609 bytes result sent to driver
2017-07-01 18:19:46,905  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:46,906  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:46,907  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 93.0 in stage 11.0 (TID 106). 1609 bytes result sent to driver
2017-07-01 18:19:46,908  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 95.0 in stage 11.0 (TID 108, localhost, partition 96,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:46,909  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 95.0 in stage 11.0 (TID 108)
2017-07-01 18:19:46,912  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 96.0 in stage 11.0 (TID 109, localhost, partition 97,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:46,913  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 94.0 in stage 11.0 (TID 107) in 27 ms on localhost (94/199)
2017-07-01 18:19:46,917  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Running task 96.0 in stage 11.0 (TID 109)
2017-07-01 18:19:46,918  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 93.0 in stage 11.0 (TID 106) in 39 ms on localhost (95/199)
2017-07-01 18:19:46,929  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:46,930  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:46,941  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Finished task 96.0 in stage 11.0 (TID 109). 1609 bytes result sent to driver
2017-07-01 18:19:46,942  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 97.0 in stage 11.0 (TID 110, localhost, partition 98,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:46,945  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 97.0 in stage 11.0 (TID 110)
2017-07-01 18:19:46,945  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 96.0 in stage 11.0 (TID 109) in 33 ms on localhost (96/199)
2017-07-01 18:19:46,961  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:46,964  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:19:46,963  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:46,966  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 10 ms
2017-07-01 18:19:46,971  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 95.0 in stage 11.0 (TID 108). 1609 bytes result sent to driver
2017-07-01 18:19:46,971  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 97.0 in stage 11.0 (TID 110). 1609 bytes result sent to driver
2017-07-01 18:19:46,972  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 98.0 in stage 11.0 (TID 111, localhost, partition 99,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:46,974  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 95.0 in stage 11.0 (TID 108) in 67 ms on localhost (97/199)
2017-07-01 18:19:46,974  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Running task 98.0 in stage 11.0 (TID 111)
2017-07-01 18:19:46,982  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 99.0 in stage 11.0 (TID 112, localhost, partition 100,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:46,982  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 97.0 in stage 11.0 (TID 110) in 40 ms on localhost (98/199)
2017-07-01 18:19:46,983  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 99.0 in stage 11.0 (TID 112)
2017-07-01 18:19:46,993  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:46,993  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:46,995  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:19:46,996  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 99.0 in stage 11.0 (TID 112). 1609 bytes result sent to driver
2017-07-01 18:19:46,997  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 100.0 in stage 11.0 (TID 113, localhost, partition 101,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:46,997  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 99.0 in stage 11.0 (TID 112) in 16 ms on localhost (99/199)
2017-07-01 18:19:46,997  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:19:46,997  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 100.0 in stage 11.0 (TID 113)
2017-07-01 18:19:46,999  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Finished task 98.0 in stage 11.0 (TID 111). 1609 bytes result sent to driver
2017-07-01 18:19:47,004  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 101.0 in stage 11.0 (TID 114, localhost, partition 102,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:47,004  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 98.0 in stage 11.0 (TID 111) in 32 ms on localhost (100/199)
2017-07-01 18:19:47,005  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 101.0 in stage 11.0 (TID 114)
2017-07-01 18:19:47,009  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:47,020  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 12 ms
2017-07-01 18:19:47,023  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 100.0 in stage 11.0 (TID 113). 1609 bytes result sent to driver
2017-07-01 18:19:47,025  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:47,026  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 9 ms
2017-07-01 18:19:47,027  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 101.0 in stage 11.0 (TID 114). 1609 bytes result sent to driver
2017-07-01 18:19:47,028  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 102.0 in stage 11.0 (TID 115, localhost, partition 103,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:47,028  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 102.0 in stage 11.0 (TID 115)
2017-07-01 18:19:47,028  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 103.0 in stage 11.0 (TID 116, localhost, partition 104,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:47,029  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 103.0 in stage 11.0 (TID 116)
2017-07-01 18:19:47,030  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 100.0 in stage 11.0 (TID 113) in 33 ms on localhost (101/199)
2017-07-01 18:19:47,031  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 101.0 in stage 11.0 (TID 114) in 30 ms on localhost (102/199)
2017-07-01 18:19:47,042  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:47,042  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:47,043  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:47,059  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 16 ms
2017-07-01 18:19:47,059  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 103.0 in stage 11.0 (TID 116). 1609 bytes result sent to driver
2017-07-01 18:19:47,061  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 104.0 in stage 11.0 (TID 117, localhost, partition 105,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:47,062  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 103.0 in stage 11.0 (TID 116) in 34 ms on localhost (103/199)
2017-07-01 18:19:47,063  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 104.0 in stage 11.0 (TID 117)
2017-07-01 18:19:47,063  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 102.0 in stage 11.0 (TID 115). 1609 bytes result sent to driver
2017-07-01 18:19:47,066  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 105.0 in stage 11.0 (TID 118, localhost, partition 106,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:47,066  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 105.0 in stage 11.0 (TID 118)
2017-07-01 18:19:47,067  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 102.0 in stage 11.0 (TID 115) in 39 ms on localhost (104/199)
2017-07-01 18:19:47,074  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:47,079  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 5 ms
2017-07-01 18:19:47,076  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:47,079  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:19:47,080  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 104.0 in stage 11.0 (TID 117). 1609 bytes result sent to driver
2017-07-01 18:19:47,080  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 105.0 in stage 11.0 (TID 118). 1609 bytes result sent to driver
2017-07-01 18:19:47,081  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 106.0 in stage 11.0 (TID 119, localhost, partition 107,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:47,082  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 104.0 in stage 11.0 (TID 117) in 21 ms on localhost (105/199)
2017-07-01 18:19:47,083  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Running task 106.0 in stage 11.0 (TID 119)
2017-07-01 18:19:47,087  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 107.0 in stage 11.0 (TID 120, localhost, partition 108,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:47,087  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 107.0 in stage 11.0 (TID 120)
2017-07-01 18:19:47,088  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 105.0 in stage 11.0 (TID 118) in 22 ms on localhost (106/199)
2017-07-01 18:19:47,093  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:47,093  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:19:47,094  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Finished task 106.0 in stage 11.0 (TID 119). 1609 bytes result sent to driver
2017-07-01 18:19:47,097  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 108.0 in stage 11.0 (TID 121, localhost, partition 109,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:47,097  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 106.0 in stage 11.0 (TID 119) in 16 ms on localhost (107/199)
2017-07-01 18:19:47,094  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:47,097  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 108.0 in stage 11.0 (TID 121)
2017-07-01 18:19:47,112  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 18 ms
2017-07-01 18:19:47,114  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 107.0 in stage 11.0 (TID 120). 1609 bytes result sent to driver
2017-07-01 18:19:47,115  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 109.0 in stage 11.0 (TID 122, localhost, partition 110,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:47,116  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 109.0 in stage 11.0 (TID 122)
2017-07-01 18:19:47,116  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 107.0 in stage 11.0 (TID 120) in 30 ms on localhost (108/199)
2017-07-01 18:19:47,126  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:47,126  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:19:47,127  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 108.0 in stage 11.0 (TID 121). 1609 bytes result sent to driver
2017-07-01 18:19:47,128  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 110.0 in stage 11.0 (TID 123, localhost, partition 111,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:47,129  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 108.0 in stage 11.0 (TID 121) in 33 ms on localhost (109/199)
2017-07-01 18:19:47,129  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Running task 110.0 in stage 11.0 (TID 123)
2017-07-01 18:19:47,130  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:47,132  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:19:47,133  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 109.0 in stage 11.0 (TID 122). 1609 bytes result sent to driver
2017-07-01 18:19:47,134  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 111.0 in stage 11.0 (TID 124, localhost, partition 112,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:47,135  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 111.0 in stage 11.0 (TID 124)
2017-07-01 18:19:47,137  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 109.0 in stage 11.0 (TID 122) in 22 ms on localhost (110/199)
2017-07-01 18:19:47,138  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:47,138  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:19:47,140  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Finished task 110.0 in stage 11.0 (TID 123). 1609 bytes result sent to driver
2017-07-01 18:19:47,141  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 112.0 in stage 11.0 (TID 125, localhost, partition 113,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:47,141  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 112.0 in stage 11.0 (TID 125)
2017-07-01 18:19:47,142  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 110.0 in stage 11.0 (TID 123) in 13 ms on localhost (111/199)
2017-07-01 18:19:47,167  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:47,167  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:19:47,169  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:47,169  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:19:47,182  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 112.0 in stage 11.0 (TID 125). 1609 bytes result sent to driver
2017-07-01 18:19:47,185  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 111.0 in stage 11.0 (TID 124). 1609 bytes result sent to driver
2017-07-01 18:19:47,189  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 113.0 in stage 11.0 (TID 126, localhost, partition 114,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:47,191  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Running task 113.0 in stage 11.0 (TID 126)
2017-07-01 18:19:47,192  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 112.0 in stage 11.0 (TID 125) in 51 ms on localhost (112/199)
2017-07-01 18:19:47,195  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 114.0 in stage 11.0 (TID 127, localhost, partition 115,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:47,197  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 111.0 in stage 11.0 (TID 124) in 63 ms on localhost (113/199)
2017-07-01 18:19:47,208  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 114.0 in stage 11.0 (TID 127)
2017-07-01 18:19:47,217  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:47,221  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:19:47,231  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Finished task 113.0 in stage 11.0 (TID 126). 1609 bytes result sent to driver
2017-07-01 18:19:47,232  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 115.0 in stage 11.0 (TID 128, localhost, partition 116,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:47,232  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 113.0 in stage 11.0 (TID 126) in 44 ms on localhost (114/199)
2017-07-01 18:19:47,239  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 115.0 in stage 11.0 (TID 128)
2017-07-01 18:19:47,245  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:47,245  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:19:47,252  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 114.0 in stage 11.0 (TID 127). 1609 bytes result sent to driver
2017-07-01 18:19:47,264  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 116.0 in stage 11.0 (TID 129, localhost, partition 117,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:47,265  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Running task 116.0 in stage 11.0 (TID 129)
2017-07-01 18:19:47,265  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 114.0 in stage 11.0 (TID 127) in 70 ms on localhost (115/199)
2017-07-01 18:19:47,273  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:47,278  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 5 ms
2017-07-01 18:19:47,280  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 115.0 in stage 11.0 (TID 128). 1609 bytes result sent to driver
2017-07-01 18:19:47,276  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:47,281  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 5 ms
2017-07-01 18:19:47,283  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Finished task 116.0 in stage 11.0 (TID 129). 1609 bytes result sent to driver
2017-07-01 18:19:47,283  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 117.0 in stage 11.0 (TID 130, localhost, partition 118,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:47,286  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 115.0 in stage 11.0 (TID 128) in 55 ms on localhost (116/199)
2017-07-01 18:19:47,293  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 117.0 in stage 11.0 (TID 130)
2017-07-01 18:19:47,296  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 118.0 in stage 11.0 (TID 131, localhost, partition 119,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:47,298  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 116.0 in stage 11.0 (TID 129) in 33 ms on localhost (117/199)
2017-07-01 18:19:47,299  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 118.0 in stage 11.0 (TID 131)
2017-07-01 18:19:47,308  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:47,311  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:19:47,317  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 118.0 in stage 11.0 (TID 131). 1609 bytes result sent to driver
2017-07-01 18:19:47,318  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 119.0 in stage 11.0 (TID 132, localhost, partition 120,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:47,319  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 118.0 in stage 11.0 (TID 131) in 24 ms on localhost (118/199)
2017-07-01 18:19:47,322  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Running task 119.0 in stage 11.0 (TID 132)
2017-07-01 18:19:47,332  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:47,332  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:19:47,338  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:47,338  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:19:47,342  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Finished task 119.0 in stage 11.0 (TID 132). 1609 bytes result sent to driver
2017-07-01 18:19:47,343  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 120.0 in stage 11.0 (TID 133, localhost, partition 121,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:47,343  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 120.0 in stage 11.0 (TID 133)
2017-07-01 18:19:47,347  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 119.0 in stage 11.0 (TID 132) in 27 ms on localhost (119/199)
2017-07-01 18:19:47,354  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 117.0 in stage 11.0 (TID 130). 1609 bytes result sent to driver
2017-07-01 18:19:47,355  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 121.0 in stage 11.0 (TID 134, localhost, partition 122,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:47,356  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 117.0 in stage 11.0 (TID 130) in 73 ms on localhost (120/199)
2017-07-01 18:19:47,357  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Running task 121.0 in stage 11.0 (TID 134)
2017-07-01 18:19:47,365  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:47,366  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:47,368  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 120.0 in stage 11.0 (TID 133). 1609 bytes result sent to driver
2017-07-01 18:19:47,371  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 122.0 in stage 11.0 (TID 135, localhost, partition 123,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:47,372  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 120.0 in stage 11.0 (TID 133) in 29 ms on localhost (121/199)
2017-07-01 18:19:47,372  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 122.0 in stage 11.0 (TID 135)
2017-07-01 18:19:47,379  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:47,380  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:47,380  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:19:47,382  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:47,387  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Finished task 121.0 in stage 11.0 (TID 134). 1609 bytes result sent to driver
2017-07-01 18:19:47,388  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 123.0 in stage 11.0 (TID 136, localhost, partition 124,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:47,389  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 121.0 in stage 11.0 (TID 134) in 34 ms on localhost (122/199)
2017-07-01 18:19:47,391  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 123.0 in stage 11.0 (TID 136)
2017-07-01 18:19:47,396  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 122.0 in stage 11.0 (TID 135). 1609 bytes result sent to driver
2017-07-01 18:19:47,398  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 124.0 in stage 11.0 (TID 137, localhost, partition 125,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:47,398  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 122.0 in stage 11.0 (TID 135) in 29 ms on localhost (123/199)
2017-07-01 18:19:47,399  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Running task 124.0 in stage 11.0 (TID 137)
2017-07-01 18:19:47,402  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:47,404  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:19:47,409  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 123.0 in stage 11.0 (TID 136). 1609 bytes result sent to driver
2017-07-01 18:19:47,412  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 125.0 in stage 11.0 (TID 138, localhost, partition 126,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:47,413  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 123.0 in stage 11.0 (TID 136) in 24 ms on localhost (124/199)
2017-07-01 18:19:47,413  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 125.0 in stage 11.0 (TID 138)
2017-07-01 18:19:47,423  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:47,424  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:47,430  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:47,431  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:47,435  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Finished task 124.0 in stage 11.0 (TID 137). 1609 bytes result sent to driver
2017-07-01 18:19:47,437  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 126.0 in stage 11.0 (TID 139, localhost, partition 127,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:47,438  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 124.0 in stage 11.0 (TID 137) in 40 ms on localhost (125/199)
2017-07-01 18:19:47,438  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 126.0 in stage 11.0 (TID 139)
2017-07-01 18:19:47,444  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:47,444  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:19:47,449  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 125.0 in stage 11.0 (TID 138). 1609 bytes result sent to driver
2017-07-01 18:19:47,450  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 127.0 in stage 11.0 (TID 140, localhost, partition 128,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:47,450  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 125.0 in stage 11.0 (TID 138) in 38 ms on localhost (126/199)
2017-07-01 18:19:47,451  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Running task 127.0 in stage 11.0 (TID 140)
2017-07-01 18:19:47,458  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 126.0 in stage 11.0 (TID 139). 1609 bytes result sent to driver
2017-07-01 18:19:47,458  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 128.0 in stage 11.0 (TID 141, localhost, partition 129,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:47,459  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 126.0 in stage 11.0 (TID 139) in 23 ms on localhost (127/199)
2017-07-01 18:19:47,459  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 128.0 in stage 11.0 (TID 141)
2017-07-01 18:19:47,463  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:47,463  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:47,464  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Finished task 127.0 in stage 11.0 (TID 140). 1609 bytes result sent to driver
2017-07-01 18:19:47,466  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 129.0 in stage 11.0 (TID 142, localhost, partition 130,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:47,467  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 127.0 in stage 11.0 (TID 140) in 18 ms on localhost (128/199)
2017-07-01 18:19:47,468  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 129.0 in stage 11.0 (TID 142)
2017-07-01 18:19:47,486  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:47,488  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:47,489  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:47,489  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:19:47,492  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 128.0 in stage 11.0 (TID 141). 1609 bytes result sent to driver
2017-07-01 18:19:47,502  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 130.0 in stage 11.0 (TID 143, localhost, partition 131,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:47,502  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 128.0 in stage 11.0 (TID 141) in 44 ms on localhost (129/199)
2017-07-01 18:19:47,503  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 129.0 in stage 11.0 (TID 142). 1609 bytes result sent to driver
2017-07-01 18:19:47,504  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 130.0 in stage 11.0 (TID 143)
2017-07-01 18:19:47,508  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 131.0 in stage 11.0 (TID 144, localhost, partition 132,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:47,510  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 129.0 in stage 11.0 (TID 142) in 44 ms on localhost (130/199)
2017-07-01 18:19:47,532  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 131.0 in stage 11.0 (TID 144)
2017-07-01 18:19:47,532  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:47,532  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 6 ms
2017-07-01 18:19:47,540  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 130.0 in stage 11.0 (TID 143). 1609 bytes result sent to driver
2017-07-01 18:19:47,551  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 132.0 in stage 11.0 (TID 145, localhost, partition 133,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:47,551  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 130.0 in stage 11.0 (TID 143) in 50 ms on localhost (131/199)
2017-07-01 18:19:47,557  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 132.0 in stage 11.0 (TID 145)
2017-07-01 18:19:47,571  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:47,580  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 9 ms
2017-07-01 18:19:47,597  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 131.0 in stage 11.0 (TID 144). 1609 bytes result sent to driver
2017-07-01 18:19:47,602  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 133.0 in stage 11.0 (TID 146, localhost, partition 134,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:47,603  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 131.0 in stage 11.0 (TID 144) in 95 ms on localhost (132/199)
2017-07-01 18:19:47,604  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 133.0 in stage 11.0 (TID 146)
2017-07-01 18:19:47,584  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:47,610  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 25 ms
2017-07-01 18:19:47,611  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 132.0 in stage 11.0 (TID 145). 1609 bytes result sent to driver
2017-07-01 18:19:47,614  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 134.0 in stage 11.0 (TID 147, localhost, partition 135,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:47,615  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Running task 134.0 in stage 11.0 (TID 147)
2017-07-01 18:19:47,619  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 132.0 in stage 11.0 (TID 145) in 68 ms on localhost (133/199)
2017-07-01 18:19:47,627  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:47,637  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 10 ms
2017-07-01 18:19:47,633  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:47,641  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 8 ms
2017-07-01 18:19:47,642  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Finished task 134.0 in stage 11.0 (TID 147). 1609 bytes result sent to driver
2017-07-01 18:19:47,640  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 133.0 in stage 11.0 (TID 146). 1609 bytes result sent to driver
2017-07-01 18:19:47,650  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 135.0 in stage 11.0 (TID 148, localhost, partition 136,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:47,656  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 136.0 in stage 11.0 (TID 149, localhost, partition 137,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:47,658  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 134.0 in stage 11.0 (TID 147) in 43 ms on localhost (134/199)
2017-07-01 18:19:47,658  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 133.0 in stage 11.0 (TID 146) in 57 ms on localhost (135/199)
2017-07-01 18:19:47,660  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 135.0 in stage 11.0 (TID 148)
2017-07-01 18:19:47,673  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Running task 136.0 in stage 11.0 (TID 149)
2017-07-01 18:19:47,674  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:47,687  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 13 ms
2017-07-01 18:19:47,688  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 135.0 in stage 11.0 (TID 148). 1609 bytes result sent to driver
2017-07-01 18:19:47,694  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 137.0 in stage 11.0 (TID 150, localhost, partition 138,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:47,694  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 135.0 in stage 11.0 (TID 148) in 45 ms on localhost (136/199)
2017-07-01 18:19:47,695  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 137.0 in stage 11.0 (TID 150)
2017-07-01 18:19:47,701  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:47,701  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:47,703  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Finished task 136.0 in stage 11.0 (TID 149). 1609 bytes result sent to driver
2017-07-01 18:19:47,704  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 138.0 in stage 11.0 (TID 151, localhost, partition 139,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:47,705  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 136.0 in stage 11.0 (TID 149) in 49 ms on localhost (137/199)
2017-07-01 18:19:47,706  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Running task 138.0 in stage 11.0 (TID 151)
2017-07-01 18:19:47,728  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:47,731  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:19:47,733  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 137.0 in stage 11.0 (TID 150). 1609 bytes result sent to driver
2017-07-01 18:19:47,735  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 139.0 in stage 11.0 (TID 152, localhost, partition 140,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:47,735  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 137.0 in stage 11.0 (TID 150) in 41 ms on localhost (138/199)
2017-07-01 18:19:47,742  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 139.0 in stage 11.0 (TID 152)
2017-07-01 18:19:47,762  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:47,762  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:19:47,764  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 139.0 in stage 11.0 (TID 152). 1609 bytes result sent to driver
2017-07-01 18:19:47,766  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 140.0 in stage 11.0 (TID 153, localhost, partition 141,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:47,767  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 140.0 in stage 11.0 (TID 153)
2017-07-01 18:19:47,767  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 139.0 in stage 11.0 (TID 152) in 33 ms on localhost (139/199)
2017-07-01 18:19:47,779  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:47,786  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 7 ms
2017-07-01 18:19:47,787  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 140.0 in stage 11.0 (TID 153). 1609 bytes result sent to driver
2017-07-01 18:19:47,795  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 141.0 in stage 11.0 (TID 154, localhost, partition 142,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:47,795  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 140.0 in stage 11.0 (TID 153) in 30 ms on localhost (140/199)
2017-07-01 18:19:47,798  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 141.0 in stage 11.0 (TID 154)
2017-07-01 18:19:47,785  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:47,800  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 16 ms
2017-07-01 18:19:47,802  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Finished task 138.0 in stage 11.0 (TID 151). 1609 bytes result sent to driver
2017-07-01 18:19:47,803  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 142.0 in stage 11.0 (TID 155, localhost, partition 143,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:47,804  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Running task 142.0 in stage 11.0 (TID 155)
2017-07-01 18:19:47,818  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:47,830  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 12 ms
2017-07-01 18:19:47,821  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 138.0 in stage 11.0 (TID 151) in 117 ms on localhost (141/199)
2017-07-01 18:19:47,834  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:47,834  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:19:47,843  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 141.0 in stage 11.0 (TID 154). 1609 bytes result sent to driver
2017-07-01 18:19:47,850  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 143.0 in stage 11.0 (TID 156, localhost, partition 144,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:47,851  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 141.0 in stage 11.0 (TID 154) in 57 ms on localhost (142/199)
2017-07-01 18:19:47,852  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Finished task 142.0 in stage 11.0 (TID 155). 1609 bytes result sent to driver
2017-07-01 18:19:47,851  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 143.0 in stage 11.0 (TID 156)
2017-07-01 18:19:47,858  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 144.0 in stage 11.0 (TID 157, localhost, partition 145,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:47,859  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 142.0 in stage 11.0 (TID 155) in 56 ms on localhost (143/199)
2017-07-01 18:19:47,865  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 144.0 in stage 11.0 (TID 157)
2017-07-01 18:19:47,880  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:47,892  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 12 ms
2017-07-01 18:19:47,897  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 144.0 in stage 11.0 (TID 157). 1609 bytes result sent to driver
2017-07-01 18:19:47,881  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:47,902  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 22 ms
2017-07-01 18:19:47,903  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 143.0 in stage 11.0 (TID 156). 1609 bytes result sent to driver
2017-07-01 18:19:47,909  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 145.0 in stage 11.0 (TID 158, localhost, partition 146,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:47,910  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Running task 145.0 in stage 11.0 (TID 158)
2017-07-01 18:19:47,911  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 143.0 in stage 11.0 (TID 156) in 61 ms on localhost (144/199)
2017-07-01 18:19:47,927  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:47,928  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:47,934  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 146.0 in stage 11.0 (TID 159, localhost, partition 147,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:47,934  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 144.0 in stage 11.0 (TID 157) in 76 ms on localhost (145/199)
2017-07-01 18:19:47,935  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 146.0 in stage 11.0 (TID 159)
2017-07-01 18:19:47,950  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Finished task 145.0 in stage 11.0 (TID 158). 1609 bytes result sent to driver
2017-07-01 18:19:47,952  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 147.0 in stage 11.0 (TID 160, localhost, partition 148,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:47,953  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 145.0 in stage 11.0 (TID 158) in 45 ms on localhost (146/199)
2017-07-01 18:19:47,958  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 147.0 in stage 11.0 (TID 160)
2017-07-01 18:19:47,979  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:47,989  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 10 ms
2017-07-01 18:19:47,995  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 146.0 in stage 11.0 (TID 159). 1609 bytes result sent to driver
2017-07-01 18:19:48,002  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 148.0 in stage 11.0 (TID 161, localhost, partition 149,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:48,003  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 146.0 in stage 11.0 (TID 159) in 70 ms on localhost (147/199)
2017-07-01 18:19:48,004  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Running task 148.0 in stage 11.0 (TID 161)
2017-07-01 18:19:48,014  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:47,991  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:48,014  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 23 ms
2017-07-01 18:19:48,018  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:19:48,022  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 147.0 in stage 11.0 (TID 160). 1609 bytes result sent to driver
2017-07-01 18:19:48,030  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Finished task 148.0 in stage 11.0 (TID 161). 1609 bytes result sent to driver
2017-07-01 18:19:48,031  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 149.0 in stage 11.0 (TID 162, localhost, partition 150,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:48,032  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 148.0 in stage 11.0 (TID 161) in 30 ms on localhost (148/199)
2017-07-01 18:19:48,036  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 149.0 in stage 11.0 (TID 162)
2017-07-01 18:19:48,046  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 150.0 in stage 11.0 (TID 163, localhost, partition 151,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:48,046  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 147.0 in stage 11.0 (TID 160) in 94 ms on localhost (149/199)
2017-07-01 18:19:48,047  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Running task 150.0 in stage 11.0 (TID 163)
2017-07-01 18:19:48,067  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:48,067  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:48,078  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 149.0 in stage 11.0 (TID 162). 1609 bytes result sent to driver
2017-07-01 18:19:48,079  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 151.0 in stage 11.0 (TID 164, localhost, partition 152,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:48,079  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 151.0 in stage 11.0 (TID 164)
2017-07-01 18:19:48,079  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 149.0 in stage 11.0 (TID 162) in 49 ms on localhost (150/199)
2017-07-01 18:19:48,098  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:48,099  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:48,103  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:48,104  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:48,113  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Finished task 150.0 in stage 11.0 (TID 163). 1609 bytes result sent to driver
2017-07-01 18:19:48,118  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 152.0 in stage 11.0 (TID 165, localhost, partition 153,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:48,119  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 150.0 in stage 11.0 (TID 163) in 74 ms on localhost (151/199)
2017-07-01 18:19:48,120  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 152.0 in stage 11.0 (TID 165)
2017-07-01 18:19:48,143  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:48,157  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 14 ms
2017-07-01 18:19:48,172  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 151.0 in stage 11.0 (TID 164). 1965 bytes result sent to driver
2017-07-01 18:19:48,172  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 152.0 in stage 11.0 (TID 165). 1609 bytes result sent to driver
2017-07-01 18:19:48,173  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 153.0 in stage 11.0 (TID 166, localhost, partition 154,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:48,177  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Running task 153.0 in stage 11.0 (TID 166)
2017-07-01 18:19:48,178  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 151.0 in stage 11.0 (TID 164) in 100 ms on localhost (152/199)
2017-07-01 18:19:48,189  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:48,192  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:19:48,194  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 154.0 in stage 11.0 (TID 167, localhost, partition 155,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:48,195  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 152.0 in stage 11.0 (TID 165) in 76 ms on localhost (153/199)
2017-07-01 18:19:48,195  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 154.0 in stage 11.0 (TID 167)
2017-07-01 18:19:48,202  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Finished task 153.0 in stage 11.0 (TID 166). 1609 bytes result sent to driver
2017-07-01 18:19:48,210  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 155.0 in stage 11.0 (TID 168, localhost, partition 156,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:48,210  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 155.0 in stage 11.0 (TID 168)
2017-07-01 18:19:48,210  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 153.0 in stage 11.0 (TID 166) in 38 ms on localhost (154/199)
2017-07-01 18:19:48,242  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:48,243  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:48,246  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:48,247  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:48,248  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 154.0 in stage 11.0 (TID 167). 1609 bytes result sent to driver
2017-07-01 18:19:48,257  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 156.0 in stage 11.0 (TID 169, localhost, partition 157,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:48,262  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 154.0 in stage 11.0 (TID 167) in 69 ms on localhost (155/199)
2017-07-01 18:19:48,262  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Running task 156.0 in stage 11.0 (TID 169)
2017-07-01 18:19:48,272  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:48,272  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:19:48,273  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Finished task 156.0 in stage 11.0 (TID 169). 1609 bytes result sent to driver
2017-07-01 18:19:48,256  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 155.0 in stage 11.0 (TID 168). 1609 bytes result sent to driver
2017-07-01 18:19:48,275  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 157.0 in stage 11.0 (TID 170, localhost, partition 158,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:48,278  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 156.0 in stage 11.0 (TID 169) in 22 ms on localhost (156/199)
2017-07-01 18:19:48,279  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 157.0 in stage 11.0 (TID 170)
2017-07-01 18:19:48,287  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 158.0 in stage 11.0 (TID 171, localhost, partition 159,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:48,288  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Running task 158.0 in stage 11.0 (TID 171)
2017-07-01 18:19:48,294  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 155.0 in stage 11.0 (TID 168) in 85 ms on localhost (157/199)
2017-07-01 18:19:48,319  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:48,329  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 10 ms
2017-07-01 18:19:48,325  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:48,330  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 5 ms
2017-07-01 18:19:48,338  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 157.0 in stage 11.0 (TID 170). 1609 bytes result sent to driver
2017-07-01 18:19:48,338  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Finished task 158.0 in stage 11.0 (TID 171). 1609 bytes result sent to driver
2017-07-01 18:19:48,340  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 159.0 in stage 11.0 (TID 172, localhost, partition 160,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:48,340  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 159.0 in stage 11.0 (TID 172)
2017-07-01 18:19:48,342  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 157.0 in stage 11.0 (TID 170) in 68 ms on localhost (158/199)
2017-07-01 18:19:48,351  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:48,351  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:19:48,353  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 159.0 in stage 11.0 (TID 172). 1609 bytes result sent to driver
2017-07-01 18:19:48,358  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 160.0 in stage 11.0 (TID 173, localhost, partition 161,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:48,360  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 158.0 in stage 11.0 (TID 171) in 74 ms on localhost (159/199)
2017-07-01 18:19:48,360  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Running task 160.0 in stage 11.0 (TID 173)
2017-07-01 18:19:48,366  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 161.0 in stage 11.0 (TID 174, localhost, partition 162,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:48,368  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 159.0 in stage 11.0 (TID 172) in 28 ms on localhost (160/199)
2017-07-01 18:19:48,368  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 161.0 in stage 11.0 (TID 174)
2017-07-01 18:19:48,394  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:48,395  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:48,404  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:48,410  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 7 ms
2017-07-01 18:19:48,410  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 161.0 in stage 11.0 (TID 174). 1609 bytes result sent to driver
2017-07-01 18:19:48,412  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 162.0 in stage 11.0 (TID 175, localhost, partition 163,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:48,415  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 162.0 in stage 11.0 (TID 175)
2017-07-01 18:19:48,417  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 161.0 in stage 11.0 (TID 174) in 47 ms on localhost (161/199)
2017-07-01 18:19:48,427  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:48,429  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:19:48,436  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Finished task 160.0 in stage 11.0 (TID 173). 1609 bytes result sent to driver
2017-07-01 18:19:48,437  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 163.0 in stage 11.0 (TID 176, localhost, partition 164,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:48,437  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 160.0 in stage 11.0 (TID 173) in 80 ms on localhost (162/199)
2017-07-01 18:19:48,442  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 163.0 in stage 11.0 (TID 176)
2017-07-01 18:19:48,450  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 162.0 in stage 11.0 (TID 175). 1609 bytes result sent to driver
2017-07-01 18:19:48,450  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 164.0 in stage 11.0 (TID 177, localhost, partition 165,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:48,451  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 162.0 in stage 11.0 (TID 175) in 39 ms on localhost (163/199)
2017-07-01 18:19:48,452  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Running task 164.0 in stage 11.0 (TID 177)
2017-07-01 18:19:48,464  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:48,480  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 16 ms
2017-07-01 18:19:48,479  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:48,485  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 6 ms
2017-07-01 18:19:48,487  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 163.0 in stage 11.0 (TID 176). 1609 bytes result sent to driver
2017-07-01 18:19:48,488  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Finished task 164.0 in stage 11.0 (TID 177). 1609 bytes result sent to driver
2017-07-01 18:19:48,492  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 165.0 in stage 11.0 (TID 178, localhost, partition 166,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:48,493  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 165.0 in stage 11.0 (TID 178)
2017-07-01 18:19:48,494  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 163.0 in stage 11.0 (TID 176) in 57 ms on localhost (164/199)
2017-07-01 18:19:48,506  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:48,506  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:48,507  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 165.0 in stage 11.0 (TID 178). 1609 bytes result sent to driver
2017-07-01 18:19:48,514  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 166.0 in stage 11.0 (TID 179, localhost, partition 167,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:48,515  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 166.0 in stage 11.0 (TID 179)
2017-07-01 18:19:48,517  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 167.0 in stage 11.0 (TID 180, localhost, partition 168,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:48,520  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Running task 167.0 in stage 11.0 (TID 180)
2017-07-01 18:19:48,522  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 165.0 in stage 11.0 (TID 178) in 30 ms on localhost (165/199)
2017-07-01 18:19:48,523  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 164.0 in stage 11.0 (TID 177) in 73 ms on localhost (166/199)
2017-07-01 18:19:48,548  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:48,548  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:19:48,554  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:48,554  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:19:48,556  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 166.0 in stage 11.0 (TID 179). 1609 bytes result sent to driver
2017-07-01 18:19:48,565  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 168.0 in stage 11.0 (TID 181, localhost, partition 169,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:48,568  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 168.0 in stage 11.0 (TID 181)
2017-07-01 18:19:48,570  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 166.0 in stage 11.0 (TID 179) in 56 ms on localhost (167/199)
2017-07-01 18:19:48,586  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:48,586  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:48,587  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 168.0 in stage 11.0 (TID 181). 1609 bytes result sent to driver
2017-07-01 18:19:48,563  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Finished task 167.0 in stage 11.0 (TID 180). 1609 bytes result sent to driver
2017-07-01 18:19:48,588  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 169.0 in stage 11.0 (TID 182, localhost, partition 170,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:48,593  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 168.0 in stage 11.0 (TID 181) in 29 ms on localhost (168/199)
2017-07-01 18:19:48,594  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 169.0 in stage 11.0 (TID 182)
2017-07-01 18:19:48,605  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 170.0 in stage 11.0 (TID 183, localhost, partition 171,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:48,608  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 167.0 in stage 11.0 (TID 180) in 92 ms on localhost (169/199)
2017-07-01 18:19:48,610  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 170.0 in stage 11.0 (TID 183)
2017-07-01 18:19:48,623  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:48,631  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 8 ms
2017-07-01 18:19:48,630  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:48,631  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:48,644  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 169.0 in stage 11.0 (TID 182). 1609 bytes result sent to driver
2017-07-01 18:19:48,650  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 171.0 in stage 11.0 (TID 184, localhost, partition 172,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:48,650  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 169.0 in stage 11.0 (TID 182) in 62 ms on localhost (170/199)
2017-07-01 18:19:48,651  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Running task 171.0 in stage 11.0 (TID 184)
2017-07-01 18:19:48,660  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:48,660  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:19:48,666  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Finished task 171.0 in stage 11.0 (TID 184). 1609 bytes result sent to driver
2017-07-01 18:19:48,666  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 170.0 in stage 11.0 (TID 183). 1609 bytes result sent to driver
2017-07-01 18:19:48,667  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 172.0 in stage 11.0 (TID 185, localhost, partition 173,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:48,668  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 171.0 in stage 11.0 (TID 184) in 18 ms on localhost (171/199)
2017-07-01 18:19:48,672  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 172.0 in stage 11.0 (TID 185)
2017-07-01 18:19:48,674  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 173.0 in stage 11.0 (TID 186, localhost, partition 174,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:48,675  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 170.0 in stage 11.0 (TID 183) in 70 ms on localhost (172/199)
2017-07-01 18:19:48,690  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Running task 173.0 in stage 11.0 (TID 186)
2017-07-01 18:19:48,700  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:48,700  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:19:48,711  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:48,721  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 10 ms
2017-07-01 18:19:48,719  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 172.0 in stage 11.0 (TID 185). 1609 bytes result sent to driver
2017-07-01 18:19:48,729  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 174.0 in stage 11.0 (TID 187, localhost, partition 175,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:48,730  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 174.0 in stage 11.0 (TID 187)
2017-07-01 18:19:48,730  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 172.0 in stage 11.0 (TID 185) in 64 ms on localhost (173/199)
2017-07-01 18:19:48,752  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:48,752  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:19:48,754  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Finished task 173.0 in stage 11.0 (TID 186). 1609 bytes result sent to driver
2017-07-01 18:19:48,755  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 174.0 in stage 11.0 (TID 187). 1609 bytes result sent to driver
2017-07-01 18:19:48,762  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 175.0 in stage 11.0 (TID 188, localhost, partition 176,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:48,763  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 173.0 in stage 11.0 (TID 186) in 89 ms on localhost (174/199)
2017-07-01 18:19:48,763  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 175.0 in stage 11.0 (TID 188)
2017-07-01 18:19:48,772  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 176.0 in stage 11.0 (TID 189, localhost, partition 177,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:48,773  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 174.0 in stage 11.0 (TID 187) in 44 ms on localhost (175/199)
2017-07-01 18:19:48,777  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Running task 176.0 in stage 11.0 (TID 189)
2017-07-01 18:19:48,790  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:48,790  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:19:48,799  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 175.0 in stage 11.0 (TID 188). 1609 bytes result sent to driver
2017-07-01 18:19:48,804  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:48,806  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 177.0 in stage 11.0 (TID 190, localhost, partition 178,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:48,810  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 175.0 in stage 11.0 (TID 188) in 48 ms on localhost (176/199)
2017-07-01 18:19:48,811  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 7 ms
2017-07-01 18:19:48,812  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 177.0 in stage 11.0 (TID 190)
2017-07-01 18:19:48,826  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Finished task 176.0 in stage 11.0 (TID 189). 1609 bytes result sent to driver
2017-07-01 18:19:48,827  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 178.0 in stage 11.0 (TID 191, localhost, partition 179,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:48,827  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 176.0 in stage 11.0 (TID 189) in 56 ms on localhost (177/199)
2017-07-01 18:19:48,828  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 178.0 in stage 11.0 (TID 191)
2017-07-01 18:19:48,842  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:48,843  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:48,844  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 178.0 in stage 11.0 (TID 191). 1609 bytes result sent to driver
2017-07-01 18:19:48,849  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 179.0 in stage 11.0 (TID 192, localhost, partition 180,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:48,850  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Running task 179.0 in stage 11.0 (TID 192)
2017-07-01 18:19:48,852  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 178.0 in stage 11.0 (TID 191) in 25 ms on localhost (178/199)
2017-07-01 18:19:48,890  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:48,893  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:19:48,899  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 177.0 in stage 11.0 (TID 190). 1609 bytes result sent to driver
2017-07-01 18:19:48,906  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 180.0 in stage 11.0 (TID 193, localhost, partition 181,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:48,907  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 180.0 in stage 11.0 (TID 193)
2017-07-01 18:19:48,908  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 177.0 in stage 11.0 (TID 190) in 103 ms on localhost (179/199)
2017-07-01 18:19:48,922  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:48,929  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 7 ms
2017-07-01 18:19:48,900  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:48,931  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 31 ms
2017-07-01 18:19:48,932  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Finished task 179.0 in stage 11.0 (TID 192). 1609 bytes result sent to driver
2017-07-01 18:19:48,937  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 181.0 in stage 11.0 (TID 194, localhost, partition 182,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:48,939  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 179.0 in stage 11.0 (TID 192) in 90 ms on localhost (180/199)
2017-07-01 18:19:48,941  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 181.0 in stage 11.0 (TID 194)
2017-07-01 18:19:48,952  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 180.0 in stage 11.0 (TID 193). 1609 bytes result sent to driver
2017-07-01 18:19:48,956  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 182.0 in stage 11.0 (TID 195, localhost, partition 183,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:48,957  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 180.0 in stage 11.0 (TID 193) in 51 ms on localhost (181/199)
2017-07-01 18:19:48,957  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Running task 182.0 in stage 11.0 (TID 195)
2017-07-01 18:19:48,968  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:48,982  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 14 ms
2017-07-01 18:19:48,983  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 181.0 in stage 11.0 (TID 194). 1609 bytes result sent to driver
2017-07-01 18:19:48,990  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 183.0 in stage 11.0 (TID 196, localhost, partition 184,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:48,990  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 183.0 in stage 11.0 (TID 196)
2017-07-01 18:19:48,999  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 181.0 in stage 11.0 (TID 194) in 66 ms on localhost (182/199)
2017-07-01 18:19:49,005  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:49,010  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 24 ms
2017-07-01 18:19:49,018  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:49,021  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:19:49,025  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Finished task 182.0 in stage 11.0 (TID 195). 1609 bytes result sent to driver
2017-07-01 18:19:49,026  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 184.0 in stage 11.0 (TID 197, localhost, partition 185,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:49,027  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 182.0 in stage 11.0 (TID 195) in 71 ms on localhost (183/199)
2017-07-01 18:19:49,032  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 184.0 in stage 11.0 (TID 197)
2017-07-01 18:19:49,041  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 183.0 in stage 11.0 (TID 196). 1609 bytes result sent to driver
2017-07-01 18:19:49,042  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 185.0 in stage 11.0 (TID 198, localhost, partition 186,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:49,043  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 183.0 in stage 11.0 (TID 196) in 54 ms on localhost (184/199)
2017-07-01 18:19:49,049  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Running task 185.0 in stage 11.0 (TID 198)
2017-07-01 18:19:49,063  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:49,070  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 7 ms
2017-07-01 18:19:49,071  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 184.0 in stage 11.0 (TID 197). 1609 bytes result sent to driver
2017-07-01 18:19:49,074  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 186.0 in stage 11.0 (TID 199, localhost, partition 187,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:49,075  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 186.0 in stage 11.0 (TID 199)
2017-07-01 18:19:49,084  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 184.0 in stage 11.0 (TID 197) in 58 ms on localhost (185/199)
2017-07-01 18:19:49,091  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:49,092  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:49,094  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:49,109  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 15 ms
2017-07-01 18:19:49,103  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Finished task 185.0 in stage 11.0 (TID 198). 1609 bytes result sent to driver
2017-07-01 18:19:49,110  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 187.0 in stage 11.0 (TID 200, localhost, partition 188,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:49,110  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 187.0 in stage 11.0 (TID 200)
2017-07-01 18:19:49,111  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 185.0 in stage 11.0 (TID 198) in 68 ms on localhost (186/199)
2017-07-01 18:19:49,137  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 186.0 in stage 11.0 (TID 199). 1609 bytes result sent to driver
2017-07-01 18:19:49,138  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 188.0 in stage 11.0 (TID 201, localhost, partition 189,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:49,139  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 186.0 in stage 11.0 (TID 199) in 67 ms on localhost (187/199)
2017-07-01 18:19:49,142  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Running task 188.0 in stage 11.0 (TID 201)
2017-07-01 18:19:49,173  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:49,179  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 54 ms
2017-07-01 18:19:49,190  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:49,193  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:19:49,191  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 187.0 in stage 11.0 (TID 200). 1609 bytes result sent to driver
2017-07-01 18:19:49,195  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 189.0 in stage 11.0 (TID 202, localhost, partition 190,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:49,198  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 187.0 in stage 11.0 (TID 200) in 89 ms on localhost (188/199)
2017-07-01 18:19:49,199  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 189.0 in stage 11.0 (TID 202)
2017-07-01 18:19:49,224  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Finished task 188.0 in stage 11.0 (TID 201). 1609 bytes result sent to driver
2017-07-01 18:19:49,230  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:49,230  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 190.0 in stage 11.0 (TID 203, localhost, partition 191,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:49,232  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Running task 190.0 in stage 11.0 (TID 203)
2017-07-01 18:19:49,236  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 21 ms
2017-07-01 18:19:49,243  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 188.0 in stage 11.0 (TID 201) in 106 ms on localhost (189/199)
2017-07-01 18:19:49,251  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 189.0 in stage 11.0 (TID 202). 1609 bytes result sent to driver
2017-07-01 18:19:49,252  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 191.0 in stage 11.0 (TID 204, localhost, partition 192,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:49,252  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 189.0 in stage 11.0 (TID 202) in 58 ms on localhost (190/199)
2017-07-01 18:19:49,265  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 191.0 in stage 11.0 (TID 204)
2017-07-01 18:19:49,295  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:49,314  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 19 ms
2017-07-01 18:19:49,313  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:49,315  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 9 ms
2017-07-01 18:19:49,316  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 191.0 in stage 11.0 (TID 204). 1609 bytes result sent to driver
2017-07-01 18:19:49,322  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 192.0 in stage 11.0 (TID 205, localhost, partition 193,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:49,323  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 191.0 in stage 11.0 (TID 204) in 72 ms on localhost (191/199)
2017-07-01 18:19:49,324  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 192.0 in stage 11.0 (TID 205)
2017-07-01 18:19:49,341  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Finished task 190.0 in stage 11.0 (TID 203). 1609 bytes result sent to driver
2017-07-01 18:19:49,346  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 193.0 in stage 11.0 (TID 206, localhost, partition 194,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:49,347  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 190.0 in stage 11.0 (TID 203) in 117 ms on localhost (192/199)
2017-07-01 18:19:49,353  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 193.0 in stage 11.0 (TID 206)
2017-07-01 18:19:49,345  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:49,361  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 16 ms
2017-07-01 18:19:49,371  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 192.0 in stage 11.0 (TID 205). 1609 bytes result sent to driver
2017-07-01 18:19:49,374  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 194.0 in stage 11.0 (TID 207, localhost, partition 195,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:49,374  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Running task 194.0 in stage 11.0 (TID 207)
2017-07-01 18:19:49,378  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 192.0 in stage 11.0 (TID 205) in 61 ms on localhost (193/199)
2017-07-01 18:19:49,390  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:49,396  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 6 ms
2017-07-01 18:19:49,403  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 193.0 in stage 11.0 (TID 206). 1609 bytes result sent to driver
2017-07-01 18:19:49,410  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 195.0 in stage 11.0 (TID 208, localhost, partition 196,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:49,410  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 195.0 in stage 11.0 (TID 208)
2017-07-01 18:19:49,412  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 193.0 in stage 11.0 (TID 206) in 66 ms on localhost (194/199)
2017-07-01 18:19:49,426  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:49,429  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:19:49,426  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:49,434  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 8 ms
2017-07-01 18:19:49,436  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Finished task 194.0 in stage 11.0 (TID 207). 1609 bytes result sent to driver
2017-07-01 18:19:49,443  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 196.0 in stage 11.0 (TID 209, localhost, partition 197,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:49,444  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 194.0 in stage 11.0 (TID 207) in 71 ms on localhost (195/199)
2017-07-01 18:19:49,449  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 196.0 in stage 11.0 (TID 209)
2017-07-01 18:19:49,442  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 195.0 in stage 11.0 (TID 208). 1609 bytes result sent to driver
2017-07-01 18:19:49,460  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 197.0 in stage 11.0 (TID 210, localhost, partition 198,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:49,462  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 195.0 in stage 11.0 (TID 208) in 52 ms on localhost (196/199)
2017-07-01 18:19:49,468  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Running task 197.0 in stage 11.0 (TID 210)
2017-07-01 18:19:49,478  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:49,479  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:19:49,484  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:49,491  INFO [Executor task launch worker-3] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 7 ms
2017-07-01 18:19:49,495  INFO [Executor task launch worker-3] (org.apache.spark.executor.Executor) - Finished task 197.0 in stage 11.0 (TID 210). 1609 bytes result sent to driver
2017-07-01 18:19:49,490  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 196.0 in stage 11.0 (TID 209). 1609 bytes result sent to driver
2017-07-01 18:19:49,501  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 198.0 in stage 11.0 (TID 211, localhost, partition 199,NODE_LOCAL, 2044 bytes)
2017-07-01 18:19:49,502  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Running task 198.0 in stage 11.0 (TID 211)
2017-07-01 18:19:49,503  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 196.0 in stage 11.0 (TID 209) in 60 ms on localhost (197/199)
2017-07-01 18:19:49,519  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:19:49,532  INFO [Executor task launch worker-2] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 13 ms
2017-07-01 18:19:49,533  INFO [Executor task launch worker-2] (org.apache.spark.executor.Executor) - Finished task 198.0 in stage 11.0 (TID 211). 1609 bytes result sent to driver
2017-07-01 18:19:49,522  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 197.0 in stage 11.0 (TID 210) in 62 ms on localhost (198/199)
2017-07-01 18:19:49,542  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 198.0 in stage 11.0 (TID 211) in 41 ms on localhost (199/199)
2017-07-01 18:19:49,542  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2017-07-01 18:19:49,546  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 11 (show at <console>:63) finished in 4,601 s
2017-07-01 18:19:49,547  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.scheduler.DAGScheduler) - Job 9 finished: show at <console>:63, took 4,759687 s
2017-07-01 18:19:50,309  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_21_piece0 on localhost:56220 in memory (size: 7.0 KB, free: 116.4 MB)
2017-07-01 18:19:50,310  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 26
2017-07-01 18:19:50,339  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned shuffle 0
2017-07-01 18:19:50,345  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 23
2017-07-01 18:19:50,349  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 22
2017-07-01 18:19:50,357  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 21
2017-07-01 18:19:50,357  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 20
2017-07-01 18:19:50,357  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 19
2017-07-01 18:19:50,357  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 18
2017-07-01 18:19:50,358  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 17
2017-07-01 18:19:50,359  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 16
2017-07-01 18:19:50,366  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_18_piece0 on localhost:56220 in memory (size: 19.6 KB, free: 116.4 MB)
2017-07-01 18:26:32,149  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.storage.MemoryStore) - Block broadcast_22 stored as values in memory (estimated size 187.4 KB, free 187.4 KB)
2017-07-01 18:26:32,243  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.storage.MemoryStore) - Block broadcast_22_piece0 stored as bytes in memory (estimated size 19.5 KB, free 206.9 KB)
2017-07-01 18:26:32,246  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_22_piece0 in memory on localhost:56220 (size: 19.5 KB, free: 116.4 MB)
2017-07-01 18:26:32,251  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.SparkContext) - Created broadcast 22 from show at <console>:65
2017-07-01 18:26:32,260  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.storage.MemoryStore) - Block broadcast_23 stored as values in memory (estimated size 188.0 KB, free 394.9 KB)
2017-07-01 18:26:32,288  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.storage.MemoryStore) - Block broadcast_23_piece0 stored as bytes in memory (estimated size 19.6 KB, free 414.5 KB)
2017-07-01 18:26:32,289  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_23_piece0 in memory on localhost:56220 (size: 19.6 KB, free: 116.4 MB)
2017-07-01 18:26:32,294  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.SparkContext) - Created broadcast 23 from show at <console>:65
2017-07-01 18:26:32,381  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.hadoop.mapred.FileInputFormat) - Total input paths to process : 1
2017-07-01 18:26:32,494  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.SparkContext) - Starting job: show at <console>:65
2017-07-01 18:26:32,495  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Registering RDD 47 (show at <console>:65)
2017-07-01 18:26:32,495  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 10 (show at <console>:65) with 1 output partitions
2017-07-01 18:26:32,495  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 13 (show at <console>:65)
2017-07-01 18:26:32,496  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List(ShuffleMapStage 12)
2017-07-01 18:26:32,496  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List(ShuffleMapStage 12)
2017-07-01 18:26:32,496  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ShuffleMapStage 12 (MapPartitionsRDD[47] at show at <console>:65), which has no missing parents
2017-07-01 18:26:32,500  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_24 stored as values in memory (estimated size 11.2 KB, free 425.7 KB)
2017-07-01 18:26:32,510  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_24_piece0 stored as bytes in memory (estimated size 5.7 KB, free 431.4 KB)
2017-07-01 18:26:32,511  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_24_piece0 in memory on localhost:56220 (size: 5.7 KB, free: 116.4 MB)
2017-07-01 18:26:32,513  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 24 from broadcast at DAGScheduler.scala:1006
2017-07-01 18:26:32,513  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[47] at show at <console>:65)
2017-07-01 18:26:32,514  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 12.0 with 2 tasks
2017-07-01 18:26:32,516  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 12.0 (TID 212, localhost, partition 0,PROCESS_LOCAL, 2187 bytes)
2017-07-01 18:26:32,517  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 12.0 (TID 213, localhost, partition 1,PROCESS_LOCAL, 2187 bytes)
2017-07-01 18:26:32,519  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 12.0 (TID 212)
2017-07-01 18:26:32,522  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 12.0 (TID 213)
2017-07-01 18:26:32,526  INFO [Executor task launch worker-4] (org.apache.spark.rdd.HadoopRDD) - Input split: file:/home/turmasabado/spark-notebook/produtos.json:0+500
2017-07-01 18:26:32,532  INFO [Executor task launch worker-5] (org.apache.spark.rdd.HadoopRDD) - Input split: file:/home/turmasabado/spark-notebook/produtos.json:500+501
2017-07-01 18:26:32,562  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 12.0 (TID 213). 2702 bytes result sent to driver
2017-07-01 18:26:32,564  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 12.0 (TID 213) in 48 ms on localhost (1/2)
2017-07-01 18:26:32,877  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 12.0 (TID 212). 2702 bytes result sent to driver
2017-07-01 18:26:32,879  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 12.0 (TID 212) in 364 ms on localhost (2/2)
2017-07-01 18:26:32,879  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 12.0, whose tasks have all completed, from pool 
2017-07-01 18:26:32,879  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ShuffleMapStage 12 (show at <console>:65) finished in 0,364 s
2017-07-01 18:26:32,880  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - looking for newly runnable stages
2017-07-01 18:26:32,880  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - running: Set()
2017-07-01 18:26:32,880  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - waiting: Set(ResultStage 13)
2017-07-01 18:26:32,880  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - failed: Set()
2017-07-01 18:26:32,880  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 13 (MapPartitionsRDD[51] at show at <console>:65), which has no missing parents
2017-07-01 18:26:32,889  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_25 stored as values in memory (estimated size 13.1 KB, free 444.5 KB)
2017-07-01 18:26:32,893  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_25_piece0 stored as bytes in memory (estimated size 7.0 KB, free 451.5 KB)
2017-07-01 18:26:32,894  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_25_piece0 in memory on localhost:56220 (size: 7.0 KB, free: 116.4 MB)
2017-07-01 18:26:32,896  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 25 from broadcast at DAGScheduler.scala:1006
2017-07-01 18:26:32,896  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[51] at show at <console>:65)
2017-07-01 18:26:32,896  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 13.0 with 1 tasks
2017-07-01 18:26:32,898  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 13.0 (TID 214, localhost, partition 0,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:32,898  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 13.0 (TID 214)
2017-07-01 18:26:32,903  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:32,903  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:32,904  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 13.0 (TID 214). 1609 bytes result sent to driver
2017-07-01 18:26:32,905  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 13.0 (TID 214) in 8 ms on localhost (1/1)
2017-07-01 18:26:32,905  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2017-07-01 18:26:32,906  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 13 (show at <console>:65) finished in 0,009 s
2017-07-01 18:26:32,907  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.scheduler.DAGScheduler) - Job 10 finished: show at <console>:65, took 0,413091 s
2017-07-01 18:26:32,912  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.SparkContext) - Starting job: show at <console>:65
2017-07-01 18:26:32,914  INFO [dag-scheduler-event-loop] (org.apache.spark.MapOutputTrackerMaster) - Size of output statuses for shuffle 1 is 169 bytes
2017-07-01 18:26:32,915  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 11 (show at <console>:65) with 199 output partitions
2017-07-01 18:26:32,916  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 15 (show at <console>:65)
2017-07-01 18:26:32,916  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List(ShuffleMapStage 14)
2017-07-01 18:26:32,916  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2017-07-01 18:26:32,921  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 15 (MapPartitionsRDD[51] at show at <console>:65), which has no missing parents
2017-07-01 18:26:32,953  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_26 stored as values in memory (estimated size 13.1 KB, free 464.6 KB)
2017-07-01 18:26:32,961  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_26_piece0 stored as bytes in memory (estimated size 7.0 KB, free 471.6 KB)
2017-07-01 18:26:32,966  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_26_piece0 in memory on localhost:56220 (size: 7.0 KB, free: 116.4 MB)
2017-07-01 18:26:32,966  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 26 from broadcast at DAGScheduler.scala:1006
2017-07-01 18:26:32,968  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 199 missing tasks from ResultStage 15 (MapPartitionsRDD[51] at show at <console>:65)
2017-07-01 18:26:32,968  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 15.0 with 199 tasks
2017-07-01 18:26:32,971  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 15.0 (TID 215, localhost, partition 1,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:32,972  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 15.0 (TID 216, localhost, partition 2,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:32,972  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 15.0 (TID 215)
2017-07-01 18:26:32,972  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 15.0 (TID 216)
2017-07-01 18:26:32,979  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:32,982  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:26:32,983  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 15.0 (TID 216). 1609 bytes result sent to driver
2017-07-01 18:26:32,979  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:32,984  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 5 ms
2017-07-01 18:26:32,985  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 15.0 (TID 215). 1609 bytes result sent to driver
2017-07-01 18:26:32,987  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 2.0 in stage 15.0 (TID 217, localhost, partition 3,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:32,993  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 3.0 in stage 15.0 (TID 218, localhost, partition 4,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:32,993  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 3.0 in stage 15.0 (TID 218)
2017-07-01 18:26:32,996  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 2.0 in stage 15.0 (TID 217)
2017-07-01 18:26:32,997  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 15.0 (TID 216) in 26 ms on localhost (1/199)
2017-07-01 18:26:32,998  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 15.0 (TID 215) in 27 ms on localhost (2/199)
2017-07-01 18:26:33,001  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,002  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:33,003  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 2.0 in stage 15.0 (TID 217). 1609 bytes result sent to driver
2017-07-01 18:26:33,001  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,003  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:33,005  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 4.0 in stage 15.0 (TID 219, localhost, partition 5,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,005  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 2.0 in stage 15.0 (TID 217) in 19 ms on localhost (3/199)
2017-07-01 18:26:33,006  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 3.0 in stage 15.0 (TID 218). 1609 bytes result sent to driver
2017-07-01 18:26:33,007  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 5.0 in stage 15.0 (TID 220, localhost, partition 6,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,008  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 3.0 in stage 15.0 (TID 218) in 16 ms on localhost (4/199)
2017-07-01 18:26:33,009  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 5.0 in stage 15.0 (TID 220)
2017-07-01 18:26:33,011  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 4.0 in stage 15.0 (TID 219)
2017-07-01 18:26:33,013  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,018  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 5 ms
2017-07-01 18:26:33,020  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 5.0 in stage 15.0 (TID 220). 1609 bytes result sent to driver
2017-07-01 18:26:33,020  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 6.0 in stage 15.0 (TID 221, localhost, partition 7,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,021  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 5.0 in stage 15.0 (TID 220) in 14 ms on localhost (5/199)
2017-07-01 18:26:33,022  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 6.0 in stage 15.0 (TID 221)
2017-07-01 18:26:33,027  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,028  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:33,029  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 6.0 in stage 15.0 (TID 221). 1609 bytes result sent to driver
2017-07-01 18:26:33,029  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 7.0 in stage 15.0 (TID 222, localhost, partition 8,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,033  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,034  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:33,036  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 4.0 in stage 15.0 (TID 219). 1609 bytes result sent to driver
2017-07-01 18:26:33,036  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 7.0 in stage 15.0 (TID 222)
2017-07-01 18:26:33,037  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 8.0 in stage 15.0 (TID 223, localhost, partition 9,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,038  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 8.0 in stage 15.0 (TID 223)
2017-07-01 18:26:33,041  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 4.0 in stage 15.0 (TID 219) in 37 ms on localhost (6/199)
2017-07-01 18:26:33,041  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 6.0 in stage 15.0 (TID 221) in 21 ms on localhost (7/199)
2017-07-01 18:26:33,047  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,047  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:33,049  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 8.0 in stage 15.0 (TID 223). 1609 bytes result sent to driver
2017-07-01 18:26:33,051  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 9.0 in stage 15.0 (TID 224, localhost, partition 10,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,052  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 8.0 in stage 15.0 (TID 223) in 15 ms on localhost (8/199)
2017-07-01 18:26:33,053  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 9.0 in stage 15.0 (TID 224)
2017-07-01 18:26:33,057  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,058  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:33,050  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,059  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 9 ms
2017-07-01 18:26:33,062  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 9.0 in stage 15.0 (TID 224). 1609 bytes result sent to driver
2017-07-01 18:26:33,062  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 7.0 in stage 15.0 (TID 222). 1609 bytes result sent to driver
2017-07-01 18:26:33,063  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 10.0 in stage 15.0 (TID 225, localhost, partition 11,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,064  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 9.0 in stage 15.0 (TID 224) in 12 ms on localhost (9/199)
2017-07-01 18:26:33,064  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 10.0 in stage 15.0 (TID 225)
2017-07-01 18:26:33,068  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,068  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 11.0 in stage 15.0 (TID 226, localhost, partition 12,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,069  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 7.0 in stage 15.0 (TID 222) in 40 ms on localhost (10/199)
2017-07-01 18:26:33,075  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 11.0 in stage 15.0 (TID 226)
2017-07-01 18:26:33,085  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 18 ms
2017-07-01 18:26:33,086  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 10.0 in stage 15.0 (TID 225). 1609 bytes result sent to driver
2017-07-01 18:26:33,089  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 12.0 in stage 15.0 (TID 227, localhost, partition 13,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,089  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 10.0 in stage 15.0 (TID 225) in 26 ms on localhost (11/199)
2017-07-01 18:26:33,090  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 12.0 in stage 15.0 (TID 227)
2017-07-01 18:26:33,095  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,096  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:33,097  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,097  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:33,098  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 11.0 in stage 15.0 (TID 226). 1609 bytes result sent to driver
2017-07-01 18:26:33,099  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 12.0 in stage 15.0 (TID 227). 1609 bytes result sent to driver
2017-07-01 18:26:33,100  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 13.0 in stage 15.0 (TID 228, localhost, partition 14,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,100  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 11.0 in stage 15.0 (TID 226) in 32 ms on localhost (12/199)
2017-07-01 18:26:33,101  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 13.0 in stage 15.0 (TID 228)
2017-07-01 18:26:33,105  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,106  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 14.0 in stage 15.0 (TID 229, localhost, partition 15,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,107  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 12.0 in stage 15.0 (TID 227) in 19 ms on localhost (13/199)
2017-07-01 18:26:33,107  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 14.0 in stage 15.0 (TID 229)
2017-07-01 18:26:33,109  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:26:33,116  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,117  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:33,120  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 14.0 in stage 15.0 (TID 229). 1609 bytes result sent to driver
2017-07-01 18:26:33,120  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 15.0 in stage 15.0 (TID 230, localhost, partition 16,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,121  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 14.0 in stage 15.0 (TID 229) in 16 ms on localhost (14/199)
2017-07-01 18:26:33,121  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 15.0 in stage 15.0 (TID 230)
2017-07-01 18:26:33,125  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,125  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:33,126  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 15.0 in stage 15.0 (TID 230). 1609 bytes result sent to driver
2017-07-01 18:26:33,127  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 16.0 in stage 15.0 (TID 231, localhost, partition 17,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,128  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 15.0 in stage 15.0 (TID 230) in 8 ms on localhost (15/199)
2017-07-01 18:26:33,128  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 16.0 in stage 15.0 (TID 231)
2017-07-01 18:26:33,132  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,132  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:33,133  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 16.0 in stage 15.0 (TID 231). 1609 bytes result sent to driver
2017-07-01 18:26:33,134  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 17.0 in stage 15.0 (TID 232, localhost, partition 18,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,135  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 16.0 in stage 15.0 (TID 231) in 8 ms on localhost (16/199)
2017-07-01 18:26:33,142  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 17.0 in stage 15.0 (TID 232)
2017-07-01 18:26:33,142  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 13.0 in stage 15.0 (TID 228). 1963 bytes result sent to driver
2017-07-01 18:26:33,144  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 18.0 in stage 15.0 (TID 233, localhost, partition 19,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,144  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 13.0 in stage 15.0 (TID 228) in 45 ms on localhost (17/199)
2017-07-01 18:26:33,145  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 18.0 in stage 15.0 (TID 233)
2017-07-01 18:26:33,164  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,166  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:33,165  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,170  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 5 ms
2017-07-01 18:26:33,174  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 18.0 in stage 15.0 (TID 233). 1609 bytes result sent to driver
2017-07-01 18:26:33,179  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 19.0 in stage 15.0 (TID 234, localhost, partition 20,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,183  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 18.0 in stage 15.0 (TID 233) in 40 ms on localhost (18/199)
2017-07-01 18:26:33,188  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 19.0 in stage 15.0 (TID 234)
2017-07-01 18:26:33,195  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,196  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:33,198  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 19.0 in stage 15.0 (TID 234). 1609 bytes result sent to driver
2017-07-01 18:26:33,197  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 17.0 in stage 15.0 (TID 232). 1609 bytes result sent to driver
2017-07-01 18:26:33,204  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 20.0 in stage 15.0 (TID 235, localhost, partition 21,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,206  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 19.0 in stage 15.0 (TID 234) in 29 ms on localhost (19/199)
2017-07-01 18:26:33,208  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 20.0 in stage 15.0 (TID 235)
2017-07-01 18:26:33,212  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 21.0 in stage 15.0 (TID 236, localhost, partition 22,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,214  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 17.0 in stage 15.0 (TID 232) in 79 ms on localhost (20/199)
2017-07-01 18:26:33,217  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 21.0 in stage 15.0 (TID 236)
2017-07-01 18:26:33,221  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,222  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:33,223  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 21.0 in stage 15.0 (TID 236). 1609 bytes result sent to driver
2017-07-01 18:26:33,222  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,223  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:33,224  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 20.0 in stage 15.0 (TID 235). 1609 bytes result sent to driver
2017-07-01 18:26:33,225  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 22.0 in stage 15.0 (TID 237, localhost, partition 23,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,227  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 20.0 in stage 15.0 (TID 235) in 24 ms on localhost (21/199)
2017-07-01 18:26:33,228  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 22.0 in stage 15.0 (TID 237)
2017-07-01 18:26:33,231  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,232  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:33,233  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 22.0 in stage 15.0 (TID 237). 1609 bytes result sent to driver
2017-07-01 18:26:33,234  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 23.0 in stage 15.0 (TID 238, localhost, partition 24,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,235  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 22.0 in stage 15.0 (TID 237) in 10 ms on localhost (22/199)
2017-07-01 18:26:33,245  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 23.0 in stage 15.0 (TID 238)
2017-07-01 18:26:33,250  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 24.0 in stage 15.0 (TID 239, localhost, partition 25,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,254  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 21.0 in stage 15.0 (TID 236) in 41 ms on localhost (23/199)
2017-07-01 18:26:33,255  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 24.0 in stage 15.0 (TID 239)
2017-07-01 18:26:33,265  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,266  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:33,265  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,266  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:33,267  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 23.0 in stage 15.0 (TID 238). 1609 bytes result sent to driver
2017-07-01 18:26:33,268  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 25.0 in stage 15.0 (TID 240, localhost, partition 26,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,269  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 23.0 in stage 15.0 (TID 238) in 35 ms on localhost (24/199)
2017-07-01 18:26:33,270  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 25.0 in stage 15.0 (TID 240)
2017-07-01 18:26:33,274  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,275  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:33,278  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 24.0 in stage 15.0 (TID 239). 1609 bytes result sent to driver
2017-07-01 18:26:33,278  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 25.0 in stage 15.0 (TID 240). 1609 bytes result sent to driver
2017-07-01 18:26:33,279  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 26.0 in stage 15.0 (TID 241, localhost, partition 27,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,282  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 24.0 in stage 15.0 (TID 239) in 33 ms on localhost (25/199)
2017-07-01 18:26:33,282  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 26.0 in stage 15.0 (TID 241)
2017-07-01 18:26:33,283  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 27.0 in stage 15.0 (TID 242, localhost, partition 28,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,284  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 25.0 in stage 15.0 (TID 240) in 16 ms on localhost (26/199)
2017-07-01 18:26:33,288  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 27.0 in stage 15.0 (TID 242)
2017-07-01 18:26:33,300  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,301  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 6 ms
2017-07-01 18:26:33,306  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,307  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:33,308  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 27.0 in stage 15.0 (TID 242). 1609 bytes result sent to driver
2017-07-01 18:26:33,307  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 26.0 in stage 15.0 (TID 241). 1609 bytes result sent to driver
2017-07-01 18:26:33,311  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 28.0 in stage 15.0 (TID 243, localhost, partition 29,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,311  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 27.0 in stage 15.0 (TID 242) in 28 ms on localhost (27/199)
2017-07-01 18:26:33,313  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 28.0 in stage 15.0 (TID 243)
2017-07-01 18:26:33,324  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,324  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:33,325  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 28.0 in stage 15.0 (TID 243). 1609 bytes result sent to driver
2017-07-01 18:26:33,326  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 29.0 in stage 15.0 (TID 244, localhost, partition 30,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,327  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 28.0 in stage 15.0 (TID 243) in 17 ms on localhost (28/199)
2017-07-01 18:26:33,327  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 29.0 in stage 15.0 (TID 244)
2017-07-01 18:26:33,328  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 30.0 in stage 15.0 (TID 245, localhost, partition 31,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,329  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 26.0 in stage 15.0 (TID 241) in 50 ms on localhost (29/199)
2017-07-01 18:26:33,330  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 30.0 in stage 15.0 (TID 245)
2017-07-01 18:26:33,338  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,338  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:33,340  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 29.0 in stage 15.0 (TID 244). 1609 bytes result sent to driver
2017-07-01 18:26:33,347  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 31.0 in stage 15.0 (TID 246, localhost, partition 32,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,348  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 29.0 in stage 15.0 (TID 244) in 22 ms on localhost (30/199)
2017-07-01 18:26:33,351  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 31.0 in stage 15.0 (TID 246)
2017-07-01 18:26:33,379  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,380  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:33,379  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,381  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:33,382  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 30.0 in stage 15.0 (TID 245). 1609 bytes result sent to driver
2017-07-01 18:26:33,383  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 32.0 in stage 15.0 (TID 247, localhost, partition 33,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,384  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 30.0 in stage 15.0 (TID 245) in 56 ms on localhost (31/199)
2017-07-01 18:26:33,385  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 32.0 in stage 15.0 (TID 247)
2017-07-01 18:26:33,388  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,389  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:33,393  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 31.0 in stage 15.0 (TID 246). 1609 bytes result sent to driver
2017-07-01 18:26:33,394  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 33.0 in stage 15.0 (TID 248, localhost, partition 34,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,394  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 31.0 in stage 15.0 (TID 246) in 49 ms on localhost (32/199)
2017-07-01 18:26:33,404  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 33.0 in stage 15.0 (TID 248)
2017-07-01 18:26:33,418  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,424  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 6 ms
2017-07-01 18:26:33,431  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 32.0 in stage 15.0 (TID 247). 1963 bytes result sent to driver
2017-07-01 18:26:33,435  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 33.0 in stage 15.0 (TID 248). 1609 bytes result sent to driver
2017-07-01 18:26:33,440  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 34.0 in stage 15.0 (TID 249, localhost, partition 35,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,440  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 33.0 in stage 15.0 (TID 248) in 47 ms on localhost (33/199)
2017-07-01 18:26:33,442  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 34.0 in stage 15.0 (TID 249)
2017-07-01 18:26:33,446  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,447  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:33,448  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 34.0 in stage 15.0 (TID 249). 1609 bytes result sent to driver
2017-07-01 18:26:33,451  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 35.0 in stage 15.0 (TID 250, localhost, partition 36,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,452  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 32.0 in stage 15.0 (TID 247) in 69 ms on localhost (34/199)
2017-07-01 18:26:33,453  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 35.0 in stage 15.0 (TID 250)
2017-07-01 18:26:33,456  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 36.0 in stage 15.0 (TID 251, localhost, partition 37,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,457  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 34.0 in stage 15.0 (TID 249) in 18 ms on localhost (35/199)
2017-07-01 18:26:33,460  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 36.0 in stage 15.0 (TID 251)
2017-07-01 18:26:33,480  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,481  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:33,480  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,489  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 9 ms
2017-07-01 18:26:33,492  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 35.0 in stage 15.0 (TID 250). 1609 bytes result sent to driver
2017-07-01 18:26:33,496  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 37.0 in stage 15.0 (TID 252, localhost, partition 38,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,497  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 35.0 in stage 15.0 (TID 250) in 46 ms on localhost (36/199)
2017-07-01 18:26:33,499  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 37.0 in stage 15.0 (TID 252)
2017-07-01 18:26:33,503  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,504  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:33,505  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 37.0 in stage 15.0 (TID 252). 1609 bytes result sent to driver
2017-07-01 18:26:33,506  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 38.0 in stage 15.0 (TID 253, localhost, partition 39,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,506  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 37.0 in stage 15.0 (TID 252) in 10 ms on localhost (37/199)
2017-07-01 18:26:33,506  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 38.0 in stage 15.0 (TID 253)
2017-07-01 18:26:33,511  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,511  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:33,513  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 38.0 in stage 15.0 (TID 253). 1609 bytes result sent to driver
2017-07-01 18:26:33,519  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 39.0 in stage 15.0 (TID 254, localhost, partition 40,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,519  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 39.0 in stage 15.0 (TID 254)
2017-07-01 18:26:33,520  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 38.0 in stage 15.0 (TID 253) in 15 ms on localhost (38/199)
2017-07-01 18:26:33,524  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,524  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:33,526  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 39.0 in stage 15.0 (TID 254). 1609 bytes result sent to driver
2017-07-01 18:26:33,530  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 40.0 in stage 15.0 (TID 255, localhost, partition 41,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,530  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 39.0 in stage 15.0 (TID 254) in 17 ms on localhost (39/199)
2017-07-01 18:26:33,531  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 40.0 in stage 15.0 (TID 255)
2017-07-01 18:26:33,495  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 36.0 in stage 15.0 (TID 251). 1609 bytes result sent to driver
2017-07-01 18:26:33,539  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 41.0 in stage 15.0 (TID 256, localhost, partition 42,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,540  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 36.0 in stage 15.0 (TID 251) in 84 ms on localhost (40/199)
2017-07-01 18:26:33,541  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 41.0 in stage 15.0 (TID 256)
2017-07-01 18:26:33,546  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,548  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:33,550  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 40.0 in stage 15.0 (TID 255). 1609 bytes result sent to driver
2017-07-01 18:26:33,547  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,551  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:26:33,552  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 42.0 in stage 15.0 (TID 257, localhost, partition 43,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,553  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 40.0 in stage 15.0 (TID 255) in 23 ms on localhost (41/199)
2017-07-01 18:26:33,562  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 42.0 in stage 15.0 (TID 257)
2017-07-01 18:26:33,571  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 41.0 in stage 15.0 (TID 256). 1609 bytes result sent to driver
2017-07-01 18:26:33,572  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,574  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 43.0 in stage 15.0 (TID 258, localhost, partition 44,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,576  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 41.0 in stage 15.0 (TID 256) in 36 ms on localhost (42/199)
2017-07-01 18:26:33,576  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 43.0 in stage 15.0 (TID 258)
2017-07-01 18:26:33,576  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:26:33,582  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 42.0 in stage 15.0 (TID 257). 1609 bytes result sent to driver
2017-07-01 18:26:33,587  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 44.0 in stage 15.0 (TID 259, localhost, partition 45,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,587  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 42.0 in stage 15.0 (TID 257) in 35 ms on localhost (43/199)
2017-07-01 18:26:33,588  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 44.0 in stage 15.0 (TID 259)
2017-07-01 18:26:33,606  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,608  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:33,607  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,611  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:26:33,610  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 44.0 in stage 15.0 (TID 259). 1609 bytes result sent to driver
2017-07-01 18:26:33,615  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 45.0 in stage 15.0 (TID 260, localhost, partition 46,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,616  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 44.0 in stage 15.0 (TID 259) in 30 ms on localhost (44/199)
2017-07-01 18:26:33,622  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 45.0 in stage 15.0 (TID 260)
2017-07-01 18:26:33,632  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 43.0 in stage 15.0 (TID 258). 1609 bytes result sent to driver
2017-07-01 18:26:33,635  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 46.0 in stage 15.0 (TID 261, localhost, partition 47,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,636  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 43.0 in stage 15.0 (TID 258) in 62 ms on localhost (45/199)
2017-07-01 18:26:33,638  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 46.0 in stage 15.0 (TID 261)
2017-07-01 18:26:33,641  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,642  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:33,647  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,651  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:26:33,657  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 46.0 in stage 15.0 (TID 261). 1609 bytes result sent to driver
2017-07-01 18:26:33,648  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 45.0 in stage 15.0 (TID 260). 1609 bytes result sent to driver
2017-07-01 18:26:33,664  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 47.0 in stage 15.0 (TID 262, localhost, partition 48,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,664  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 45.0 in stage 15.0 (TID 260) in 49 ms on localhost (46/199)
2017-07-01 18:26:33,667  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 47.0 in stage 15.0 (TID 262)
2017-07-01 18:26:33,672  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,672  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:33,674  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 48.0 in stage 15.0 (TID 263, localhost, partition 49,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,674  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 46.0 in stage 15.0 (TID 261) in 39 ms on localhost (47/199)
2017-07-01 18:26:33,679  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 48.0 in stage 15.0 (TID 263)
2017-07-01 18:26:33,686  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 47.0 in stage 15.0 (TID 262). 1609 bytes result sent to driver
2017-07-01 18:26:33,689  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 49.0 in stage 15.0 (TID 264, localhost, partition 50,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,693  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 47.0 in stage 15.0 (TID 262) in 29 ms on localhost (48/199)
2017-07-01 18:26:33,696  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 49.0 in stage 15.0 (TID 264)
2017-07-01 18:26:33,710  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,713  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:26:33,714  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 48.0 in stage 15.0 (TID 263). 1609 bytes result sent to driver
2017-07-01 18:26:33,724  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,779  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 55 ms
2017-07-01 18:26:33,780  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 49.0 in stage 15.0 (TID 264). 1609 bytes result sent to driver
2017-07-01 18:26:33,778  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 50.0 in stage 15.0 (TID 265, localhost, partition 51,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,784  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 50.0 in stage 15.0 (TID 265)
2017-07-01 18:26:33,786  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 48.0 in stage 15.0 (TID 263) in 113 ms on localhost (49/199)
2017-07-01 18:26:33,791  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 51.0 in stage 15.0 (TID 266, localhost, partition 52,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,792  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 49.0 in stage 15.0 (TID 264) in 103 ms on localhost (50/199)
2017-07-01 18:26:33,794  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 51.0 in stage 15.0 (TID 266)
2017-07-01 18:26:33,800  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,804  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:26:33,807  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 50.0 in stage 15.0 (TID 265). 1609 bytes result sent to driver
2017-07-01 18:26:33,813  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,815  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:33,823  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 51.0 in stage 15.0 (TID 266). 1609 bytes result sent to driver
2017-07-01 18:26:33,827  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 52.0 in stage 15.0 (TID 267, localhost, partition 53,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,830  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 52.0 in stage 15.0 (TID 267)
2017-07-01 18:26:33,835  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 53.0 in stage 15.0 (TID 268, localhost, partition 54,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,836  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 51.0 in stage 15.0 (TID 266) in 45 ms on localhost (51/199)
2017-07-01 18:26:33,836  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 50.0 in stage 15.0 (TID 265) in 110 ms on localhost (52/199)
2017-07-01 18:26:33,839  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 53.0 in stage 15.0 (TID 268)
2017-07-01 18:26:33,845  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_25_piece0 on localhost:56220 in memory (size: 7.0 KB, free: 116.4 MB)
2017-07-01 18:26:33,849  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,853  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:26:33,858  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 53.0 in stage 15.0 (TID 268). 1609 bytes result sent to driver
2017-07-01 18:26:33,864  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 54.0 in stage 15.0 (TID 269, localhost, partition 55,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,865  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 53.0 in stage 15.0 (TID 268) in 38 ms on localhost (53/199)
2017-07-01 18:26:33,865  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 54.0 in stage 15.0 (TID 269)
2017-07-01 18:26:33,872  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,874  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:33,876  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 54.0 in stage 15.0 (TID 269). 1609 bytes result sent to driver
2017-07-01 18:26:33,878  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 55.0 in stage 15.0 (TID 270, localhost, partition 56,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,879  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 54.0 in stage 15.0 (TID 269) in 14 ms on localhost (54/199)
2017-07-01 18:26:33,879  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 55.0 in stage 15.0 (TID 270)
2017-07-01 18:26:33,885  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,886  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:33,888  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 55.0 in stage 15.0 (TID 270). 1609 bytes result sent to driver
2017-07-01 18:26:33,890  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 56.0 in stage 15.0 (TID 271, localhost, partition 57,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,891  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 55.0 in stage 15.0 (TID 270) in 12 ms on localhost (55/199)
2017-07-01 18:26:33,891  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 56.0 in stage 15.0 (TID 271)
2017-07-01 18:26:33,898  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,899  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:33,900  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 56.0 in stage 15.0 (TID 271). 1609 bytes result sent to driver
2017-07-01 18:26:33,902  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 57.0 in stage 15.0 (TID 272, localhost, partition 58,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,903  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 56.0 in stage 15.0 (TID 271) in 14 ms on localhost (56/199)
2017-07-01 18:26:33,861  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,907  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 46 ms
2017-07-01 18:26:33,910  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 52.0 in stage 15.0 (TID 267). 1609 bytes result sent to driver
2017-07-01 18:26:33,923  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 58.0 in stage 15.0 (TID 273, localhost, partition 59,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,923  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 52.0 in stage 15.0 (TID 267) in 96 ms on localhost (57/199)
2017-07-01 18:26:33,926  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 58.0 in stage 15.0 (TID 273)
2017-07-01 18:26:33,931  INFO [Executor task launch worker-9] (org.apache.spark.executor.Executor) - Running task 57.0 in stage 15.0 (TID 272)
2017-07-01 18:26:33,937  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,938  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:33,941  INFO [Executor task launch worker-9] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,942  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 36
2017-07-01 18:26:33,947  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_24_piece0 on localhost:56220 in memory (size: 5.7 KB, free: 116.4 MB)
2017-07-01 18:26:33,948  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 35
2017-07-01 18:26:33,949  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_22_piece0 on localhost:56220 in memory (size: 19.5 KB, free: 116.4 MB)
2017-07-01 18:26:33,942  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 58.0 in stage 15.0 (TID 273). 1609 bytes result sent to driver
2017-07-01 18:26:33,951  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 59.0 in stage 15.0 (TID 274, localhost, partition 60,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,952  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 58.0 in stage 15.0 (TID 273) in 30 ms on localhost (58/199)
2017-07-01 18:26:33,952  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 59.0 in stage 15.0 (TID 274)
2017-07-01 18:26:33,957  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,957  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:33,958  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 59.0 in stage 15.0 (TID 274). 1609 bytes result sent to driver
2017-07-01 18:26:33,959  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 60.0 in stage 15.0 (TID 275, localhost, partition 61,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,960  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 59.0 in stage 15.0 (TID 274) in 9 ms on localhost (59/199)
2017-07-01 18:26:33,960  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 60.0 in stage 15.0 (TID 275)
2017-07-01 18:26:33,964  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,965  INFO [Executor task launch worker-9] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 24 ms
2017-07-01 18:26:33,970  INFO [Executor task launch worker-9] (org.apache.spark.executor.Executor) - Finished task 57.0 in stage 15.0 (TID 272). 1609 bytes result sent to driver
2017-07-01 18:26:33,970  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 61.0 in stage 15.0 (TID 276, localhost, partition 62,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,971  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 57.0 in stage 15.0 (TID 272) in 69 ms on localhost (60/199)
2017-07-01 18:26:33,972  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 61.0 in stage 15.0 (TID 276)
2017-07-01 18:26:33,981  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 17 ms
2017-07-01 18:26:33,990  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,991  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:33,991  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 60.0 in stage 15.0 (TID 275). 1609 bytes result sent to driver
2017-07-01 18:26:33,993  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 62.0 in stage 15.0 (TID 277, localhost, partition 63,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:33,994  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 60.0 in stage 15.0 (TID 275) in 34 ms on localhost (61/199)
2017-07-01 18:26:33,994  INFO [Executor task launch worker-9] (org.apache.spark.executor.Executor) - Running task 62.0 in stage 15.0 (TID 277)
2017-07-01 18:26:33,998  INFO [Executor task launch worker-9] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:33,999  INFO [Executor task launch worker-9] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:34,000  INFO [Executor task launch worker-9] (org.apache.spark.executor.Executor) - Finished task 62.0 in stage 15.0 (TID 277). 1609 bytes result sent to driver
2017-07-01 18:26:33,999  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 61.0 in stage 15.0 (TID 276). 1609 bytes result sent to driver
2017-07-01 18:26:34,003  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 63.0 in stage 15.0 (TID 278, localhost, partition 64,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,004  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 62.0 in stage 15.0 (TID 277) in 11 ms on localhost (62/199)
2017-07-01 18:26:34,006  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 63.0 in stage 15.0 (TID 278)
2017-07-01 18:26:34,009  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 64.0 in stage 15.0 (TID 279, localhost, partition 65,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,010  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 64.0 in stage 15.0 (TID 279)
2017-07-01 18:26:34,010  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 61.0 in stage 15.0 (TID 276) in 40 ms on localhost (63/199)
2017-07-01 18:26:34,020  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,022  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:34,024  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 64.0 in stage 15.0 (TID 279). 1609 bytes result sent to driver
2017-07-01 18:26:34,027  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 65.0 in stage 15.0 (TID 280, localhost, partition 66,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,027  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 64.0 in stage 15.0 (TID 279) in 18 ms on localhost (64/199)
2017-07-01 18:26:34,028  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 65.0 in stage 15.0 (TID 280)
2017-07-01 18:26:34,036  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,036  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:34,038  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 65.0 in stage 15.0 (TID 280). 1609 bytes result sent to driver
2017-07-01 18:26:34,040  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 66.0 in stage 15.0 (TID 281, localhost, partition 67,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,040  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 65.0 in stage 15.0 (TID 280) in 14 ms on localhost (65/199)
2017-07-01 18:26:34,040  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 66.0 in stage 15.0 (TID 281)
2017-07-01 18:26:34,044  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,045  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:34,046  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 66.0 in stage 15.0 (TID 281). 1609 bytes result sent to driver
2017-07-01 18:26:34,047  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 67.0 in stage 15.0 (TID 282, localhost, partition 68,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,047  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 66.0 in stage 15.0 (TID 281) in 8 ms on localhost (66/199)
2017-07-01 18:26:34,055  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,056  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:34,055  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 67.0 in stage 15.0 (TID 282)
2017-07-01 18:26:34,058  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 63.0 in stage 15.0 (TID 278). 1609 bytes result sent to driver
2017-07-01 18:26:34,062  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 68.0 in stage 15.0 (TID 283, localhost, partition 69,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,063  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 63.0 in stage 15.0 (TID 278) in 60 ms on localhost (67/199)
2017-07-01 18:26:34,064  INFO [Executor task launch worker-9] (org.apache.spark.executor.Executor) - Running task 68.0 in stage 15.0 (TID 283)
2017-07-01 18:26:34,068  INFO [Executor task launch worker-9] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,071  INFO [Executor task launch worker-9] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:26:34,079  INFO [Executor task launch worker-9] (org.apache.spark.executor.Executor) - Finished task 68.0 in stage 15.0 (TID 283). 1609 bytes result sent to driver
2017-07-01 18:26:34,083  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 69.0 in stage 15.0 (TID 284, localhost, partition 70,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,084  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 68.0 in stage 15.0 (TID 283) in 22 ms on localhost (68/199)
2017-07-01 18:26:34,086  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 69.0 in stage 15.0 (TID 284)
2017-07-01 18:26:34,091  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,094  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:26:34,097  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 67.0 in stage 15.0 (TID 282). 1609 bytes result sent to driver
2017-07-01 18:26:34,099  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,103  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:26:34,105  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 70.0 in stage 15.0 (TID 285, localhost, partition 71,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,106  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 67.0 in stage 15.0 (TID 282) in 59 ms on localhost (69/199)
2017-07-01 18:26:34,108  INFO [Executor task launch worker-9] (org.apache.spark.executor.Executor) - Running task 70.0 in stage 15.0 (TID 285)
2017-07-01 18:26:34,113  INFO [Executor task launch worker-9] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,116  INFO [Executor task launch worker-9] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:26:34,115  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 69.0 in stage 15.0 (TID 284). 1609 bytes result sent to driver
2017-07-01 18:26:34,120  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 71.0 in stage 15.0 (TID 286, localhost, partition 72,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,120  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 69.0 in stage 15.0 (TID 284) in 37 ms on localhost (70/199)
2017-07-01 18:26:34,123  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 71.0 in stage 15.0 (TID 286)
2017-07-01 18:26:34,129  INFO [Executor task launch worker-9] (org.apache.spark.executor.Executor) - Finished task 70.0 in stage 15.0 (TID 285). 1609 bytes result sent to driver
2017-07-01 18:26:34,135  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 72.0 in stage 15.0 (TID 287, localhost, partition 73,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,135  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 70.0 in stage 15.0 (TID 285) in 30 ms on localhost (71/199)
2017-07-01 18:26:34,138  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 72.0 in stage 15.0 (TID 287)
2017-07-01 18:26:34,146  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,152  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 6 ms
2017-07-01 18:26:34,133  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,154  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 21 ms
2017-07-01 18:26:34,156  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 71.0 in stage 15.0 (TID 286). 1609 bytes result sent to driver
2017-07-01 18:26:34,159  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 72.0 in stage 15.0 (TID 287). 1609 bytes result sent to driver
2017-07-01 18:26:34,160  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 73.0 in stage 15.0 (TID 288, localhost, partition 74,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,162  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 71.0 in stage 15.0 (TID 286) in 43 ms on localhost (72/199)
2017-07-01 18:26:34,165  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 73.0 in stage 15.0 (TID 288)
2017-07-01 18:26:34,170  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 74.0 in stage 15.0 (TID 289, localhost, partition 75,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,170  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 72.0 in stage 15.0 (TID 287) in 35 ms on localhost (73/199)
2017-07-01 18:26:34,173  INFO [Executor task launch worker-9] (org.apache.spark.executor.Executor) - Running task 74.0 in stage 15.0 (TID 289)
2017-07-01 18:26:34,177  INFO [Executor task launch worker-9] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,178  INFO [Executor task launch worker-9] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:34,183  INFO [Executor task launch worker-9] (org.apache.spark.executor.Executor) - Finished task 74.0 in stage 15.0 (TID 289). 1609 bytes result sent to driver
2017-07-01 18:26:34,185  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 75.0 in stage 15.0 (TID 290, localhost, partition 76,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,187  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 74.0 in stage 15.0 (TID 289) in 18 ms on localhost (74/199)
2017-07-01 18:26:34,188  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 75.0 in stage 15.0 (TID 290)
2017-07-01 18:26:34,196  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,202  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 6 ms
2017-07-01 18:26:34,205  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,207  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:34,209  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 75.0 in stage 15.0 (TID 290). 1609 bytes result sent to driver
2017-07-01 18:26:34,209  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 73.0 in stage 15.0 (TID 288). 1609 bytes result sent to driver
2017-07-01 18:26:34,211  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 76.0 in stage 15.0 (TID 291, localhost, partition 77,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,212  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 75.0 in stage 15.0 (TID 290) in 27 ms on localhost (75/199)
2017-07-01 18:26:34,214  INFO [Executor task launch worker-9] (org.apache.spark.executor.Executor) - Running task 76.0 in stage 15.0 (TID 291)
2017-07-01 18:26:34,219  INFO [Executor task launch worker-9] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,220  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 77.0 in stage 15.0 (TID 292, localhost, partition 78,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,222  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 73.0 in stage 15.0 (TID 288) in 63 ms on localhost (76/199)
2017-07-01 18:26:34,228  INFO [Executor task launch worker-9] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 9 ms
2017-07-01 18:26:34,228  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 77.0 in stage 15.0 (TID 292)
2017-07-01 18:26:34,232  INFO [Executor task launch worker-9] (org.apache.spark.executor.Executor) - Finished task 76.0 in stage 15.0 (TID 291). 1609 bytes result sent to driver
2017-07-01 18:26:34,238  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 78.0 in stage 15.0 (TID 293, localhost, partition 79,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,238  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 76.0 in stage 15.0 (TID 291) in 27 ms on localhost (77/199)
2017-07-01 18:26:34,240  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 78.0 in stage 15.0 (TID 293)
2017-07-01 18:26:34,251  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,253  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:26:34,253  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,256  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:26:34,257  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 78.0 in stage 15.0 (TID 293). 1609 bytes result sent to driver
2017-07-01 18:26:34,258  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 77.0 in stage 15.0 (TID 292). 1609 bytes result sent to driver
2017-07-01 18:26:34,259  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 79.0 in stage 15.0 (TID 294, localhost, partition 80,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,259  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 78.0 in stage 15.0 (TID 293) in 22 ms on localhost (78/199)
2017-07-01 18:26:34,260  INFO [Executor task launch worker-9] (org.apache.spark.executor.Executor) - Running task 79.0 in stage 15.0 (TID 294)
2017-07-01 18:26:34,264  INFO [Executor task launch worker-9] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,265  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 80.0 in stage 15.0 (TID 295, localhost, partition 81,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,266  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 77.0 in stage 15.0 (TID 292) in 47 ms on localhost (79/199)
2017-07-01 18:26:34,267  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 80.0 in stage 15.0 (TID 295)
2017-07-01 18:26:34,268  INFO [Executor task launch worker-9] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:26:34,272  INFO [Executor task launch worker-9] (org.apache.spark.executor.Executor) - Finished task 79.0 in stage 15.0 (TID 294). 1609 bytes result sent to driver
2017-07-01 18:26:34,274  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 81.0 in stage 15.0 (TID 296, localhost, partition 82,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,274  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 79.0 in stage 15.0 (TID 294) in 16 ms on localhost (80/199)
2017-07-01 18:26:34,275  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 81.0 in stage 15.0 (TID 296)
2017-07-01 18:26:34,280  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,280  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:34,280  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,281  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:34,282  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 80.0 in stage 15.0 (TID 295). 1609 bytes result sent to driver
2017-07-01 18:26:34,283  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 81.0 in stage 15.0 (TID 296). 1609 bytes result sent to driver
2017-07-01 18:26:34,284  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 82.0 in stage 15.0 (TID 297, localhost, partition 83,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,284  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 80.0 in stage 15.0 (TID 295) in 19 ms on localhost (81/199)
2017-07-01 18:26:34,285  INFO [Executor task launch worker-9] (org.apache.spark.executor.Executor) - Running task 82.0 in stage 15.0 (TID 297)
2017-07-01 18:26:34,296  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 83.0 in stage 15.0 (TID 298, localhost, partition 84,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,297  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 81.0 in stage 15.0 (TID 296) in 24 ms on localhost (82/199)
2017-07-01 18:26:34,297  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 83.0 in stage 15.0 (TID 298)
2017-07-01 18:26:34,301  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,302  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:34,303  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 83.0 in stage 15.0 (TID 298). 1609 bytes result sent to driver
2017-07-01 18:26:34,304  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 84.0 in stage 15.0 (TID 299, localhost, partition 85,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,304  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 83.0 in stage 15.0 (TID 298) in 8 ms on localhost (83/199)
2017-07-01 18:26:34,305  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 84.0 in stage 15.0 (TID 299)
2017-07-01 18:26:34,309  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,310  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:34,311  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 84.0 in stage 15.0 (TID 299). 1609 bytes result sent to driver
2017-07-01 18:26:34,311  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 85.0 in stage 15.0 (TID 300, localhost, partition 86,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,312  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 84.0 in stage 15.0 (TID 299) in 8 ms on localhost (84/199)
2017-07-01 18:26:34,312  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 85.0 in stage 15.0 (TID 300)
2017-07-01 18:26:34,317  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,317  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:34,320  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 85.0 in stage 15.0 (TID 300). 1609 bytes result sent to driver
2017-07-01 18:26:34,321  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 86.0 in stage 15.0 (TID 301, localhost, partition 87,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,321  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 85.0 in stage 15.0 (TID 300) in 10 ms on localhost (85/199)
2017-07-01 18:26:34,322  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 86.0 in stage 15.0 (TID 301)
2017-07-01 18:26:34,333  INFO [Executor task launch worker-9] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,334  INFO [Executor task launch worker-9] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:34,338  INFO [Executor task launch worker-9] (org.apache.spark.executor.Executor) - Finished task 82.0 in stage 15.0 (TID 297). 1609 bytes result sent to driver
2017-07-01 18:26:34,340  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 87.0 in stage 15.0 (TID 302, localhost, partition 88,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,340  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 82.0 in stage 15.0 (TID 297) in 57 ms on localhost (86/199)
2017-07-01 18:26:34,342  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 87.0 in stage 15.0 (TID 302)
2017-07-01 18:26:34,347  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,350  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:26:34,352  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 87.0 in stage 15.0 (TID 302). 1609 bytes result sent to driver
2017-07-01 18:26:34,349  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,355  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 18 ms
2017-07-01 18:26:34,357  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 86.0 in stage 15.0 (TID 301). 1609 bytes result sent to driver
2017-07-01 18:26:34,359  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 88.0 in stage 15.0 (TID 303, localhost, partition 89,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,359  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 86.0 in stage 15.0 (TID 301) in 39 ms on localhost (87/199)
2017-07-01 18:26:34,362  INFO [Executor task launch worker-9] (org.apache.spark.executor.Executor) - Running task 88.0 in stage 15.0 (TID 303)
2017-07-01 18:26:34,366  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 89.0 in stage 15.0 (TID 304, localhost, partition 90,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,367  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 87.0 in stage 15.0 (TID 302) in 28 ms on localhost (88/199)
2017-07-01 18:26:34,369  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 89.0 in stage 15.0 (TID 304)
2017-07-01 18:26:34,373  INFO [Executor task launch worker-9] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,374  INFO [Executor task launch worker-9] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:34,377  INFO [Executor task launch worker-9] (org.apache.spark.executor.Executor) - Finished task 88.0 in stage 15.0 (TID 303). 1609 bytes result sent to driver
2017-07-01 18:26:34,380  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 90.0 in stage 15.0 (TID 305, localhost, partition 91,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,381  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 88.0 in stage 15.0 (TID 303) in 22 ms on localhost (89/199)
2017-07-01 18:26:34,383  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 90.0 in stage 15.0 (TID 305)
2017-07-01 18:26:34,394  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,396  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:34,395  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,398  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:26:34,400  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 89.0 in stage 15.0 (TID 304). 1609 bytes result sent to driver
2017-07-01 18:26:34,401  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 90.0 in stage 15.0 (TID 305). 1609 bytes result sent to driver
2017-07-01 18:26:34,410  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 91.0 in stage 15.0 (TID 306, localhost, partition 92,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,413  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 89.0 in stage 15.0 (TID 304) in 47 ms on localhost (90/199)
2017-07-01 18:26:34,414  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 91.0 in stage 15.0 (TID 306)
2017-07-01 18:26:34,415  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 92.0 in stage 15.0 (TID 307, localhost, partition 93,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,426  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 90.0 in stage 15.0 (TID 305) in 46 ms on localhost (91/199)
2017-07-01 18:26:34,427  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 92.0 in stage 15.0 (TID 307)
2017-07-01 18:26:34,433  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,435  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:34,434  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,435  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:34,436  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 92.0 in stage 15.0 (TID 307). 1609 bytes result sent to driver
2017-07-01 18:26:34,443  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 93.0 in stage 15.0 (TID 308, localhost, partition 94,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,444  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 92.0 in stage 15.0 (TID 307) in 30 ms on localhost (92/199)
2017-07-01 18:26:34,444  INFO [Executor task launch worker-9] (org.apache.spark.executor.Executor) - Running task 93.0 in stage 15.0 (TID 308)
2017-07-01 18:26:34,448  INFO [Executor task launch worker-9] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,448  INFO [Executor task launch worker-9] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:34,454  INFO [Executor task launch worker-9] (org.apache.spark.executor.Executor) - Finished task 93.0 in stage 15.0 (TID 308). 1609 bytes result sent to driver
2017-07-01 18:26:34,455  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 94.0 in stage 15.0 (TID 309, localhost, partition 95,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,456  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 93.0 in stage 15.0 (TID 308) in 13 ms on localhost (93/199)
2017-07-01 18:26:34,456  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 94.0 in stage 15.0 (TID 309)
2017-07-01 18:26:34,460  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,461  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:34,462  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 94.0 in stage 15.0 (TID 309). 1609 bytes result sent to driver
2017-07-01 18:26:34,463  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 95.0 in stage 15.0 (TID 310, localhost, partition 96,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,463  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 94.0 in stage 15.0 (TID 309) in 8 ms on localhost (94/199)
2017-07-01 18:26:34,463  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 95.0 in stage 15.0 (TID 310)
2017-07-01 18:26:34,468  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,468  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:34,469  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 95.0 in stage 15.0 (TID 310). 1609 bytes result sent to driver
2017-07-01 18:26:34,470  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 96.0 in stage 15.0 (TID 311, localhost, partition 97,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,471  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 95.0 in stage 15.0 (TID 310) in 9 ms on localhost (95/199)
2017-07-01 18:26:34,471  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 96.0 in stage 15.0 (TID 311)
2017-07-01 18:26:34,475  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,475  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:34,476  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 96.0 in stage 15.0 (TID 311). 1609 bytes result sent to driver
2017-07-01 18:26:34,478  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 97.0 in stage 15.0 (TID 312, localhost, partition 98,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,478  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 97.0 in stage 15.0 (TID 312)
2017-07-01 18:26:34,478  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 96.0 in stage 15.0 (TID 311) in 8 ms on localhost (96/199)
2017-07-01 18:26:34,482  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,482  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:34,483  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 97.0 in stage 15.0 (TID 312). 1609 bytes result sent to driver
2017-07-01 18:26:34,484  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 98.0 in stage 15.0 (TID 313, localhost, partition 99,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,485  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 97.0 in stage 15.0 (TID 312) in 7 ms on localhost (97/199)
2017-07-01 18:26:34,485  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 98.0 in stage 15.0 (TID 313)
2017-07-01 18:26:34,442  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 91.0 in stage 15.0 (TID 306). 1609 bytes result sent to driver
2017-07-01 18:26:34,505  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 91.0 in stage 15.0 (TID 306) in 95 ms on localhost (98/199)
2017-07-01 18:26:34,506  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 99.0 in stage 15.0 (TID 314, localhost, partition 100,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,507  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 99.0 in stage 15.0 (TID 314)
2017-07-01 18:26:34,511  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,511  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:34,514  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 98.0 in stage 15.0 (TID 313). 1609 bytes result sent to driver
2017-07-01 18:26:34,516  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 100.0 in stage 15.0 (TID 315, localhost, partition 101,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,517  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 98.0 in stage 15.0 (TID 313) in 33 ms on localhost (99/199)
2017-07-01 18:26:34,518  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 100.0 in stage 15.0 (TID 315)
2017-07-01 18:26:34,521  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,522  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:34,524  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 100.0 in stage 15.0 (TID 315). 1609 bytes result sent to driver
2017-07-01 18:26:34,524  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,525  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:34,526  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 101.0 in stage 15.0 (TID 316, localhost, partition 102,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,526  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 100.0 in stage 15.0 (TID 315) in 10 ms on localhost (100/199)
2017-07-01 18:26:34,527  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 101.0 in stage 15.0 (TID 316)
2017-07-01 18:26:34,535  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 99.0 in stage 15.0 (TID 314). 1609 bytes result sent to driver
2017-07-01 18:26:34,539  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 102.0 in stage 15.0 (TID 317, localhost, partition 103,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,539  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 99.0 in stage 15.0 (TID 314) in 33 ms on localhost (101/199)
2017-07-01 18:26:34,542  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 102.0 in stage 15.0 (TID 317)
2017-07-01 18:26:34,549  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,552  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:26:34,554  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 101.0 in stage 15.0 (TID 316). 1609 bytes result sent to driver
2017-07-01 18:26:34,556  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 103.0 in stage 15.0 (TID 318, localhost, partition 104,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,556  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 101.0 in stage 15.0 (TID 316) in 30 ms on localhost (102/199)
2017-07-01 18:26:34,559  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 103.0 in stage 15.0 (TID 318)
2017-07-01 18:26:34,563  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,565  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:34,567  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 103.0 in stage 15.0 (TID 318). 1609 bytes result sent to driver
2017-07-01 18:26:34,551  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,571  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 21 ms
2017-07-01 18:26:34,573  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 102.0 in stage 15.0 (TID 317). 1609 bytes result sent to driver
2017-07-01 18:26:34,575  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 104.0 in stage 15.0 (TID 319, localhost, partition 105,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,576  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 103.0 in stage 15.0 (TID 318) in 21 ms on localhost (103/199)
2017-07-01 18:26:34,578  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 104.0 in stage 15.0 (TID 319)
2017-07-01 18:26:34,582  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 105.0 in stage 15.0 (TID 320, localhost, partition 106,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,582  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 102.0 in stage 15.0 (TID 317) in 43 ms on localhost (104/199)
2017-07-01 18:26:34,585  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 105.0 in stage 15.0 (TID 320)
2017-07-01 18:26:34,595  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,597  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 6 ms
2017-07-01 18:26:34,599  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 104.0 in stage 15.0 (TID 319). 1609 bytes result sent to driver
2017-07-01 18:26:34,602  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 106.0 in stage 15.0 (TID 321, localhost, partition 107,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,604  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 104.0 in stage 15.0 (TID 319) in 28 ms on localhost (105/199)
2017-07-01 18:26:34,606  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 106.0 in stage 15.0 (TID 321)
2017-07-01 18:26:34,612  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,613  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:34,600  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,617  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 18 ms
2017-07-01 18:26:34,619  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 106.0 in stage 15.0 (TID 321). 1609 bytes result sent to driver
2017-07-01 18:26:34,619  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 105.0 in stage 15.0 (TID 320). 1609 bytes result sent to driver
2017-07-01 18:26:34,624  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 107.0 in stage 15.0 (TID 322, localhost, partition 108,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,624  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 106.0 in stage 15.0 (TID 321) in 22 ms on localhost (106/199)
2017-07-01 18:26:34,626  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 107.0 in stage 15.0 (TID 322)
2017-07-01 18:26:34,628  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 108.0 in stage 15.0 (TID 323, localhost, partition 109,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,628  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 105.0 in stage 15.0 (TID 320) in 47 ms on localhost (107/199)
2017-07-01 18:26:34,629  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 108.0 in stage 15.0 (TID 323)
2017-07-01 18:26:34,635  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,641  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 6 ms
2017-07-01 18:26:34,647  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,647  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 107.0 in stage 15.0 (TID 322). 1609 bytes result sent to driver
2017-07-01 18:26:34,648  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:34,648  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 109.0 in stage 15.0 (TID 324, localhost, partition 110,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,650  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 107.0 in stage 15.0 (TID 322) in 26 ms on localhost (108/199)
2017-07-01 18:26:34,650  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 109.0 in stage 15.0 (TID 324)
2017-07-01 18:26:34,654  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 108.0 in stage 15.0 (TID 323). 1609 bytes result sent to driver
2017-07-01 18:26:34,656  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 110.0 in stage 15.0 (TID 325, localhost, partition 111,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,657  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 108.0 in stage 15.0 (TID 323) in 28 ms on localhost (109/199)
2017-07-01 18:26:34,657  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 110.0 in stage 15.0 (TID 325)
2017-07-01 18:26:34,670  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,670  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:34,672  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 110.0 in stage 15.0 (TID 325). 1609 bytes result sent to driver
2017-07-01 18:26:34,672  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 111.0 in stage 15.0 (TID 326, localhost, partition 112,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,673  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 110.0 in stage 15.0 (TID 325) in 17 ms on localhost (110/199)
2017-07-01 18:26:34,673  INFO [Executor task launch worker-9] (org.apache.spark.executor.Executor) - Running task 111.0 in stage 15.0 (TID 326)
2017-07-01 18:26:34,678  INFO [Executor task launch worker-9] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,678  INFO [Executor task launch worker-9] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:34,679  INFO [Executor task launch worker-9] (org.apache.spark.executor.Executor) - Finished task 111.0 in stage 15.0 (TID 326). 1609 bytes result sent to driver
2017-07-01 18:26:34,679  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 112.0 in stage 15.0 (TID 327, localhost, partition 113,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,680  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 111.0 in stage 15.0 (TID 326) in 8 ms on localhost (111/199)
2017-07-01 18:26:34,680  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 112.0 in stage 15.0 (TID 327)
2017-07-01 18:26:34,684  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,684  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:34,686  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 112.0 in stage 15.0 (TID 327). 1609 bytes result sent to driver
2017-07-01 18:26:34,686  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 113.0 in stage 15.0 (TID 328, localhost, partition 114,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,687  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 112.0 in stage 15.0 (TID 327) in 8 ms on localhost (112/199)
2017-07-01 18:26:34,687  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 113.0 in stage 15.0 (TID 328)
2017-07-01 18:26:34,691  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,692  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:34,693  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 113.0 in stage 15.0 (TID 328). 1609 bytes result sent to driver
2017-07-01 18:26:34,694  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 114.0 in stage 15.0 (TID 329, localhost, partition 115,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,694  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 113.0 in stage 15.0 (TID 328) in 8 ms on localhost (113/199)
2017-07-01 18:26:34,695  INFO [Executor task launch worker-9] (org.apache.spark.executor.Executor) - Running task 114.0 in stage 15.0 (TID 329)
2017-07-01 18:26:34,710  INFO [Executor task launch worker-9] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,713  INFO [Executor task launch worker-9] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:26:34,714  INFO [Executor task launch worker-9] (org.apache.spark.executor.Executor) - Finished task 114.0 in stage 15.0 (TID 329). 1609 bytes result sent to driver
2017-07-01 18:26:34,715  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,716  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:34,719  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 115.0 in stage 15.0 (TID 330, localhost, partition 116,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,720  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 114.0 in stage 15.0 (TID 329) in 26 ms on localhost (114/199)
2017-07-01 18:26:34,720  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 115.0 in stage 15.0 (TID 330)
2017-07-01 18:26:34,726  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 109.0 in stage 15.0 (TID 324). 1609 bytes result sent to driver
2017-07-01 18:26:34,727  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,728  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:34,729  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 116.0 in stage 15.0 (TID 331, localhost, partition 117,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,730  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 109.0 in stage 15.0 (TID 324) in 82 ms on localhost (115/199)
2017-07-01 18:26:34,731  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 116.0 in stage 15.0 (TID 331)
2017-07-01 18:26:34,732  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 115.0 in stage 15.0 (TID 330). 1609 bytes result sent to driver
2017-07-01 18:26:34,737  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 117.0 in stage 15.0 (TID 332, localhost, partition 118,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,738  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 115.0 in stage 15.0 (TID 330) in 19 ms on localhost (116/199)
2017-07-01 18:26:34,739  INFO [Executor task launch worker-9] (org.apache.spark.executor.Executor) - Running task 117.0 in stage 15.0 (TID 332)
2017-07-01 18:26:34,753  INFO [Executor task launch worker-9] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,754  INFO [Executor task launch worker-9] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:34,757  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,758  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:34,763  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 116.0 in stage 15.0 (TID 331). 1609 bytes result sent to driver
2017-07-01 18:26:34,759  INFO [Executor task launch worker-9] (org.apache.spark.executor.Executor) - Finished task 117.0 in stage 15.0 (TID 332). 1609 bytes result sent to driver
2017-07-01 18:26:34,767  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 118.0 in stage 15.0 (TID 333, localhost, partition 119,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,768  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 116.0 in stage 15.0 (TID 331) in 39 ms on localhost (117/199)
2017-07-01 18:26:34,769  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 118.0 in stage 15.0 (TID 333)
2017-07-01 18:26:34,773  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,774  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 119.0 in stage 15.0 (TID 334, localhost, partition 120,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,775  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 117.0 in stage 15.0 (TID 332) in 38 ms on localhost (118/199)
2017-07-01 18:26:34,775  INFO [Executor task launch worker-9] (org.apache.spark.executor.Executor) - Running task 119.0 in stage 15.0 (TID 334)
2017-07-01 18:26:34,777  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:26:34,786  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 118.0 in stage 15.0 (TID 333). 1609 bytes result sent to driver
2017-07-01 18:26:34,792  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 120.0 in stage 15.0 (TID 335, localhost, partition 121,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,793  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 118.0 in stage 15.0 (TID 333) in 25 ms on localhost (119/199)
2017-07-01 18:26:34,793  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 120.0 in stage 15.0 (TID 335)
2017-07-01 18:26:34,799  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,788  INFO [Executor task launch worker-9] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,802  INFO [Executor task launch worker-9] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 14 ms
2017-07-01 18:26:34,803  INFO [Executor task launch worker-9] (org.apache.spark.executor.Executor) - Finished task 119.0 in stage 15.0 (TID 334). 1609 bytes result sent to driver
2017-07-01 18:26:34,805  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 6 ms
2017-07-01 18:26:34,810  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 121.0 in stage 15.0 (TID 336, localhost, partition 122,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,812  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 119.0 in stage 15.0 (TID 334) in 39 ms on localhost (120/199)
2017-07-01 18:26:34,813  INFO [Executor task launch worker-9] (org.apache.spark.executor.Executor) - Running task 121.0 in stage 15.0 (TID 336)
2017-07-01 18:26:34,816  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 120.0 in stage 15.0 (TID 335). 1609 bytes result sent to driver
2017-07-01 18:26:34,821  INFO [Executor task launch worker-9] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,822  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 122.0 in stage 15.0 (TID 337, localhost, partition 123,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,829  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 120.0 in stage 15.0 (TID 335) in 37 ms on localhost (121/199)
2017-07-01 18:26:34,830  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 122.0 in stage 15.0 (TID 337)
2017-07-01 18:26:34,833  INFO [Executor task launch worker-9] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 12 ms
2017-07-01 18:26:34,834  INFO [Executor task launch worker-9] (org.apache.spark.executor.Executor) - Finished task 121.0 in stage 15.0 (TID 336). 1609 bytes result sent to driver
2017-07-01 18:26:34,835  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,839  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:26:34,840  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 122.0 in stage 15.0 (TID 337). 1609 bytes result sent to driver
2017-07-01 18:26:34,841  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 123.0 in stage 15.0 (TID 338, localhost, partition 124,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,850  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 121.0 in stage 15.0 (TID 336) in 40 ms on localhost (122/199)
2017-07-01 18:26:34,852  INFO [Executor task launch worker-9] (org.apache.spark.executor.Executor) - Running task 123.0 in stage 15.0 (TID 338)
2017-07-01 18:26:34,855  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 124.0 in stage 15.0 (TID 339, localhost, partition 125,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,856  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 122.0 in stage 15.0 (TID 337) in 35 ms on localhost (123/199)
2017-07-01 18:26:34,856  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 124.0 in stage 15.0 (TID 339)
2017-07-01 18:26:34,862  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,863  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:34,865  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 124.0 in stage 15.0 (TID 339). 1609 bytes result sent to driver
2017-07-01 18:26:34,867  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 125.0 in stage 15.0 (TID 340, localhost, partition 126,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,868  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 124.0 in stage 15.0 (TID 339) in 12 ms on localhost (124/199)
2017-07-01 18:26:34,868  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 125.0 in stage 15.0 (TID 340)
2017-07-01 18:26:34,874  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,876  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:34,878  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 125.0 in stage 15.0 (TID 340). 1609 bytes result sent to driver
2017-07-01 18:26:34,880  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 126.0 in stage 15.0 (TID 341, localhost, partition 127,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,880  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 125.0 in stage 15.0 (TID 340) in 13 ms on localhost (125/199)
2017-07-01 18:26:34,883  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 126.0 in stage 15.0 (TID 341)
2017-07-01 18:26:34,890  INFO [Executor task launch worker-9] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,892  INFO [Executor task launch worker-9] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:34,895  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,899  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:26:34,898  INFO [Executor task launch worker-9] (org.apache.spark.executor.Executor) - Finished task 123.0 in stage 15.0 (TID 338). 1609 bytes result sent to driver
2017-07-01 18:26:34,903  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 127.0 in stage 15.0 (TID 342, localhost, partition 128,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,903  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 123.0 in stage 15.0 (TID 338) in 63 ms on localhost (126/199)
2017-07-01 18:26:34,905  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 127.0 in stage 15.0 (TID 342)
2017-07-01 18:26:34,910  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,911  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:34,914  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 127.0 in stage 15.0 (TID 342). 1609 bytes result sent to driver
2017-07-01 18:26:34,914  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 126.0 in stage 15.0 (TID 341). 1609 bytes result sent to driver
2017-07-01 18:26:34,919  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 128.0 in stage 15.0 (TID 343, localhost, partition 129,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,920  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 127.0 in stage 15.0 (TID 342) in 18 ms on localhost (127/199)
2017-07-01 18:26:34,921  INFO [Executor task launch worker-9] (org.apache.spark.executor.Executor) - Running task 128.0 in stage 15.0 (TID 343)
2017-07-01 18:26:34,923  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 129.0 in stage 15.0 (TID 344, localhost, partition 130,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,923  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 126.0 in stage 15.0 (TID 341) in 44 ms on localhost (128/199)
2017-07-01 18:26:34,925  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 129.0 in stage 15.0 (TID 344)
2017-07-01 18:26:34,934  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,934  INFO [Executor task launch worker-9] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,935  INFO [Executor task launch worker-9] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:34,936  INFO [Executor task launch worker-9] (org.apache.spark.executor.Executor) - Finished task 128.0 in stage 15.0 (TID 343). 1609 bytes result sent to driver
2017-07-01 18:26:34,937  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:26:34,939  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 130.0 in stage 15.0 (TID 345, localhost, partition 131,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,939  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 128.0 in stage 15.0 (TID 343) in 20 ms on localhost (129/199)
2017-07-01 18:26:34,940  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 130.0 in stage 15.0 (TID 345)
2017-07-01 18:26:34,944  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,944  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:34,948  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 130.0 in stage 15.0 (TID 345). 1609 bytes result sent to driver
2017-07-01 18:26:34,950  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 131.0 in stage 15.0 (TID 346, localhost, partition 132,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,950  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 130.0 in stage 15.0 (TID 345) in 12 ms on localhost (130/199)
2017-07-01 18:26:34,951  INFO [Executor task launch worker-9] (org.apache.spark.executor.Executor) - Running task 131.0 in stage 15.0 (TID 346)
2017-07-01 18:26:34,949  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 129.0 in stage 15.0 (TID 344). 1609 bytes result sent to driver
2017-07-01 18:26:34,952  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 132.0 in stage 15.0 (TID 347, localhost, partition 133,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,954  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 129.0 in stage 15.0 (TID 344) in 31 ms on localhost (131/199)
2017-07-01 18:26:34,954  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 132.0 in stage 15.0 (TID 347)
2017-07-01 18:26:34,973  INFO [Executor task launch worker-9] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,974  INFO [Executor task launch worker-9] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:34,974  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,975  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:34,976  INFO [Executor task launch worker-9] (org.apache.spark.executor.Executor) - Finished task 131.0 in stage 15.0 (TID 346). 1609 bytes result sent to driver
2017-07-01 18:26:34,977  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 133.0 in stage 15.0 (TID 348, localhost, partition 134,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,977  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 131.0 in stage 15.0 (TID 346) in 28 ms on localhost (132/199)
2017-07-01 18:26:34,980  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 133.0 in stage 15.0 (TID 348)
2017-07-01 18:26:34,988  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:34,988  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:34,990  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 133.0 in stage 15.0 (TID 348). 1609 bytes result sent to driver
2017-07-01 18:26:34,989  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 132.0 in stage 15.0 (TID 347). 1609 bytes result sent to driver
2017-07-01 18:26:34,992  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 134.0 in stage 15.0 (TID 349, localhost, partition 135,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,993  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 133.0 in stage 15.0 (TID 348) in 16 ms on localhost (133/199)
2017-07-01 18:26:34,993  INFO [Executor task launch worker-9] (org.apache.spark.executor.Executor) - Running task 134.0 in stage 15.0 (TID 349)
2017-07-01 18:26:34,995  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 135.0 in stage 15.0 (TID 350, localhost, partition 136,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:34,995  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 132.0 in stage 15.0 (TID 347) in 43 ms on localhost (134/199)
2017-07-01 18:26:35,012  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 135.0 in stage 15.0 (TID 350)
2017-07-01 18:26:35,026  INFO [Executor task launch worker-9] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,026  INFO [Executor task launch worker-9] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:35,027  INFO [Executor task launch worker-9] (org.apache.spark.executor.Executor) - Finished task 134.0 in stage 15.0 (TID 349). 1609 bytes result sent to driver
2017-07-01 18:26:35,028  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,028  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:35,029  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 136.0 in stage 15.0 (TID 351, localhost, partition 137,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,030  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 134.0 in stage 15.0 (TID 349) in 38 ms on localhost (135/199)
2017-07-01 18:26:35,031  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 136.0 in stage 15.0 (TID 351)
2017-07-01 18:26:35,036  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,036  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:35,042  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 136.0 in stage 15.0 (TID 351). 1609 bytes result sent to driver
2017-07-01 18:26:35,044  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 137.0 in stage 15.0 (TID 352, localhost, partition 138,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,045  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 136.0 in stage 15.0 (TID 351) in 16 ms on localhost (136/199)
2017-07-01 18:26:35,046  INFO [Executor task launch worker-9] (org.apache.spark.executor.Executor) - Running task 137.0 in stage 15.0 (TID 352)
2017-07-01 18:26:35,042  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 135.0 in stage 15.0 (TID 350). 1609 bytes result sent to driver
2017-07-01 18:26:35,049  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 138.0 in stage 15.0 (TID 353, localhost, partition 139,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,049  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 135.0 in stage 15.0 (TID 350) in 54 ms on localhost (137/199)
2017-07-01 18:26:35,050  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 138.0 in stage 15.0 (TID 353)
2017-07-01 18:26:35,055  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,058  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:26:35,057  INFO [Executor task launch worker-9] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,058  INFO [Executor task launch worker-9] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:35,059  INFO [Executor task launch worker-9] (org.apache.spark.executor.Executor) - Finished task 137.0 in stage 15.0 (TID 352). 1609 bytes result sent to driver
2017-07-01 18:26:35,062  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 139.0 in stage 15.0 (TID 354, localhost, partition 140,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,062  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 137.0 in stage 15.0 (TID 352) in 18 ms on localhost (138/199)
2017-07-01 18:26:35,063  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 139.0 in stage 15.0 (TID 354)
2017-07-01 18:26:35,067  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,067  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:35,067  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 138.0 in stage 15.0 (TID 353). 1609 bytes result sent to driver
2017-07-01 18:26:35,069  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 140.0 in stage 15.0 (TID 355, localhost, partition 141,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,071  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 138.0 in stage 15.0 (TID 353) in 23 ms on localhost (139/199)
2017-07-01 18:26:35,071  INFO [Executor task launch worker-9] (org.apache.spark.executor.Executor) - Running task 140.0 in stage 15.0 (TID 355)
2017-07-01 18:26:35,074  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 139.0 in stage 15.0 (TID 354). 1609 bytes result sent to driver
2017-07-01 18:26:35,076  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 141.0 in stage 15.0 (TID 356, localhost, partition 142,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,076  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 139.0 in stage 15.0 (TID 354) in 15 ms on localhost (140/199)
2017-07-01 18:26:35,077  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 141.0 in stage 15.0 (TID 356)
2017-07-01 18:26:35,080  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,093  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 13 ms
2017-07-01 18:26:35,092  INFO [Executor task launch worker-9] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,096  INFO [Executor task launch worker-9] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:26:35,099  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 141.0 in stage 15.0 (TID 356). 1609 bytes result sent to driver
2017-07-01 18:26:35,099  INFO [Executor task launch worker-9] (org.apache.spark.executor.Executor) - Finished task 140.0 in stage 15.0 (TID 355). 1609 bytes result sent to driver
2017-07-01 18:26:35,104  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 142.0 in stage 15.0 (TID 357, localhost, partition 143,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,105  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 141.0 in stage 15.0 (TID 356) in 30 ms on localhost (141/199)
2017-07-01 18:26:35,107  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 142.0 in stage 15.0 (TID 357)
2017-07-01 18:26:35,111  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,111  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:35,112  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 143.0 in stage 15.0 (TID 358, localhost, partition 144,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,113  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 140.0 in stage 15.0 (TID 355) in 44 ms on localhost (142/199)
2017-07-01 18:26:35,113  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 143.0 in stage 15.0 (TID 358)
2017-07-01 18:26:35,118  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,119  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:35,120  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 143.0 in stage 15.0 (TID 358). 1609 bytes result sent to driver
2017-07-01 18:26:35,121  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 144.0 in stage 15.0 (TID 359, localhost, partition 145,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,121  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 144.0 in stage 15.0 (TID 359)
2017-07-01 18:26:35,122  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 143.0 in stage 15.0 (TID 358) in 9 ms on localhost (143/199)
2017-07-01 18:26:35,126  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,126  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:35,128  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 144.0 in stage 15.0 (TID 359). 1609 bytes result sent to driver
2017-07-01 18:26:35,128  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 145.0 in stage 15.0 (TID 360, localhost, partition 146,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,129  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 144.0 in stage 15.0 (TID 359) in 9 ms on localhost (144/199)
2017-07-01 18:26:35,129  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 145.0 in stage 15.0 (TID 360)
2017-07-01 18:26:35,134  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,135  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:35,136  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 145.0 in stage 15.0 (TID 360). 1609 bytes result sent to driver
2017-07-01 18:26:35,137  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 146.0 in stage 15.0 (TID 361, localhost, partition 147,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,137  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 146.0 in stage 15.0 (TID 361)
2017-07-01 18:26:35,137  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 145.0 in stage 15.0 (TID 360) in 9 ms on localhost (145/199)
2017-07-01 18:26:35,141  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,141  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:35,142  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 146.0 in stage 15.0 (TID 361). 1609 bytes result sent to driver
2017-07-01 18:26:35,143  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 147.0 in stage 15.0 (TID 362, localhost, partition 148,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,144  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 146.0 in stage 15.0 (TID 361) in 8 ms on localhost (146/199)
2017-07-01 18:26:35,144  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 147.0 in stage 15.0 (TID 362)
2017-07-01 18:26:35,162  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 142.0 in stage 15.0 (TID 357). 1609 bytes result sent to driver
2017-07-01 18:26:35,165  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 148.0 in stage 15.0 (TID 363, localhost, partition 149,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,165  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 142.0 in stage 15.0 (TID 357) in 61 ms on localhost (147/199)
2017-07-01 18:26:35,166  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 148.0 in stage 15.0 (TID 363)
2017-07-01 18:26:35,176  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,177  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:35,178  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 147.0 in stage 15.0 (TID 362). 1609 bytes result sent to driver
2017-07-01 18:26:35,178  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 149.0 in stage 15.0 (TID 364, localhost, partition 150,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,179  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 147.0 in stage 15.0 (TID 362) in 36 ms on localhost (148/199)
2017-07-01 18:26:35,180  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 149.0 in stage 15.0 (TID 364)
2017-07-01 18:26:35,184  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,189  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 5 ms
2017-07-01 18:26:35,188  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,192  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 16 ms
2017-07-01 18:26:35,194  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 148.0 in stage 15.0 (TID 363). 1609 bytes result sent to driver
2017-07-01 18:26:35,207  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 150.0 in stage 15.0 (TID 365, localhost, partition 151,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,208  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 148.0 in stage 15.0 (TID 363) in 44 ms on localhost (149/199)
2017-07-01 18:26:35,208  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 150.0 in stage 15.0 (TID 365)
2017-07-01 18:26:35,215  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 149.0 in stage 15.0 (TID 364). 1609 bytes result sent to driver
2017-07-01 18:26:35,218  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 151.0 in stage 15.0 (TID 366, localhost, partition 152,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,219  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 149.0 in stage 15.0 (TID 364) in 41 ms on localhost (150/199)
2017-07-01 18:26:35,221  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 151.0 in stage 15.0 (TID 366)
2017-07-01 18:26:35,226  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,229  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:26:35,236  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 150.0 in stage 15.0 (TID 365). 1609 bytes result sent to driver
2017-07-01 18:26:35,240  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 152.0 in stage 15.0 (TID 367, localhost, partition 153,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,240  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 150.0 in stage 15.0 (TID 365) in 33 ms on localhost (151/199)
2017-07-01 18:26:35,242  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 152.0 in stage 15.0 (TID 367)
2017-07-01 18:26:35,250  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,252  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:35,255  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,256  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:35,257  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 152.0 in stage 15.0 (TID 367). 1609 bytes result sent to driver
2017-07-01 18:26:35,262  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 153.0 in stage 15.0 (TID 368, localhost, partition 154,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,263  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 152.0 in stage 15.0 (TID 367) in 24 ms on localhost (152/199)
2017-07-01 18:26:35,263  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 153.0 in stage 15.0 (TID 368)
2017-07-01 18:26:35,270  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,273  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:26:35,274  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 153.0 in stage 15.0 (TID 368). 1609 bytes result sent to driver
2017-07-01 18:26:35,278  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 154.0 in stage 15.0 (TID 369, localhost, partition 155,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,278  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 153.0 in stage 15.0 (TID 368) in 16 ms on localhost (153/199)
2017-07-01 18:26:35,279  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 154.0 in stage 15.0 (TID 369)
2017-07-01 18:26:35,283  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,293  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 10 ms
2017-07-01 18:26:35,297  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 154.0 in stage 15.0 (TID 369). 1609 bytes result sent to driver
2017-07-01 18:26:35,303  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 155.0 in stage 15.0 (TID 370, localhost, partition 156,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,304  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 154.0 in stage 15.0 (TID 369) in 26 ms on localhost (154/199)
2017-07-01 18:26:35,306  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 155.0 in stage 15.0 (TID 370)
2017-07-01 18:26:35,311  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 151.0 in stage 15.0 (TID 366). 1965 bytes result sent to driver
2017-07-01 18:26:35,315  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 156.0 in stage 15.0 (TID 371, localhost, partition 157,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,316  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 151.0 in stage 15.0 (TID 366) in 99 ms on localhost (155/199)
2017-07-01 18:26:35,318  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 156.0 in stage 15.0 (TID 371)
2017-07-01 18:26:35,321  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,323  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 12 ms
2017-07-01 18:26:35,329  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 155.0 in stage 15.0 (TID 370). 1609 bytes result sent to driver
2017-07-01 18:26:35,334  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 157.0 in stage 15.0 (TID 372, localhost, partition 158,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,336  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 155.0 in stage 15.0 (TID 370) in 33 ms on localhost (156/199)
2017-07-01 18:26:35,338  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 157.0 in stage 15.0 (TID 372)
2017-07-01 18:26:35,343  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,346  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:26:35,347  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 157.0 in stage 15.0 (TID 372). 1609 bytes result sent to driver
2017-07-01 18:26:35,343  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,353  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 10 ms
2017-07-01 18:26:35,355  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 156.0 in stage 15.0 (TID 371). 1609 bytes result sent to driver
2017-07-01 18:26:35,357  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 158.0 in stage 15.0 (TID 373, localhost, partition 159,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,357  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 157.0 in stage 15.0 (TID 372) in 24 ms on localhost (157/199)
2017-07-01 18:26:35,359  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 158.0 in stage 15.0 (TID 373)
2017-07-01 18:26:35,364  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,364  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 159.0 in stage 15.0 (TID 374, localhost, partition 160,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,370  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 156.0 in stage 15.0 (TID 371) in 55 ms on localhost (158/199)
2017-07-01 18:26:35,372  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 159.0 in stage 15.0 (TID 374)
2017-07-01 18:26:35,375  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 11 ms
2017-07-01 18:26:35,381  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 158.0 in stage 15.0 (TID 373). 1609 bytes result sent to driver
2017-07-01 18:26:35,384  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,384  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 160.0 in stage 15.0 (TID 375, localhost, partition 161,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,390  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 158.0 in stage 15.0 (TID 373) in 34 ms on localhost (159/199)
2017-07-01 18:26:35,392  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 160.0 in stage 15.0 (TID 375)
2017-07-01 18:26:35,395  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 11 ms
2017-07-01 18:26:35,397  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 159.0 in stage 15.0 (TID 374). 1609 bytes result sent to driver
2017-07-01 18:26:35,400  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 161.0 in stage 15.0 (TID 376, localhost, partition 162,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,400  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 159.0 in stage 15.0 (TID 374) in 36 ms on localhost (160/199)
2017-07-01 18:26:35,402  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 161.0 in stage 15.0 (TID 376)
2017-07-01 18:26:35,407  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,408  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:35,410  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 161.0 in stage 15.0 (TID 376). 1609 bytes result sent to driver
2017-07-01 18:26:35,412  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 162.0 in stage 15.0 (TID 377, localhost, partition 163,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,412  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 161.0 in stage 15.0 (TID 376) in 12 ms on localhost (161/199)
2017-07-01 18:26:35,412  INFO [Executor task launch worker-9] (org.apache.spark.executor.Executor) - Running task 162.0 in stage 15.0 (TID 377)
2017-07-01 18:26:35,420  INFO [Executor task launch worker-9] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,421  INFO [Executor task launch worker-9] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:35,423  INFO [Executor task launch worker-9] (org.apache.spark.executor.Executor) - Finished task 162.0 in stage 15.0 (TID 377). 1609 bytes result sent to driver
2017-07-01 18:26:35,426  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 163.0 in stage 15.0 (TID 378, localhost, partition 164,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,426  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 163.0 in stage 15.0 (TID 378)
2017-07-01 18:26:35,426  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 162.0 in stage 15.0 (TID 377) in 15 ms on localhost (162/199)
2017-07-01 18:26:35,432  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,433  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:35,435  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 163.0 in stage 15.0 (TID 378). 1609 bytes result sent to driver
2017-07-01 18:26:35,437  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 164.0 in stage 15.0 (TID 379, localhost, partition 165,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,437  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 164.0 in stage 15.0 (TID 379)
2017-07-01 18:26:35,437  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 163.0 in stage 15.0 (TID 378) in 12 ms on localhost (163/199)
2017-07-01 18:26:35,443  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,444  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:35,445  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 164.0 in stage 15.0 (TID 379). 1609 bytes result sent to driver
2017-07-01 18:26:35,447  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 165.0 in stage 15.0 (TID 380, localhost, partition 166,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,448  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 165.0 in stage 15.0 (TID 380)
2017-07-01 18:26:35,449  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 164.0 in stage 15.0 (TID 379) in 13 ms on localhost (164/199)
2017-07-01 18:26:35,454  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,454  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:35,456  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 165.0 in stage 15.0 (TID 380). 1609 bytes result sent to driver
2017-07-01 18:26:35,458  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 166.0 in stage 15.0 (TID 381, localhost, partition 167,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,458  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 165.0 in stage 15.0 (TID 380) in 11 ms on localhost (165/199)
2017-07-01 18:26:35,460  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 166.0 in stage 15.0 (TID 381)
2017-07-01 18:26:35,468  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,472  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:26:35,469  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,476  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 8 ms
2017-07-01 18:26:35,478  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 160.0 in stage 15.0 (TID 375). 1609 bytes result sent to driver
2017-07-01 18:26:35,480  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 167.0 in stage 15.0 (TID 382, localhost, partition 168,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,480  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 160.0 in stage 15.0 (TID 375) in 96 ms on localhost (166/199)
2017-07-01 18:26:35,482  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 167.0 in stage 15.0 (TID 382)
2017-07-01 18:26:35,489  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 166.0 in stage 15.0 (TID 381). 1609 bytes result sent to driver
2017-07-01 18:26:35,489  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,493  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:26:35,495  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 168.0 in stage 15.0 (TID 383, localhost, partition 169,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,496  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 166.0 in stage 15.0 (TID 381) in 39 ms on localhost (167/199)
2017-07-01 18:26:35,498  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 168.0 in stage 15.0 (TID 383)
2017-07-01 18:26:35,504  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,514  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 10 ms
2017-07-01 18:26:35,513  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 167.0 in stage 15.0 (TID 382). 1609 bytes result sent to driver
2017-07-01 18:26:35,518  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 169.0 in stage 15.0 (TID 384, localhost, partition 170,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,519  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 167.0 in stage 15.0 (TID 382) in 40 ms on localhost (168/199)
2017-07-01 18:26:35,520  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 169.0 in stage 15.0 (TID 384)
2017-07-01 18:26:35,525  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,532  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 7 ms
2017-07-01 18:26:35,527  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 168.0 in stage 15.0 (TID 383). 1609 bytes result sent to driver
2017-07-01 18:26:35,538  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 170.0 in stage 15.0 (TID 385, localhost, partition 171,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,539  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 168.0 in stage 15.0 (TID 383) in 44 ms on localhost (169/199)
2017-07-01 18:26:35,541  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 170.0 in stage 15.0 (TID 385)
2017-07-01 18:26:35,546  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,550  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 5 ms
2017-07-01 18:26:35,535  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 169.0 in stage 15.0 (TID 384). 1609 bytes result sent to driver
2017-07-01 18:26:35,553  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 171.0 in stage 15.0 (TID 386, localhost, partition 172,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,554  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 169.0 in stage 15.0 (TID 384) in 37 ms on localhost (170/199)
2017-07-01 18:26:35,556  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 171.0 in stage 15.0 (TID 386)
2017-07-01 18:26:35,560  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,567  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 7 ms
2017-07-01 18:26:35,561  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 170.0 in stage 15.0 (TID 385). 1609 bytes result sent to driver
2017-07-01 18:26:35,570  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 172.0 in stage 15.0 (TID 387, localhost, partition 173,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,570  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 170.0 in stage 15.0 (TID 385) in 32 ms on localhost (171/199)
2017-07-01 18:26:35,572  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 172.0 in stage 15.0 (TID 387)
2017-07-01 18:26:35,582  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 171.0 in stage 15.0 (TID 386). 1609 bytes result sent to driver
2017-07-01 18:26:35,586  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 173.0 in stage 15.0 (TID 388, localhost, partition 174,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,587  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 171.0 in stage 15.0 (TID 386) in 34 ms on localhost (172/199)
2017-07-01 18:26:35,588  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 173.0 in stage 15.0 (TID 388)
2017-07-01 18:26:35,592  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,595  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:26:35,594  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,602  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 8 ms
2017-07-01 18:26:35,605  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 173.0 in stage 15.0 (TID 388). 1609 bytes result sent to driver
2017-07-01 18:26:35,602  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 172.0 in stage 15.0 (TID 387). 1609 bytes result sent to driver
2017-07-01 18:26:35,610  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 174.0 in stage 15.0 (TID 389, localhost, partition 175,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,611  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 173.0 in stage 15.0 (TID 388) in 24 ms on localhost (173/199)
2017-07-01 18:26:35,611  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 174.0 in stage 15.0 (TID 389)
2017-07-01 18:26:35,616  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 175.0 in stage 15.0 (TID 390, localhost, partition 176,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,616  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 172.0 in stage 15.0 (TID 387) in 46 ms on localhost (174/199)
2017-07-01 18:26:35,616  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 175.0 in stage 15.0 (TID 390)
2017-07-01 18:26:35,620  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,621  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:35,622  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 175.0 in stage 15.0 (TID 390). 1609 bytes result sent to driver
2017-07-01 18:26:35,623  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 176.0 in stage 15.0 (TID 391, localhost, partition 177,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,623  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 175.0 in stage 15.0 (TID 390) in 8 ms on localhost (175/199)
2017-07-01 18:26:35,624  INFO [Executor task launch worker-9] (org.apache.spark.executor.Executor) - Running task 176.0 in stage 15.0 (TID 391)
2017-07-01 18:26:35,628  INFO [Executor task launch worker-9] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,628  INFO [Executor task launch worker-9] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:35,629  INFO [Executor task launch worker-9] (org.apache.spark.executor.Executor) - Finished task 176.0 in stage 15.0 (TID 391). 1609 bytes result sent to driver
2017-07-01 18:26:35,629  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 177.0 in stage 15.0 (TID 392, localhost, partition 178,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,630  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 176.0 in stage 15.0 (TID 391) in 7 ms on localhost (176/199)
2017-07-01 18:26:35,630  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 177.0 in stage 15.0 (TID 392)
2017-07-01 18:26:35,635  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,635  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:35,636  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 177.0 in stage 15.0 (TID 392). 1609 bytes result sent to driver
2017-07-01 18:26:35,637  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 178.0 in stage 15.0 (TID 393, localhost, partition 179,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,637  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 178.0 in stage 15.0 (TID 393)
2017-07-01 18:26:35,637  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 177.0 in stage 15.0 (TID 392) in 8 ms on localhost (177/199)
2017-07-01 18:26:35,642  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,642  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:35,643  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 178.0 in stage 15.0 (TID 393). 1609 bytes result sent to driver
2017-07-01 18:26:35,644  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 179.0 in stage 15.0 (TID 394, localhost, partition 180,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,644  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 178.0 in stage 15.0 (TID 393) in 8 ms on localhost (178/199)
2017-07-01 18:26:35,653  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 179.0 in stage 15.0 (TID 394)
2017-07-01 18:26:35,656  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,656  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 41 ms
2017-07-01 18:26:35,661  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 174.0 in stage 15.0 (TID 389). 1609 bytes result sent to driver
2017-07-01 18:26:35,666  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 180.0 in stage 15.0 (TID 395, localhost, partition 181,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,666  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 174.0 in stage 15.0 (TID 389) in 56 ms on localhost (179/199)
2017-07-01 18:26:35,667  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 180.0 in stage 15.0 (TID 395)
2017-07-01 18:26:35,670  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,675  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 5 ms
2017-07-01 18:26:35,677  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 180.0 in stage 15.0 (TID 395). 1609 bytes result sent to driver
2017-07-01 18:26:35,664  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,679  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 15 ms
2017-07-01 18:26:35,680  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 179.0 in stage 15.0 (TID 394). 1609 bytes result sent to driver
2017-07-01 18:26:35,680  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 181.0 in stage 15.0 (TID 396, localhost, partition 182,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,682  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 180.0 in stage 15.0 (TID 395) in 16 ms on localhost (180/199)
2017-07-01 18:26:35,682  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 181.0 in stage 15.0 (TID 396)
2017-07-01 18:26:35,692  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 182.0 in stage 15.0 (TID 397, localhost, partition 183,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,692  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 179.0 in stage 15.0 (TID 394) in 48 ms on localhost (181/199)
2017-07-01 18:26:35,692  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 182.0 in stage 15.0 (TID 397)
2017-07-01 18:26:35,699  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,700  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:35,702  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 182.0 in stage 15.0 (TID 397). 1609 bytes result sent to driver
2017-07-01 18:26:35,703  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 183.0 in stage 15.0 (TID 398, localhost, partition 184,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,704  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 182.0 in stage 15.0 (TID 397) in 13 ms on localhost (182/199)
2017-07-01 18:26:35,706  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 183.0 in stage 15.0 (TID 398)
2017-07-01 18:26:35,709  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,712  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:26:35,719  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 181.0 in stage 15.0 (TID 396). 1609 bytes result sent to driver
2017-07-01 18:26:35,723  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 184.0 in stage 15.0 (TID 399, localhost, partition 185,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,723  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 181.0 in stage 15.0 (TID 396) in 43 ms on localhost (183/199)
2017-07-01 18:26:35,726  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 184.0 in stage 15.0 (TID 399)
2017-07-01 18:26:35,730  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,732  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:35,733  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,736  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:26:35,735  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 184.0 in stage 15.0 (TID 399). 1609 bytes result sent to driver
2017-07-01 18:26:35,741  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 185.0 in stage 15.0 (TID 400, localhost, partition 186,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,742  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 184.0 in stage 15.0 (TID 399) in 19 ms on localhost (184/199)
2017-07-01 18:26:35,744  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 185.0 in stage 15.0 (TID 400)
2017-07-01 18:26:35,748  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,755  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 7 ms
2017-07-01 18:26:35,739  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 183.0 in stage 15.0 (TID 398). 1609 bytes result sent to driver
2017-07-01 18:26:35,759  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 186.0 in stage 15.0 (TID 401, localhost, partition 187,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,759  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 183.0 in stage 15.0 (TID 398) in 56 ms on localhost (185/199)
2017-07-01 18:26:35,762  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 186.0 in stage 15.0 (TID 401)
2017-07-01 18:26:35,766  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,772  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 6 ms
2017-07-01 18:26:35,768  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 185.0 in stage 15.0 (TID 400). 1609 bytes result sent to driver
2017-07-01 18:26:35,774  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 187.0 in stage 15.0 (TID 402, localhost, partition 188,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,775  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 185.0 in stage 15.0 (TID 400) in 35 ms on localhost (186/199)
2017-07-01 18:26:35,777  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 187.0 in stage 15.0 (TID 402)
2017-07-01 18:26:35,782  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,786  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:26:35,783  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 186.0 in stage 15.0 (TID 401). 1609 bytes result sent to driver
2017-07-01 18:26:35,790  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 188.0 in stage 15.0 (TID 403, localhost, partition 189,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,791  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 186.0 in stage 15.0 (TID 401) in 33 ms on localhost (187/199)
2017-07-01 18:26:35,793  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 188.0 in stage 15.0 (TID 403)
2017-07-01 18:26:35,800  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,808  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 8 ms
2017-07-01 18:26:35,801  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 187.0 in stage 15.0 (TID 402). 1609 bytes result sent to driver
2017-07-01 18:26:35,810  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 189.0 in stage 15.0 (TID 404, localhost, partition 190,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,811  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 187.0 in stage 15.0 (TID 402) in 37 ms on localhost (188/199)
2017-07-01 18:26:35,813  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 189.0 in stage 15.0 (TID 404)
2017-07-01 18:26:35,819  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,823  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 5 ms
2017-07-01 18:26:35,825  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 189.0 in stage 15.0 (TID 404). 1609 bytes result sent to driver
2017-07-01 18:26:35,821  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 188.0 in stage 15.0 (TID 403). 1609 bytes result sent to driver
2017-07-01 18:26:35,832  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 190.0 in stage 15.0 (TID 405, localhost, partition 191,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,833  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 189.0 in stage 15.0 (TID 404) in 22 ms on localhost (189/199)
2017-07-01 18:26:35,833  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 190.0 in stage 15.0 (TID 405)
2017-07-01 18:26:35,837  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 191.0 in stage 15.0 (TID 406, localhost, partition 192,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,838  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 188.0 in stage 15.0 (TID 403) in 48 ms on localhost (190/199)
2017-07-01 18:26:35,838  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 191.0 in stage 15.0 (TID 406)
2017-07-01 18:26:35,843  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,843  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:35,844  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 191.0 in stage 15.0 (TID 406). 1609 bytes result sent to driver
2017-07-01 18:26:35,845  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 192.0 in stage 15.0 (TID 407, localhost, partition 193,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,845  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 191.0 in stage 15.0 (TID 406) in 8 ms on localhost (191/199)
2017-07-01 18:26:35,846  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 192.0 in stage 15.0 (TID 407)
2017-07-01 18:26:35,847  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,849  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:35,850  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 190.0 in stage 15.0 (TID 405). 1609 bytes result sent to driver
2017-07-01 18:26:35,852  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 193.0 in stage 15.0 (TID 408, localhost, partition 194,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,852  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 190.0 in stage 15.0 (TID 405) in 20 ms on localhost (192/199)
2017-07-01 18:26:35,853  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 193.0 in stage 15.0 (TID 408)
2017-07-01 18:26:35,860  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,867  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 7 ms
2017-07-01 18:26:35,862  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,869  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 7 ms
2017-07-01 18:26:35,881  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 192.0 in stage 15.0 (TID 407). 1609 bytes result sent to driver
2017-07-01 18:26:35,886  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 194.0 in stage 15.0 (TID 409, localhost, partition 195,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,886  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 192.0 in stage 15.0 (TID 407) in 42 ms on localhost (193/199)
2017-07-01 18:26:35,887  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 194.0 in stage 15.0 (TID 409)
2017-07-01 18:26:35,891  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,892  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:35,893  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 194.0 in stage 15.0 (TID 409). 1609 bytes result sent to driver
2017-07-01 18:26:35,893  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 193.0 in stage 15.0 (TID 408). 1609 bytes result sent to driver
2017-07-01 18:26:35,894  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 195.0 in stage 15.0 (TID 410, localhost, partition 196,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,894  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 194.0 in stage 15.0 (TID 409) in 9 ms on localhost (194/199)
2017-07-01 18:26:35,895  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 195.0 in stage 15.0 (TID 410)
2017-07-01 18:26:35,896  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 196.0 in stage 15.0 (TID 411, localhost, partition 197,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,897  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 193.0 in stage 15.0 (TID 408) in 45 ms on localhost (195/199)
2017-07-01 18:26:35,898  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 196.0 in stage 15.0 (TID 411)
2017-07-01 18:26:35,908  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,909  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:35,908  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,916  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 8 ms
2017-07-01 18:26:35,919  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 195.0 in stage 15.0 (TID 410). 1609 bytes result sent to driver
2017-07-01 18:26:35,921  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 197.0 in stage 15.0 (TID 412, localhost, partition 198,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,922  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 195.0 in stage 15.0 (TID 410) in 28 ms on localhost (196/199)
2017-07-01 18:26:35,924  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 197.0 in stage 15.0 (TID 412)
2017-07-01 18:26:35,929  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,931  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:35,935  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 196.0 in stage 15.0 (TID 411). 1609 bytes result sent to driver
2017-07-01 18:26:35,935  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 197.0 in stage 15.0 (TID 412). 1609 bytes result sent to driver
2017-07-01 18:26:35,938  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 198.0 in stage 15.0 (TID 413, localhost, partition 199,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:35,939  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 196.0 in stage 15.0 (TID 411) in 43 ms on localhost (197/199)
2017-07-01 18:26:35,940  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 198.0 in stage 15.0 (TID 413)
2017-07-01 18:26:35,944  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:35,945  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 197.0 in stage 15.0 (TID 412) in 24 ms on localhost (198/199)
2017-07-01 18:26:35,955  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 11 ms
2017-07-01 18:26:35,958  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 198.0 in stage 15.0 (TID 413). 1609 bytes result sent to driver
2017-07-01 18:26:35,961  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 198.0 in stage 15.0 (TID 413) in 23 ms on localhost (199/199)
2017-07-01 18:26:35,961  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 15.0, whose tasks have all completed, from pool 
2017-07-01 18:26:35,961  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 15 (show at <console>:65) finished in 2,976 s
2017-07-01 18:26:35,962  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.scheduler.DAGScheduler) - Job 11 finished: show at <console>:65, took 3,049127 s
2017-07-01 18:26:36,745  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 37
2017-07-01 18:26:36,748  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned shuffle 1
2017-07-01 18:26:36,748  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 34
2017-07-01 18:26:36,748  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 33
2017-07-01 18:26:36,748  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 32
2017-07-01 18:26:36,748  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 31
2017-07-01 18:26:36,748  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 30
2017-07-01 18:26:36,748  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 29
2017-07-01 18:26:36,748  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 28
2017-07-01 18:26:36,748  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 27
2017-07-01 18:26:36,752  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_23_piece0 on localhost:56220 in memory (size: 19.6 KB, free: 116.4 MB)
2017-07-01 18:26:36,755  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_26_piece0 on localhost:56220 in memory (size: 7.0 KB, free: 116.4 MB)
2017-07-01 18:26:47,516  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.storage.MemoryStore) - Block broadcast_27 stored as values in memory (estimated size 187.4 KB, free 187.4 KB)
2017-07-01 18:26:47,559  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.storage.MemoryStore) - Block broadcast_27_piece0 stored as bytes in memory (estimated size 19.5 KB, free 206.9 KB)
2017-07-01 18:26:47,559  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_27_piece0 in memory on localhost:56220 (size: 19.5 KB, free: 116.4 MB)
2017-07-01 18:26:47,577  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.SparkContext) - Created broadcast 27 from show at <console>:65
2017-07-01 18:26:47,590  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.storage.MemoryStore) - Block broadcast_28 stored as values in memory (estimated size 188.0 KB, free 394.9 KB)
2017-07-01 18:26:47,631  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.storage.MemoryStore) - Block broadcast_28_piece0 stored as bytes in memory (estimated size 19.6 KB, free 414.5 KB)
2017-07-01 18:26:47,632  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_28_piece0 in memory on localhost:56220 (size: 19.6 KB, free: 116.4 MB)
2017-07-01 18:26:47,636  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.SparkContext) - Created broadcast 28 from show at <console>:65
2017-07-01 18:26:47,691  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.hadoop.mapred.FileInputFormat) - Total input paths to process : 1
2017-07-01 18:26:47,742  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.SparkContext) - Starting job: show at <console>:65
2017-07-01 18:26:47,745  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Registering RDD 57 (show at <console>:65)
2017-07-01 18:26:47,745  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 12 (show at <console>:65) with 1 output partitions
2017-07-01 18:26:47,745  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 17 (show at <console>:65)
2017-07-01 18:26:47,746  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List(ShuffleMapStage 16)
2017-07-01 18:26:47,746  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List(ShuffleMapStage 16)
2017-07-01 18:26:47,746  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ShuffleMapStage 16 (MapPartitionsRDD[57] at show at <console>:65), which has no missing parents
2017-07-01 18:26:47,753  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_29 stored as values in memory (estimated size 11.2 KB, free 425.7 KB)
2017-07-01 18:26:47,757  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_29_piece0 stored as bytes in memory (estimated size 5.7 KB, free 431.4 KB)
2017-07-01 18:26:47,757  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_29_piece0 in memory on localhost:56220 (size: 5.7 KB, free: 116.4 MB)
2017-07-01 18:26:47,759  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 29 from broadcast at DAGScheduler.scala:1006
2017-07-01 18:26:47,759  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[57] at show at <console>:65)
2017-07-01 18:26:47,759  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 16.0 with 2 tasks
2017-07-01 18:26:47,760  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 16.0 (TID 414, localhost, partition 0,PROCESS_LOCAL, 2187 bytes)
2017-07-01 18:26:47,764  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 16.0 (TID 415, localhost, partition 1,PROCESS_LOCAL, 2187 bytes)
2017-07-01 18:26:47,764  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 16.0 (TID 414)
2017-07-01 18:26:47,765  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 16.0 (TID 415)
2017-07-01 18:26:47,769  INFO [Executor task launch worker-5] (org.apache.spark.rdd.HadoopRDD) - Input split: file:/home/turmasabado/spark-notebook/produtos.json:0+500
2017-07-01 18:26:47,773  INFO [Executor task launch worker-6] (org.apache.spark.rdd.HadoopRDD) - Input split: file:/home/turmasabado/spark-notebook/produtos.json:500+501
2017-07-01 18:26:47,780  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 16.0 (TID 415). 2702 bytes result sent to driver
2017-07-01 18:26:47,783  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 16.0 (TID 415) in 23 ms on localhost (1/2)
2017-07-01 18:26:47,855  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 16.0 (TID 414). 2702 bytes result sent to driver
2017-07-01 18:26:47,858  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 16.0 (TID 414) in 97 ms on localhost (2/2)
2017-07-01 18:26:47,858  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ShuffleMapStage 16 (show at <console>:65) finished in 0,099 s
2017-07-01 18:26:47,858  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - looking for newly runnable stages
2017-07-01 18:26:47,858  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - running: Set()
2017-07-01 18:26:47,858  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - waiting: Set(ResultStage 17)
2017-07-01 18:26:47,858  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - failed: Set()
2017-07-01 18:26:47,858  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 16.0, whose tasks have all completed, from pool 
2017-07-01 18:26:47,859  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 17 (MapPartitionsRDD[61] at show at <console>:65), which has no missing parents
2017-07-01 18:26:47,861  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_30 stored as values in memory (estimated size 13.1 KB, free 444.5 KB)
2017-07-01 18:26:47,866  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_30_piece0 stored as bytes in memory (estimated size 7.0 KB, free 451.5 KB)
2017-07-01 18:26:47,867  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_30_piece0 in memory on localhost:56220 (size: 7.0 KB, free: 116.4 MB)
2017-07-01 18:26:47,868  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 30 from broadcast at DAGScheduler.scala:1006
2017-07-01 18:26:47,869  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[61] at show at <console>:65)
2017-07-01 18:26:47,869  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 17.0 with 1 tasks
2017-07-01 18:26:47,871  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 17.0 (TID 416, localhost, partition 0,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:47,872  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 17.0 (TID 416)
2017-07-01 18:26:47,877  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:47,878  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:47,879  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 17.0 (TID 416). 1609 bytes result sent to driver
2017-07-01 18:26:47,879  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 17.0 (TID 416) in 8 ms on localhost (1/1)
2017-07-01 18:26:47,879  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 17.0, whose tasks have all completed, from pool 
2017-07-01 18:26:47,880  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 17 (show at <console>:65) finished in 0,008 s
2017-07-01 18:26:47,881  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.scheduler.DAGScheduler) - Job 12 finished: show at <console>:65, took 0,138547 s
2017-07-01 18:26:47,891  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.SparkContext) - Starting job: show at <console>:65
2017-07-01 18:26:47,894  INFO [dag-scheduler-event-loop] (org.apache.spark.MapOutputTrackerMaster) - Size of output statuses for shuffle 2 is 169 bytes
2017-07-01 18:26:47,895  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 13 (show at <console>:65) with 199 output partitions
2017-07-01 18:26:47,896  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 19 (show at <console>:65)
2017-07-01 18:26:47,896  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List(ShuffleMapStage 18)
2017-07-01 18:26:47,896  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2017-07-01 18:26:47,904  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 19 (MapPartitionsRDD[61] at show at <console>:65), which has no missing parents
2017-07-01 18:26:47,932  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_31 stored as values in memory (estimated size 13.1 KB, free 464.6 KB)
2017-07-01 18:26:47,935  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_31_piece0 stored as bytes in memory (estimated size 7.0 KB, free 471.6 KB)
2017-07-01 18:26:47,936  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_31_piece0 in memory on localhost:56220 (size: 7.0 KB, free: 116.4 MB)
2017-07-01 18:26:47,937  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 31 from broadcast at DAGScheduler.scala:1006
2017-07-01 18:26:47,940  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 199 missing tasks from ResultStage 19 (MapPartitionsRDD[61] at show at <console>:65)
2017-07-01 18:26:47,942  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 19.0 with 199 tasks
2017-07-01 18:26:47,944  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 19.0 (TID 417, localhost, partition 1,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:47,944  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 19.0 (TID 418, localhost, partition 2,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:47,944  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 19.0 (TID 418)
2017-07-01 18:26:47,945  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 19.0 (TID 417)
2017-07-01 18:26:47,952  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:47,953  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:47,953  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:47,955  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:47,958  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 19.0 (TID 417). 1609 bytes result sent to driver
2017-07-01 18:26:47,958  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 2.0 in stage 19.0 (TID 419, localhost, partition 3,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:47,959  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 19.0 (TID 417) in 15 ms on localhost (1/199)
2017-07-01 18:26:47,960  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 2.0 in stage 19.0 (TID 419)
2017-07-01 18:26:47,962  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 19.0 (TID 418). 1609 bytes result sent to driver
2017-07-01 18:26:47,964  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 3.0 in stage 19.0 (TID 420, localhost, partition 4,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:47,964  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 3.0 in stage 19.0 (TID 420)
2017-07-01 18:26:47,965  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 19.0 (TID 418) in 21 ms on localhost (2/199)
2017-07-01 18:26:47,971  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:47,972  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:47,975  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 3.0 in stage 19.0 (TID 420). 1609 bytes result sent to driver
2017-07-01 18:26:47,976  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 4.0 in stage 19.0 (TID 421, localhost, partition 5,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:47,977  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 4.0 in stage 19.0 (TID 421)
2017-07-01 18:26:47,978  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 3.0 in stage 19.0 (TID 420) in 13 ms on localhost (3/199)
2017-07-01 18:26:47,983  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:47,984  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:47,986  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 4.0 in stage 19.0 (TID 421). 1609 bytes result sent to driver
2017-07-01 18:26:47,988  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 5.0 in stage 19.0 (TID 422, localhost, partition 6,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:47,989  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 5.0 in stage 19.0 (TID 422)
2017-07-01 18:26:47,989  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 4.0 in stage 19.0 (TID 421) in 13 ms on localhost (4/199)
2017-07-01 18:26:47,994  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:47,994  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:47,995  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 5.0 in stage 19.0 (TID 422). 1609 bytes result sent to driver
2017-07-01 18:26:47,996  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 6.0 in stage 19.0 (TID 423, localhost, partition 7,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:47,997  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 6.0 in stage 19.0 (TID 423)
2017-07-01 18:26:47,997  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 5.0 in stage 19.0 (TID 422) in 9 ms on localhost (5/199)
2017-07-01 18:26:48,001  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,002  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:48,003  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,003  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:48,004  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 6.0 in stage 19.0 (TID 423). 1609 bytes result sent to driver
2017-07-01 18:26:48,005  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 7.0 in stage 19.0 (TID 424, localhost, partition 8,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,005  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 6.0 in stage 19.0 (TID 423) in 9 ms on localhost (6/199)
2017-07-01 18:26:48,004  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 2.0 in stage 19.0 (TID 419). 1609 bytes result sent to driver
2017-07-01 18:26:48,007  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 8.0 in stage 19.0 (TID 425, localhost, partition 9,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,006  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 7.0 in stage 19.0 (TID 424)
2017-07-01 18:26:48,008  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 2.0 in stage 19.0 (TID 419) in 50 ms on localhost (7/199)
2017-07-01 18:26:48,009  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 8.0 in stage 19.0 (TID 425)
2017-07-01 18:26:48,016  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,017  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:48,019  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 8.0 in stage 19.0 (TID 425). 1609 bytes result sent to driver
2017-07-01 18:26:48,020  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 9.0 in stage 19.0 (TID 426, localhost, partition 10,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,023  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 8.0 in stage 19.0 (TID 425) in 15 ms on localhost (8/199)
2017-07-01 18:26:48,023  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 9.0 in stage 19.0 (TID 426)
2017-07-01 18:26:48,028  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,028  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,031  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 9.0 in stage 19.0 (TID 426). 1609 bytes result sent to driver
2017-07-01 18:26:48,033  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 10.0 in stage 19.0 (TID 427, localhost, partition 11,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,033  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,036  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 10.0 in stage 19.0 (TID 427)
2017-07-01 18:26:48,034  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 9.0 in stage 19.0 (TID 426) in 14 ms on localhost (9/199)
2017-07-01 18:26:48,041  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 8 ms
2017-07-01 18:26:48,042  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 7.0 in stage 19.0 (TID 424). 1609 bytes result sent to driver
2017-07-01 18:26:48,046  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 11.0 in stage 19.0 (TID 428, localhost, partition 12,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,046  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 7.0 in stage 19.0 (TID 424) in 41 ms on localhost (10/199)
2017-07-01 18:26:48,047  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 11.0 in stage 19.0 (TID 428)
2017-07-01 18:26:48,050  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,050  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,052  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,053  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:48,054  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 10.0 in stage 19.0 (TID 427). 1609 bytes result sent to driver
2017-07-01 18:26:48,054  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 11.0 in stage 19.0 (TID 428). 1609 bytes result sent to driver
2017-07-01 18:26:48,055  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 12.0 in stage 19.0 (TID 429, localhost, partition 13,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,055  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 10.0 in stage 19.0 (TID 427) in 24 ms on localhost (11/199)
2017-07-01 18:26:48,056  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 12.0 in stage 19.0 (TID 429)
2017-07-01 18:26:48,059  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,059  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,060  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 13.0 in stage 19.0 (TID 430, localhost, partition 14,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,060  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 11.0 in stage 19.0 (TID 428) in 15 ms on localhost (12/199)
2017-07-01 18:26:48,061  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 13.0 in stage 19.0 (TID 430)
2017-07-01 18:26:48,064  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,064  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,065  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 12.0 in stage 19.0 (TID 429). 1609 bytes result sent to driver
2017-07-01 18:26:48,066  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 14.0 in stage 19.0 (TID 431, localhost, partition 15,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,066  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 12.0 in stage 19.0 (TID 429) in 12 ms on localhost (13/199)
2017-07-01 18:26:48,067  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 14.0 in stage 19.0 (TID 431)
2017-07-01 18:26:48,070  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,070  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,072  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 14.0 in stage 19.0 (TID 431). 1609 bytes result sent to driver
2017-07-01 18:26:48,072  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 15.0 in stage 19.0 (TID 432, localhost, partition 16,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,072  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 14.0 in stage 19.0 (TID 431) in 7 ms on localhost (14/199)
2017-07-01 18:26:48,075  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 15.0 in stage 19.0 (TID 432)
2017-07-01 18:26:48,096  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,097  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:48,096  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 13.0 in stage 19.0 (TID 430). 1963 bytes result sent to driver
2017-07-01 18:26:48,097  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 16.0 in stage 19.0 (TID 433, localhost, partition 17,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,098  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 13.0 in stage 19.0 (TID 430) in 39 ms on localhost (15/199)
2017-07-01 18:26:48,098  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 16.0 in stage 19.0 (TID 433)
2017-07-01 18:26:48,099  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 15.0 in stage 19.0 (TID 432). 1609 bytes result sent to driver
2017-07-01 18:26:48,099  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 17.0 in stage 19.0 (TID 434, localhost, partition 18,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,100  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 15.0 in stage 19.0 (TID 432) in 27 ms on localhost (16/199)
2017-07-01 18:26:48,101  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 17.0 in stage 19.0 (TID 434)
2017-07-01 18:26:48,104  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,104  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,107  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,107  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,108  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 16.0 in stage 19.0 (TID 433). 1609 bytes result sent to driver
2017-07-01 18:26:48,108  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 18.0 in stage 19.0 (TID 435, localhost, partition 19,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,109  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 16.0 in stage 19.0 (TID 433) in 12 ms on localhost (17/199)
2017-07-01 18:26:48,109  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 18.0 in stage 19.0 (TID 435)
2017-07-01 18:26:48,111  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 17.0 in stage 19.0 (TID 434). 1609 bytes result sent to driver
2017-07-01 18:26:48,113  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,113  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,114  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 19.0 in stage 19.0 (TID 436, localhost, partition 20,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,114  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 17.0 in stage 19.0 (TID 434) in 15 ms on localhost (18/199)
2017-07-01 18:26:48,115  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 19.0 in stage 19.0 (TID 436)
2017-07-01 18:26:48,115  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 18.0 in stage 19.0 (TID 435). 1609 bytes result sent to driver
2017-07-01 18:26:48,116  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 20.0 in stage 19.0 (TID 437, localhost, partition 21,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,116  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 18.0 in stage 19.0 (TID 435) in 8 ms on localhost (19/199)
2017-07-01 18:26:48,116  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 20.0 in stage 19.0 (TID 437)
2017-07-01 18:26:48,121  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,121  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,124  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 19.0 in stage 19.0 (TID 436). 1609 bytes result sent to driver
2017-07-01 18:26:48,130  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 21.0 in stage 19.0 (TID 438, localhost, partition 22,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,130  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 19.0 in stage 19.0 (TID 436) in 16 ms on localhost (20/199)
2017-07-01 18:26:48,133  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 21.0 in stage 19.0 (TID 438)
2017-07-01 18:26:48,137  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,140  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:26:48,143  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,143  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,144  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 20.0 in stage 19.0 (TID 437). 1609 bytes result sent to driver
2017-07-01 18:26:48,146  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 22.0 in stage 19.0 (TID 439, localhost, partition 23,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,146  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 20.0 in stage 19.0 (TID 437) in 31 ms on localhost (21/199)
2017-07-01 18:26:48,147  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 21.0 in stage 19.0 (TID 438). 1609 bytes result sent to driver
2017-07-01 18:26:48,147  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 23.0 in stage 19.0 (TID 440, localhost, partition 24,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,147  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 23.0 in stage 19.0 (TID 440)
2017-07-01 18:26:48,148  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 21.0 in stage 19.0 (TID 438) in 18 ms on localhost (22/199)
2017-07-01 18:26:48,152  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 22.0 in stage 19.0 (TID 439)
2017-07-01 18:26:48,158  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,158  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,159  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 23.0 in stage 19.0 (TID 440). 1609 bytes result sent to driver
2017-07-01 18:26:48,162  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 24.0 in stage 19.0 (TID 441, localhost, partition 25,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,162  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 24.0 in stage 19.0 (TID 441)
2017-07-01 18:26:48,163  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 23.0 in stage 19.0 (TID 440) in 16 ms on localhost (23/199)
2017-07-01 18:26:48,169  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,169  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,170  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,172  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:48,175  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 24.0 in stage 19.0 (TID 441). 1609 bytes result sent to driver
2017-07-01 18:26:48,176  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 25.0 in stage 19.0 (TID 442, localhost, partition 26,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,176  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 24.0 in stage 19.0 (TID 441) in 15 ms on localhost (24/199)
2017-07-01 18:26:48,176  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 25.0 in stage 19.0 (TID 442)
2017-07-01 18:26:48,179  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 22.0 in stage 19.0 (TID 439). 1609 bytes result sent to driver
2017-07-01 18:26:48,181  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 26.0 in stage 19.0 (TID 443, localhost, partition 27,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,181  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 22.0 in stage 19.0 (TID 439) in 35 ms on localhost (25/199)
2017-07-01 18:26:48,182  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 26.0 in stage 19.0 (TID 443)
2017-07-01 18:26:48,187  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,187  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,190  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 25.0 in stage 19.0 (TID 442). 1609 bytes result sent to driver
2017-07-01 18:26:48,190  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 27.0 in stage 19.0 (TID 444, localhost, partition 28,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,191  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 25.0 in stage 19.0 (TID 442) in 15 ms on localhost (26/199)
2017-07-01 18:26:48,191  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 27.0 in stage 19.0 (TID 444)
2017-07-01 18:26:48,222  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,222  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,223  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 26.0 in stage 19.0 (TID 443). 1609 bytes result sent to driver
2017-07-01 18:26:48,223  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 28.0 in stage 19.0 (TID 445, localhost, partition 29,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,224  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 28.0 in stage 19.0 (TID 445)
2017-07-01 18:26:48,224  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 26.0 in stage 19.0 (TID 443) in 44 ms on localhost (27/199)
2017-07-01 18:26:48,230  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,231  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:48,235  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,235  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,237  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_30_piece0 on localhost:56220 in memory (size: 7.0 KB, free: 116.4 MB)
2017-07-01 18:26:48,239  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 27.0 in stage 19.0 (TID 444). 1609 bytes result sent to driver
2017-07-01 18:26:48,241  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 29.0 in stage 19.0 (TID 446, localhost, partition 30,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,241  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 27.0 in stage 19.0 (TID 444) in 51 ms on localhost (28/199)
2017-07-01 18:26:48,240  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 47
2017-07-01 18:26:48,241  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 29.0 in stage 19.0 (TID 446)
2017-07-01 18:26:48,242  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_29_piece0 on localhost:56220 in memory (size: 5.7 KB, free: 116.4 MB)
2017-07-01 18:26:48,243  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 28.0 in stage 19.0 (TID 445). 1609 bytes result sent to driver
2017-07-01 18:26:48,243  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 46
2017-07-01 18:26:48,244  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 30.0 in stage 19.0 (TID 447, localhost, partition 31,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,244  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 28.0 in stage 19.0 (TID 445) in 21 ms on localhost (29/199)
2017-07-01 18:26:48,244  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 30.0 in stage 19.0 (TID 447)
2017-07-01 18:26:48,247  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,247  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,250  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 29.0 in stage 19.0 (TID 446). 1609 bytes result sent to driver
2017-07-01 18:26:48,252  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 31.0 in stage 19.0 (TID 448, localhost, partition 32,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,252  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 29.0 in stage 19.0 (TID 446) in 11 ms on localhost (30/199)
2017-07-01 18:26:48,252  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_27_piece0 on localhost:56220 in memory (size: 19.5 KB, free: 116.4 MB)
2017-07-01 18:26:48,253  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 31.0 in stage 19.0 (TID 448)
2017-07-01 18:26:48,254  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,254  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,255  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 30.0 in stage 19.0 (TID 447). 1609 bytes result sent to driver
2017-07-01 18:26:48,256  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 32.0 in stage 19.0 (TID 449, localhost, partition 33,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,256  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 32.0 in stage 19.0 (TID 449)
2017-07-01 18:26:48,256  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 30.0 in stage 19.0 (TID 447) in 13 ms on localhost (31/199)
2017-07-01 18:26:48,260  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,260  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,260  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,261  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:48,264  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 31.0 in stage 19.0 (TID 448). 1609 bytes result sent to driver
2017-07-01 18:26:48,265  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 33.0 in stage 19.0 (TID 450, localhost, partition 34,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,265  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 31.0 in stage 19.0 (TID 448) in 13 ms on localhost (32/199)
2017-07-01 18:26:48,266  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 33.0 in stage 19.0 (TID 450)
2017-07-01 18:26:48,269  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,269  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,271  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 32.0 in stage 19.0 (TID 449). 1963 bytes result sent to driver
2017-07-01 18:26:48,273  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 34.0 in stage 19.0 (TID 451, localhost, partition 35,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,274  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 34.0 in stage 19.0 (TID 451)
2017-07-01 18:26:48,274  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 32.0 in stage 19.0 (TID 449) in 18 ms on localhost (33/199)
2017-07-01 18:26:48,290  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,272  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 33.0 in stage 19.0 (TID 450). 1609 bytes result sent to driver
2017-07-01 18:26:48,296  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 35.0 in stage 19.0 (TID 452, localhost, partition 36,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,296  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 33.0 in stage 19.0 (TID 450) in 31 ms on localhost (34/199)
2017-07-01 18:26:48,295  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 5 ms
2017-07-01 18:26:48,296  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 35.0 in stage 19.0 (TID 452)
2017-07-01 18:26:48,297  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 34.0 in stage 19.0 (TID 451). 1609 bytes result sent to driver
2017-07-01 18:26:48,298  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 36.0 in stage 19.0 (TID 453, localhost, partition 37,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,298  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 34.0 in stage 19.0 (TID 451) in 25 ms on localhost (35/199)
2017-07-01 18:26:48,298  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 36.0 in stage 19.0 (TID 453)
2017-07-01 18:26:48,300  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,300  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,303  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,303  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 35.0 in stage 19.0 (TID 452). 1609 bytes result sent to driver
2017-07-01 18:26:48,306  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 37.0 in stage 19.0 (TID 454, localhost, partition 38,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,306  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 35.0 in stage 19.0 (TID 452) in 10 ms on localhost (36/199)
2017-07-01 18:26:48,305  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:48,306  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 37.0 in stage 19.0 (TID 454)
2017-07-01 18:26:48,307  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 36.0 in stage 19.0 (TID 453). 1609 bytes result sent to driver
2017-07-01 18:26:48,308  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 38.0 in stage 19.0 (TID 455, localhost, partition 39,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,308  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 36.0 in stage 19.0 (TID 453) in 10 ms on localhost (37/199)
2017-07-01 18:26:48,308  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 38.0 in stage 19.0 (TID 455)
2017-07-01 18:26:48,310  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,311  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:48,312  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,313  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:48,314  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 38.0 in stage 19.0 (TID 455). 1609 bytes result sent to driver
2017-07-01 18:26:48,315  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 39.0 in stage 19.0 (TID 456, localhost, partition 40,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,315  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 39.0 in stage 19.0 (TID 456)
2017-07-01 18:26:48,316  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 38.0 in stage 19.0 (TID 455) in 8 ms on localhost (38/199)
2017-07-01 18:26:48,320  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,321  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:48,329  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 39.0 in stage 19.0 (TID 456). 1609 bytes result sent to driver
2017-07-01 18:26:48,330  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 40.0 in stage 19.0 (TID 457, localhost, partition 41,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,330  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 39.0 in stage 19.0 (TID 456) in 15 ms on localhost (39/199)
2017-07-01 18:26:48,334  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 37.0 in stage 19.0 (TID 454). 1609 bytes result sent to driver
2017-07-01 18:26:48,338  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 40.0 in stage 19.0 (TID 457)
2017-07-01 18:26:48,342  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 41.0 in stage 19.0 (TID 458, localhost, partition 42,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,343  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 41.0 in stage 19.0 (TID 458)
2017-07-01 18:26:48,345  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 37.0 in stage 19.0 (TID 454) in 39 ms on localhost (40/199)
2017-07-01 18:26:48,348  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,348  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,349  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 40.0 in stage 19.0 (TID 457). 1609 bytes result sent to driver
2017-07-01 18:26:48,350  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 42.0 in stage 19.0 (TID 459, localhost, partition 43,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,350  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 40.0 in stage 19.0 (TID 457) in 20 ms on localhost (41/199)
2017-07-01 18:26:48,350  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 42.0 in stage 19.0 (TID 459)
2017-07-01 18:26:48,352  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,352  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,354  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 41.0 in stage 19.0 (TID 458). 1609 bytes result sent to driver
2017-07-01 18:26:48,355  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 43.0 in stage 19.0 (TID 460, localhost, partition 44,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,356  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 41.0 in stage 19.0 (TID 458) in 14 ms on localhost (42/199)
2017-07-01 18:26:48,356  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 43.0 in stage 19.0 (TID 460)
2017-07-01 18:26:48,362  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,362  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,368  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 43.0 in stage 19.0 (TID 460). 1609 bytes result sent to driver
2017-07-01 18:26:48,370  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,370  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:48,373  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 44.0 in stage 19.0 (TID 461, localhost, partition 45,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,373  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 43.0 in stage 19.0 (TID 460) in 18 ms on localhost (43/199)
2017-07-01 18:26:48,374  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 44.0 in stage 19.0 (TID 461)
2017-07-01 18:26:48,374  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 42.0 in stage 19.0 (TID 459). 1609 bytes result sent to driver
2017-07-01 18:26:48,375  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 45.0 in stage 19.0 (TID 462, localhost, partition 46,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,376  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 42.0 in stage 19.0 (TID 459) in 26 ms on localhost (44/199)
2017-07-01 18:26:48,380  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 45.0 in stage 19.0 (TID 462)
2017-07-01 18:26:48,381  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,381  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,383  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 44.0 in stage 19.0 (TID 461). 1609 bytes result sent to driver
2017-07-01 18:26:48,384  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 46.0 in stage 19.0 (TID 463, localhost, partition 47,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,384  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 46.0 in stage 19.0 (TID 463)
2017-07-01 18:26:48,385  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 44.0 in stage 19.0 (TID 461) in 12 ms on localhost (45/199)
2017-07-01 18:26:48,392  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,393  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:48,396  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,396  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,399  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 46.0 in stage 19.0 (TID 463). 1609 bytes result sent to driver
2017-07-01 18:26:48,400  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 47.0 in stage 19.0 (TID 464, localhost, partition 48,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,400  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 46.0 in stage 19.0 (TID 463) in 16 ms on localhost (46/199)
2017-07-01 18:26:48,400  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 47.0 in stage 19.0 (TID 464)
2017-07-01 18:26:48,405  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 45.0 in stage 19.0 (TID 462). 1609 bytes result sent to driver
2017-07-01 18:26:48,409  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 48.0 in stage 19.0 (TID 465, localhost, partition 49,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,410  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 48.0 in stage 19.0 (TID 465)
2017-07-01 18:26:48,411  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 45.0 in stage 19.0 (TID 462) in 36 ms on localhost (47/199)
2017-07-01 18:26:48,417  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,418  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:48,422  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,424  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 47.0 in stage 19.0 (TID 464). 1609 bytes result sent to driver
2017-07-01 18:26:48,425  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,425  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 49.0 in stage 19.0 (TID 466, localhost, partition 50,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,426  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 47.0 in stage 19.0 (TID 464) in 27 ms on localhost (48/199)
2017-07-01 18:26:48,426  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 49.0 in stage 19.0 (TID 466)
2017-07-01 18:26:48,442  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,442  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,444  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 49.0 in stage 19.0 (TID 466). 1609 bytes result sent to driver
2017-07-01 18:26:48,446  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 50.0 in stage 19.0 (TID 467, localhost, partition 51,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,446  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 50.0 in stage 19.0 (TID 467)
2017-07-01 18:26:48,447  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 49.0 in stage 19.0 (TID 466) in 22 ms on localhost (49/199)
2017-07-01 18:26:48,453  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,453  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,455  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 50.0 in stage 19.0 (TID 467). 1609 bytes result sent to driver
2017-07-01 18:26:48,456  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 51.0 in stage 19.0 (TID 468, localhost, partition 52,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,456  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 51.0 in stage 19.0 (TID 468)
2017-07-01 18:26:48,462  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,462  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,464  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 51.0 in stage 19.0 (TID 468). 1609 bytes result sent to driver
2017-07-01 18:26:48,465  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 52.0 in stage 19.0 (TID 469, localhost, partition 53,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,466  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 51.0 in stage 19.0 (TID 468) in 10 ms on localhost (50/199)
2017-07-01 18:26:48,467  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 50.0 in stage 19.0 (TID 467) in 22 ms on localhost (51/199)
2017-07-01 18:26:48,468  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 48.0 in stage 19.0 (TID 465). 1609 bytes result sent to driver
2017-07-01 18:26:48,475  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 53.0 in stage 19.0 (TID 470, localhost, partition 54,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,475  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 53.0 in stage 19.0 (TID 470)
2017-07-01 18:26:48,475  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 48.0 in stage 19.0 (TID 465) in 66 ms on localhost (52/199)
2017-07-01 18:26:48,480  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 52.0 in stage 19.0 (TID 469)
2017-07-01 18:26:48,482  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,482  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,483  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 53.0 in stage 19.0 (TID 470). 1609 bytes result sent to driver
2017-07-01 18:26:48,483  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 54.0 in stage 19.0 (TID 471, localhost, partition 55,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,484  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 54.0 in stage 19.0 (TID 471)
2017-07-01 18:26:48,484  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 53.0 in stage 19.0 (TID 470) in 8 ms on localhost (53/199)
2017-07-01 18:26:48,487  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,487  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,491  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 54.0 in stage 19.0 (TID 471). 1609 bytes result sent to driver
2017-07-01 18:26:48,492  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 55.0 in stage 19.0 (TID 472, localhost, partition 56,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,492  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 54.0 in stage 19.0 (TID 471) in 9 ms on localhost (54/199)
2017-07-01 18:26:48,492  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,492  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:48,493  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 55.0 in stage 19.0 (TID 472)
2017-07-01 18:26:48,493  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 52.0 in stage 19.0 (TID 469). 1609 bytes result sent to driver
2017-07-01 18:26:48,494  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 56.0 in stage 19.0 (TID 473, localhost, partition 57,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,494  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 52.0 in stage 19.0 (TID 469) in 30 ms on localhost (55/199)
2017-07-01 18:26:48,494  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 56.0 in stage 19.0 (TID 473)
2017-07-01 18:26:48,497  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,497  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,497  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,497  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,498  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 55.0 in stage 19.0 (TID 472). 1609 bytes result sent to driver
2017-07-01 18:26:48,501  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 57.0 in stage 19.0 (TID 474, localhost, partition 58,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,502  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 55.0 in stage 19.0 (TID 472) in 11 ms on localhost (56/199)
2017-07-01 18:26:48,502  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 57.0 in stage 19.0 (TID 474)
2017-07-01 18:26:48,502  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 56.0 in stage 19.0 (TID 473). 1609 bytes result sent to driver
2017-07-01 18:26:48,510  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 58.0 in stage 19.0 (TID 475, localhost, partition 59,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,510  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 56.0 in stage 19.0 (TID 473) in 17 ms on localhost (57/199)
2017-07-01 18:26:48,518  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,520  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:48,519  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 58.0 in stage 19.0 (TID 475)
2017-07-01 18:26:48,522  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 57.0 in stage 19.0 (TID 474). 1609 bytes result sent to driver
2017-07-01 18:26:48,523  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 59.0 in stage 19.0 (TID 476, localhost, partition 60,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,524  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 57.0 in stage 19.0 (TID 474) in 22 ms on localhost (58/199)
2017-07-01 18:26:48,524  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 59.0 in stage 19.0 (TID 476)
2017-07-01 18:26:48,527  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,527  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,528  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 59.0 in stage 19.0 (TID 476). 1609 bytes result sent to driver
2017-07-01 18:26:48,530  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 60.0 in stage 19.0 (TID 477, localhost, partition 61,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,531  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 59.0 in stage 19.0 (TID 476) in 8 ms on localhost (59/199)
2017-07-01 18:26:48,531  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 60.0 in stage 19.0 (TID 477)
2017-07-01 18:26:48,534  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,534  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,535  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 60.0 in stage 19.0 (TID 477). 1609 bytes result sent to driver
2017-07-01 18:26:48,535  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 61.0 in stage 19.0 (TID 478, localhost, partition 62,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,536  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 60.0 in stage 19.0 (TID 477) in 6 ms on localhost (60/199)
2017-07-01 18:26:48,537  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,537  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:48,537  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 58.0 in stage 19.0 (TID 475). 1609 bytes result sent to driver
2017-07-01 18:26:48,541  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 62.0 in stage 19.0 (TID 479, localhost, partition 63,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,541  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 62.0 in stage 19.0 (TID 479)
2017-07-01 18:26:48,542  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 58.0 in stage 19.0 (TID 475) in 32 ms on localhost (61/199)
2017-07-01 18:26:48,542  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 61.0 in stage 19.0 (TID 478)
2017-07-01 18:26:48,545  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,560  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 15 ms
2017-07-01 18:26:48,564  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,564  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,566  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 62.0 in stage 19.0 (TID 479). 1609 bytes result sent to driver
2017-07-01 18:26:48,568  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 63.0 in stage 19.0 (TID 480, localhost, partition 64,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,568  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 62.0 in stage 19.0 (TID 479) in 27 ms on localhost (62/199)
2017-07-01 18:26:48,567  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 61.0 in stage 19.0 (TID 478). 1609 bytes result sent to driver
2017-07-01 18:26:48,571  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 64.0 in stage 19.0 (TID 481, localhost, partition 65,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,571  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 61.0 in stage 19.0 (TID 478) in 36 ms on localhost (63/199)
2017-07-01 18:26:48,571  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 64.0 in stage 19.0 (TID 481)
2017-07-01 18:26:48,570  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 63.0 in stage 19.0 (TID 480)
2017-07-01 18:26:48,579  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,581  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:48,581  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,583  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 5 ms
2017-07-01 18:26:48,586  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 64.0 in stage 19.0 (TID 481). 1609 bytes result sent to driver
2017-07-01 18:26:48,586  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 63.0 in stage 19.0 (TID 480). 1609 bytes result sent to driver
2017-07-01 18:26:48,587  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 65.0 in stage 19.0 (TID 482, localhost, partition 66,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,587  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 64.0 in stage 19.0 (TID 481) in 16 ms on localhost (64/199)
2017-07-01 18:26:48,588  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 65.0 in stage 19.0 (TID 482)
2017-07-01 18:26:48,592  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,592  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,593  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 65.0 in stage 19.0 (TID 482). 1609 bytes result sent to driver
2017-07-01 18:26:48,594  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 66.0 in stage 19.0 (TID 483, localhost, partition 67,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,594  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 66.0 in stage 19.0 (TID 483)
2017-07-01 18:26:48,594  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 65.0 in stage 19.0 (TID 482) in 7 ms on localhost (65/199)
2017-07-01 18:26:48,595  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 67.0 in stage 19.0 (TID 484, localhost, partition 68,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,595  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 63.0 in stage 19.0 (TID 480) in 28 ms on localhost (66/199)
2017-07-01 18:26:48,596  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 67.0 in stage 19.0 (TID 484)
2017-07-01 18:26:48,599  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,599  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,599  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,600  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:48,600  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 67.0 in stage 19.0 (TID 484). 1609 bytes result sent to driver
2017-07-01 18:26:48,600  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 68.0 in stage 19.0 (TID 485, localhost, partition 69,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,601  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 67.0 in stage 19.0 (TID 484) in 6 ms on localhost (67/199)
2017-07-01 18:26:48,601  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 68.0 in stage 19.0 (TID 485)
2017-07-01 18:26:48,601  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 66.0 in stage 19.0 (TID 483). 1609 bytes result sent to driver
2017-07-01 18:26:48,602  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 69.0 in stage 19.0 (TID 486, localhost, partition 70,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,602  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 69.0 in stage 19.0 (TID 486)
2017-07-01 18:26:48,602  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 66.0 in stage 19.0 (TID 483) in 9 ms on localhost (68/199)
2017-07-01 18:26:48,605  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,605  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,606  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 68.0 in stage 19.0 (TID 485). 1609 bytes result sent to driver
2017-07-01 18:26:48,607  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 70.0 in stage 19.0 (TID 487, localhost, partition 71,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,607  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 68.0 in stage 19.0 (TID 485) in 7 ms on localhost (69/199)
2017-07-01 18:26:48,607  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 70.0 in stage 19.0 (TID 487)
2017-07-01 18:26:48,609  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,611  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,611  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,611  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:48,612  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 70.0 in stage 19.0 (TID 487). 1609 bytes result sent to driver
2017-07-01 18:26:48,613  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 71.0 in stage 19.0 (TID 488, localhost, partition 72,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,613  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 70.0 in stage 19.0 (TID 487) in 6 ms on localhost (70/199)
2017-07-01 18:26:48,613  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 71.0 in stage 19.0 (TID 488)
2017-07-01 18:26:48,617  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,617  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,618  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 71.0 in stage 19.0 (TID 488). 1609 bytes result sent to driver
2017-07-01 18:26:48,618  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 72.0 in stage 19.0 (TID 489, localhost, partition 73,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,619  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 69.0 in stage 19.0 (TID 486). 1609 bytes result sent to driver
2017-07-01 18:26:48,619  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 73.0 in stage 19.0 (TID 490, localhost, partition 74,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,619  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 73.0 in stage 19.0 (TID 490)
2017-07-01 18:26:48,620  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 71.0 in stage 19.0 (TID 488) in 8 ms on localhost (71/199)
2017-07-01 18:26:48,621  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 69.0 in stage 19.0 (TID 486) in 19 ms on localhost (72/199)
2017-07-01 18:26:48,624  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 72.0 in stage 19.0 (TID 489)
2017-07-01 18:26:48,651  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,651  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,652  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,652  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,652  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 73.0 in stage 19.0 (TID 490). 1609 bytes result sent to driver
2017-07-01 18:26:48,653  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 74.0 in stage 19.0 (TID 491, localhost, partition 75,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,653  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 73.0 in stage 19.0 (TID 490) in 34 ms on localhost (73/199)
2017-07-01 18:26:48,653  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 74.0 in stage 19.0 (TID 491)
2017-07-01 18:26:48,654  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 72.0 in stage 19.0 (TID 489). 1609 bytes result sent to driver
2017-07-01 18:26:48,657  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,657  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,658  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 75.0 in stage 19.0 (TID 492, localhost, partition 76,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,658  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 72.0 in stage 19.0 (TID 489) in 40 ms on localhost (74/199)
2017-07-01 18:26:48,658  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 75.0 in stage 19.0 (TID 492)
2017-07-01 18:26:48,659  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 74.0 in stage 19.0 (TID 491). 1609 bytes result sent to driver
2017-07-01 18:26:48,660  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 76.0 in stage 19.0 (TID 493, localhost, partition 77,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,661  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 74.0 in stage 19.0 (TID 491) in 8 ms on localhost (75/199)
2017-07-01 18:26:48,661  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 76.0 in stage 19.0 (TID 493)
2017-07-01 18:26:48,664  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,664  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,669  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 76.0 in stage 19.0 (TID 493). 1609 bytes result sent to driver
2017-07-01 18:26:48,669  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 77.0 in stage 19.0 (TID 494, localhost, partition 78,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,669  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 77.0 in stage 19.0 (TID 494)
2017-07-01 18:26:48,670  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 76.0 in stage 19.0 (TID 493) in 10 ms on localhost (76/199)
2017-07-01 18:26:48,679  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,682  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:26:48,684  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 77.0 in stage 19.0 (TID 494). 1609 bytes result sent to driver
2017-07-01 18:26:48,685  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 78.0 in stage 19.0 (TID 495, localhost, partition 79,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,686  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 77.0 in stage 19.0 (TID 494) in 16 ms on localhost (77/199)
2017-07-01 18:26:48,686  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 78.0 in stage 19.0 (TID 495)
2017-07-01 18:26:48,689  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,691  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:48,690  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,697  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 7 ms
2017-07-01 18:26:48,700  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 75.0 in stage 19.0 (TID 492). 1609 bytes result sent to driver
2017-07-01 18:26:48,697  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 78.0 in stage 19.0 (TID 495). 1609 bytes result sent to driver
2017-07-01 18:26:48,702  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 79.0 in stage 19.0 (TID 496, localhost, partition 80,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,707  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 80.0 in stage 19.0 (TID 497, localhost, partition 81,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,707  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 80.0 in stage 19.0 (TID 497)
2017-07-01 18:26:48,710  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 75.0 in stage 19.0 (TID 492) in 52 ms on localhost (78/199)
2017-07-01 18:26:48,710  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 78.0 in stage 19.0 (TID 495) in 25 ms on localhost (79/199)
2017-07-01 18:26:48,712  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 79.0 in stage 19.0 (TID 496)
2017-07-01 18:26:48,716  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,717  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:48,717  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,718  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:48,719  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 80.0 in stage 19.0 (TID 497). 1609 bytes result sent to driver
2017-07-01 18:26:48,720  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 81.0 in stage 19.0 (TID 498, localhost, partition 82,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,720  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 81.0 in stage 19.0 (TID 498)
2017-07-01 18:26:48,723  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,724  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:48,725  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 81.0 in stage 19.0 (TID 498). 1609 bytes result sent to driver
2017-07-01 18:26:48,725  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 82.0 in stage 19.0 (TID 499, localhost, partition 83,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,726  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 80.0 in stage 19.0 (TID 497) in 20 ms on localhost (80/199)
2017-07-01 18:26:48,726  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 81.0 in stage 19.0 (TID 498) in 7 ms on localhost (81/199)
2017-07-01 18:26:48,727  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 82.0 in stage 19.0 (TID 499)
2017-07-01 18:26:48,730  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,730  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,731  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 82.0 in stage 19.0 (TID 499). 1609 bytes result sent to driver
2017-07-01 18:26:48,732  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 83.0 in stage 19.0 (TID 500, localhost, partition 84,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,733  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 83.0 in stage 19.0 (TID 500)
2017-07-01 18:26:48,734  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 79.0 in stage 19.0 (TID 496). 1609 bytes result sent to driver
2017-07-01 18:26:48,734  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 84.0 in stage 19.0 (TID 501, localhost, partition 85,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,734  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 84.0 in stage 19.0 (TID 501)
2017-07-01 18:26:48,742  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 82.0 in stage 19.0 (TID 499) in 17 ms on localhost (82/199)
2017-07-01 18:26:48,742  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 79.0 in stage 19.0 (TID 496) in 40 ms on localhost (83/199)
2017-07-01 18:26:48,759  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,759  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,760  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 84.0 in stage 19.0 (TID 501). 1609 bytes result sent to driver
2017-07-01 18:26:48,760  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 85.0 in stage 19.0 (TID 502, localhost, partition 86,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,761  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 84.0 in stage 19.0 (TID 501) in 27 ms on localhost (84/199)
2017-07-01 18:26:48,761  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 85.0 in stage 19.0 (TID 502)
2017-07-01 18:26:48,769  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,769  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,770  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 85.0 in stage 19.0 (TID 502). 1609 bytes result sent to driver
2017-07-01 18:26:48,772  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 86.0 in stage 19.0 (TID 503, localhost, partition 87,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,773  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 85.0 in stage 19.0 (TID 502) in 13 ms on localhost (85/199)
2017-07-01 18:26:48,773  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 86.0 in stage 19.0 (TID 503)
2017-07-01 18:26:48,792  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,793  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,793  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:48,794  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 86.0 in stage 19.0 (TID 503). 1609 bytes result sent to driver
2017-07-01 18:26:48,794  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 87.0 in stage 19.0 (TID 504, localhost, partition 88,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,796  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 87.0 in stage 19.0 (TID 504)
2017-07-01 18:26:48,798  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 86.0 in stage 19.0 (TID 503) in 26 ms on localhost (86/199)
2017-07-01 18:26:48,793  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:48,808  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 83.0 in stage 19.0 (TID 500). 1609 bytes result sent to driver
2017-07-01 18:26:48,808  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,810  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 5 ms
2017-07-01 18:26:48,811  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 87.0 in stage 19.0 (TID 504). 1609 bytes result sent to driver
2017-07-01 18:26:48,812  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 88.0 in stage 19.0 (TID 505, localhost, partition 89,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,817  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 88.0 in stage 19.0 (TID 505)
2017-07-01 18:26:48,817  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 83.0 in stage 19.0 (TID 500) in 85 ms on localhost (87/199)
2017-07-01 18:26:48,823  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 89.0 in stage 19.0 (TID 506, localhost, partition 90,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,824  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 87.0 in stage 19.0 (TID 504) in 30 ms on localhost (88/199)
2017-07-01 18:26:48,824  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 89.0 in stage 19.0 (TID 506)
2017-07-01 18:26:48,825  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,825  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,828  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 88.0 in stage 19.0 (TID 505). 1609 bytes result sent to driver
2017-07-01 18:26:48,829  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 90.0 in stage 19.0 (TID 507, localhost, partition 91,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,831  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 88.0 in stage 19.0 (TID 505) in 19 ms on localhost (89/199)
2017-07-01 18:26:48,832  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 90.0 in stage 19.0 (TID 507)
2017-07-01 18:26:48,833  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,833  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,838  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 89.0 in stage 19.0 (TID 506). 1609 bytes result sent to driver
2017-07-01 18:26:48,839  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 91.0 in stage 19.0 (TID 508, localhost, partition 92,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,839  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 91.0 in stage 19.0 (TID 508)
2017-07-01 18:26:48,839  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 89.0 in stage 19.0 (TID 506) in 16 ms on localhost (90/199)
2017-07-01 18:26:48,843  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,847  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:26:48,846  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,849  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:26:48,852  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 90.0 in stage 19.0 (TID 507). 1609 bytes result sent to driver
2017-07-01 18:26:48,852  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 91.0 in stage 19.0 (TID 508). 1609 bytes result sent to driver
2017-07-01 18:26:48,855  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 92.0 in stage 19.0 (TID 509, localhost, partition 93,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,856  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 90.0 in stage 19.0 (TID 507) in 27 ms on localhost (91/199)
2017-07-01 18:26:48,857  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 93.0 in stage 19.0 (TID 510, localhost, partition 94,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,857  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 91.0 in stage 19.0 (TID 508) in 18 ms on localhost (92/199)
2017-07-01 18:26:48,857  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 93.0 in stage 19.0 (TID 510)
2017-07-01 18:26:48,858  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 92.0 in stage 19.0 (TID 509)
2017-07-01 18:26:48,865  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,865  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,866  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 93.0 in stage 19.0 (TID 510). 1609 bytes result sent to driver
2017-07-01 18:26:48,865  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,867  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:48,867  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 92.0 in stage 19.0 (TID 509). 1609 bytes result sent to driver
2017-07-01 18:26:48,868  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 94.0 in stage 19.0 (TID 511, localhost, partition 95,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,868  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 93.0 in stage 19.0 (TID 510) in 12 ms on localhost (93/199)
2017-07-01 18:26:48,869  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 94.0 in stage 19.0 (TID 511)
2017-07-01 18:26:48,878  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,878  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,879  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 94.0 in stage 19.0 (TID 511). 1609 bytes result sent to driver
2017-07-01 18:26:48,880  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 95.0 in stage 19.0 (TID 512, localhost, partition 96,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,880  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 95.0 in stage 19.0 (TID 512)
2017-07-01 18:26:48,880  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 94.0 in stage 19.0 (TID 511) in 12 ms on localhost (94/199)
2017-07-01 18:26:48,881  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 96.0 in stage 19.0 (TID 513, localhost, partition 97,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,881  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 92.0 in stage 19.0 (TID 509) in 27 ms on localhost (95/199)
2017-07-01 18:26:48,882  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 96.0 in stage 19.0 (TID 513)
2017-07-01 18:26:48,885  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,885  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,886  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 95.0 in stage 19.0 (TID 512). 1609 bytes result sent to driver
2017-07-01 18:26:48,887  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 97.0 in stage 19.0 (TID 514, localhost, partition 98,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,887  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 95.0 in stage 19.0 (TID 512) in 8 ms on localhost (96/199)
2017-07-01 18:26:48,888  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,888  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,888  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 97.0 in stage 19.0 (TID 514)
2017-07-01 18:26:48,889  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 96.0 in stage 19.0 (TID 513). 1609 bytes result sent to driver
2017-07-01 18:26:48,890  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 98.0 in stage 19.0 (TID 515, localhost, partition 99,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,890  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 98.0 in stage 19.0 (TID 515)
2017-07-01 18:26:48,890  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 96.0 in stage 19.0 (TID 513) in 9 ms on localhost (97/199)
2017-07-01 18:26:48,894  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,895  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:48,912  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 98.0 in stage 19.0 (TID 515). 1609 bytes result sent to driver
2017-07-01 18:26:48,914  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,915  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:48,916  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 97.0 in stage 19.0 (TID 514). 1609 bytes result sent to driver
2017-07-01 18:26:48,918  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 99.0 in stage 19.0 (TID 516, localhost, partition 100,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,918  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 100.0 in stage 19.0 (TID 517, localhost, partition 101,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,918  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 100.0 in stage 19.0 (TID 517)
2017-07-01 18:26:48,919  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 98.0 in stage 19.0 (TID 515) in 28 ms on localhost (98/199)
2017-07-01 18:26:48,919  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 97.0 in stage 19.0 (TID 514) in 32 ms on localhost (99/199)
2017-07-01 18:26:48,923  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,923  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,924  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 100.0 in stage 19.0 (TID 517). 1609 bytes result sent to driver
2017-07-01 18:26:48,923  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 99.0 in stage 19.0 (TID 516)
2017-07-01 18:26:48,927  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,928  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 101.0 in stage 19.0 (TID 518, localhost, partition 102,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,928  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 100.0 in stage 19.0 (TID 517) in 10 ms on localhost (100/199)
2017-07-01 18:26:48,929  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 101.0 in stage 19.0 (TID 518)
2017-07-01 18:26:48,931  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:26:48,932  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 99.0 in stage 19.0 (TID 516). 1609 bytes result sent to driver
2017-07-01 18:26:48,937  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 102.0 in stage 19.0 (TID 519, localhost, partition 103,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,937  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 102.0 in stage 19.0 (TID 519)
2017-07-01 18:26:48,937  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 99.0 in stage 19.0 (TID 516) in 20 ms on localhost (101/199)
2017-07-01 18:26:48,942  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,944  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:48,946  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,946  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:48,954  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 102.0 in stage 19.0 (TID 519). 1609 bytes result sent to driver
2017-07-01 18:26:48,957  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 103.0 in stage 19.0 (TID 520, localhost, partition 104,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,957  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 103.0 in stage 19.0 (TID 520)
2017-07-01 18:26:48,957  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 102.0 in stage 19.0 (TID 519) in 20 ms on localhost (102/199)
2017-07-01 18:26:48,958  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 101.0 in stage 19.0 (TID 518). 1609 bytes result sent to driver
2017-07-01 18:26:48,962  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 104.0 in stage 19.0 (TID 521, localhost, partition 105,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,962  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 101.0 in stage 19.0 (TID 518) in 35 ms on localhost (103/199)
2017-07-01 18:26:48,963  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 104.0 in stage 19.0 (TID 521)
2017-07-01 18:26:48,971  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,972  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:48,974  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 103.0 in stage 19.0 (TID 520). 1609 bytes result sent to driver
2017-07-01 18:26:48,975  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 105.0 in stage 19.0 (TID 522, localhost, partition 106,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,976  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 103.0 in stage 19.0 (TID 520) in 18 ms on localhost (104/199)
2017-07-01 18:26:48,976  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 105.0 in stage 19.0 (TID 522)
2017-07-01 18:26:48,981  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,983  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:48,991  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 105.0 in stage 19.0 (TID 522). 1609 bytes result sent to driver
2017-07-01 18:26:48,983  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:48,991  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 8 ms
2017-07-01 18:26:48,995  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 106.0 in stage 19.0 (TID 523, localhost, partition 107,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:48,997  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 106.0 in stage 19.0 (TID 523)
2017-07-01 18:26:49,000  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 105.0 in stage 19.0 (TID 522) in 25 ms on localhost (105/199)
2017-07-01 18:26:49,004  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 104.0 in stage 19.0 (TID 521). 1609 bytes result sent to driver
2017-07-01 18:26:49,006  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 107.0 in stage 19.0 (TID 524, localhost, partition 108,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,007  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 104.0 in stage 19.0 (TID 521) in 46 ms on localhost (106/199)
2017-07-01 18:26:49,008  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 107.0 in stage 19.0 (TID 524)
2017-07-01 18:26:49,010  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,012  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:49,014  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 106.0 in stage 19.0 (TID 523). 1609 bytes result sent to driver
2017-07-01 18:26:49,020  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 108.0 in stage 19.0 (TID 525, localhost, partition 109,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,021  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 106.0 in stage 19.0 (TID 523) in 26 ms on localhost (107/199)
2017-07-01 18:26:49,025  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 108.0 in stage 19.0 (TID 525)
2017-07-01 18:26:49,034  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,039  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 5 ms
2017-07-01 18:26:49,043  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,045  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:49,046  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 107.0 in stage 19.0 (TID 524). 1609 bytes result sent to driver
2017-07-01 18:26:49,047  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 109.0 in stage 19.0 (TID 526, localhost, partition 110,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,047  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 107.0 in stage 19.0 (TID 524) in 42 ms on localhost (108/199)
2017-07-01 18:26:49,048  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 109.0 in stage 19.0 (TID 526)
2017-07-01 18:26:49,051  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,052  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:49,053  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 108.0 in stage 19.0 (TID 525). 1609 bytes result sent to driver
2017-07-01 18:26:49,055  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 110.0 in stage 19.0 (TID 527, localhost, partition 111,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,055  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 110.0 in stage 19.0 (TID 527)
2017-07-01 18:26:49,056  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 108.0 in stage 19.0 (TID 525) in 37 ms on localhost (109/199)
2017-07-01 18:26:49,057  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 109.0 in stage 19.0 (TID 526). 1609 bytes result sent to driver
2017-07-01 18:26:49,058  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 111.0 in stage 19.0 (TID 528, localhost, partition 112,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,058  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 109.0 in stage 19.0 (TID 526) in 11 ms on localhost (110/199)
2017-07-01 18:26:49,059  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 111.0 in stage 19.0 (TID 528)
2017-07-01 18:26:49,070  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,073  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:26:49,074  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,074  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 5 ms
2017-07-01 18:26:49,075  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 110.0 in stage 19.0 (TID 527). 1609 bytes result sent to driver
2017-07-01 18:26:49,076  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 111.0 in stage 19.0 (TID 528). 1609 bytes result sent to driver
2017-07-01 18:26:49,087  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 112.0 in stage 19.0 (TID 529, localhost, partition 113,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,088  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 110.0 in stage 19.0 (TID 527) in 33 ms on localhost (111/199)
2017-07-01 18:26:49,088  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 112.0 in stage 19.0 (TID 529)
2017-07-01 18:26:49,092  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,092  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:49,093  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 113.0 in stage 19.0 (TID 530, localhost, partition 114,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,094  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 113.0 in stage 19.0 (TID 530)
2017-07-01 18:26:49,096  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 111.0 in stage 19.0 (TID 528) in 37 ms on localhost (112/199)
2017-07-01 18:26:49,096  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 112.0 in stage 19.0 (TID 529). 1609 bytes result sent to driver
2017-07-01 18:26:49,098  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 114.0 in stage 19.0 (TID 531, localhost, partition 115,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,100  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 114.0 in stage 19.0 (TID 531)
2017-07-01 18:26:49,102  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 112.0 in stage 19.0 (TID 529) in 15 ms on localhost (113/199)
2017-07-01 18:26:49,109  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,113  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 5 ms
2017-07-01 18:26:49,114  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 113.0 in stage 19.0 (TID 530). 1609 bytes result sent to driver
2017-07-01 18:26:49,112  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,115  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:26:49,116  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 114.0 in stage 19.0 (TID 531). 1609 bytes result sent to driver
2017-07-01 18:26:49,118  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 115.0 in stage 19.0 (TID 532, localhost, partition 116,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,119  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 113.0 in stage 19.0 (TID 530) in 26 ms on localhost (114/199)
2017-07-01 18:26:49,120  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 115.0 in stage 19.0 (TID 532)
2017-07-01 18:26:49,135  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,135  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:49,138  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 116.0 in stage 19.0 (TID 533, localhost, partition 117,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,139  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 114.0 in stage 19.0 (TID 531) in 41 ms on localhost (115/199)
2017-07-01 18:26:49,141  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 116.0 in stage 19.0 (TID 533)
2017-07-01 18:26:49,145  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,147  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:49,148  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 116.0 in stage 19.0 (TID 533). 1609 bytes result sent to driver
2017-07-01 18:26:49,149  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 117.0 in stage 19.0 (TID 534, localhost, partition 118,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,149  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 117.0 in stage 19.0 (TID 534)
2017-07-01 18:26:49,153  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,155  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:49,156  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 117.0 in stage 19.0 (TID 534). 1609 bytes result sent to driver
2017-07-01 18:26:49,157  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 118.0 in stage 19.0 (TID 535, localhost, partition 119,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,157  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 118.0 in stage 19.0 (TID 535)
2017-07-01 18:26:49,161  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,161  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:49,162  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 116.0 in stage 19.0 (TID 533) in 24 ms on localhost (116/199)
2017-07-01 18:26:49,162  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 117.0 in stage 19.0 (TID 534) in 13 ms on localhost (117/199)
2017-07-01 18:26:49,163  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 118.0 in stage 19.0 (TID 535). 1609 bytes result sent to driver
2017-07-01 18:26:49,164  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 119.0 in stage 19.0 (TID 536, localhost, partition 120,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,164  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 118.0 in stage 19.0 (TID 535) in 7 ms on localhost (118/199)
2017-07-01 18:26:49,168  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 119.0 in stage 19.0 (TID 536)
2017-07-01 18:26:49,174  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 115.0 in stage 19.0 (TID 532). 1609 bytes result sent to driver
2017-07-01 18:26:49,175  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 120.0 in stage 19.0 (TID 537, localhost, partition 121,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,175  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 115.0 in stage 19.0 (TID 532) in 58 ms on localhost (119/199)
2017-07-01 18:26:49,177  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 120.0 in stage 19.0 (TID 537)
2017-07-01 18:26:49,181  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,185  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:26:49,184  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,186  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:49,188  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 119.0 in stage 19.0 (TID 536). 1609 bytes result sent to driver
2017-07-01 18:26:49,188  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 121.0 in stage 19.0 (TID 538, localhost, partition 122,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,189  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 121.0 in stage 19.0 (TID 538)
2017-07-01 18:26:49,192  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 119.0 in stage 19.0 (TID 536) in 29 ms on localhost (120/199)
2017-07-01 18:26:49,194  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,196  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:49,197  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 120.0 in stage 19.0 (TID 537). 1609 bytes result sent to driver
2017-07-01 18:26:49,198  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 122.0 in stage 19.0 (TID 539, localhost, partition 123,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,198  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 120.0 in stage 19.0 (TID 537) in 23 ms on localhost (121/199)
2017-07-01 18:26:49,199  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 122.0 in stage 19.0 (TID 539)
2017-07-01 18:26:49,201  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 121.0 in stage 19.0 (TID 538). 1609 bytes result sent to driver
2017-07-01 18:26:49,203  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,204  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:49,205  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 122.0 in stage 19.0 (TID 539). 1609 bytes result sent to driver
2017-07-01 18:26:49,217  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 123.0 in stage 19.0 (TID 540, localhost, partition 124,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,218  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 124.0 in stage 19.0 (TID 541, localhost, partition 125,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,219  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 122.0 in stage 19.0 (TID 539) in 20 ms on localhost (122/199)
2017-07-01 18:26:49,219  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 121.0 in stage 19.0 (TID 538) in 31 ms on localhost (123/199)
2017-07-01 18:26:49,224  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 124.0 in stage 19.0 (TID 541)
2017-07-01 18:26:49,231  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 123.0 in stage 19.0 (TID 540)
2017-07-01 18:26:49,237  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,248  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 11 ms
2017-07-01 18:26:49,250  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 124.0 in stage 19.0 (TID 541). 1609 bytes result sent to driver
2017-07-01 18:26:49,252  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,254  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 125.0 in stage 19.0 (TID 542, localhost, partition 126,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,258  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 125.0 in stage 19.0 (TID 542)
2017-07-01 18:26:49,259  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 7 ms
2017-07-01 18:26:49,260  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 123.0 in stage 19.0 (TID 540). 1609 bytes result sent to driver
2017-07-01 18:26:49,268  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,268  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:49,269  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 125.0 in stage 19.0 (TID 542). 1609 bytes result sent to driver
2017-07-01 18:26:49,261  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 124.0 in stage 19.0 (TID 541) in 44 ms on localhost (124/199)
2017-07-01 18:26:49,272  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 126.0 in stage 19.0 (TID 543, localhost, partition 127,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,273  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 127.0 in stage 19.0 (TID 544, localhost, partition 128,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,275  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 127.0 in stage 19.0 (TID 544)
2017-07-01 18:26:49,275  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 123.0 in stage 19.0 (TID 540) in 73 ms on localhost (125/199)
2017-07-01 18:26:49,276  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 125.0 in stage 19.0 (TID 542) in 22 ms on localhost (126/199)
2017-07-01 18:26:49,280  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,280  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:49,280  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 126.0 in stage 19.0 (TID 543)
2017-07-01 18:26:49,301  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 127.0 in stage 19.0 (TID 544). 1609 bytes result sent to driver
2017-07-01 18:26:49,303  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 128.0 in stage 19.0 (TID 545, localhost, partition 129,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,303  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 127.0 in stage 19.0 (TID 544) in 31 ms on localhost (127/199)
2017-07-01 18:26:49,306  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 128.0 in stage 19.0 (TID 545)
2017-07-01 18:26:49,317  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,318  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:49,320  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 126.0 in stage 19.0 (TID 543). 1609 bytes result sent to driver
2017-07-01 18:26:49,322  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 129.0 in stage 19.0 (TID 546, localhost, partition 130,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,324  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 129.0 in stage 19.0 (TID 546)
2017-07-01 18:26:49,327  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 126.0 in stage 19.0 (TID 543) in 55 ms on localhost (128/199)
2017-07-01 18:26:49,330  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,330  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:49,340  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 128.0 in stage 19.0 (TID 545). 1609 bytes result sent to driver
2017-07-01 18:26:49,337  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,344  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 7 ms
2017-07-01 18:26:49,346  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 129.0 in stage 19.0 (TID 546). 1609 bytes result sent to driver
2017-07-01 18:26:49,347  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 130.0 in stage 19.0 (TID 547, localhost, partition 131,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,347  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 130.0 in stage 19.0 (TID 547)
2017-07-01 18:26:49,347  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 129.0 in stage 19.0 (TID 546) in 25 ms on localhost (129/199)
2017-07-01 18:26:49,353  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 131.0 in stage 19.0 (TID 548, localhost, partition 132,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,354  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 128.0 in stage 19.0 (TID 545) in 50 ms on localhost (130/199)
2017-07-01 18:26:49,357  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 131.0 in stage 19.0 (TID 548)
2017-07-01 18:26:49,368  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,370  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:26:49,368  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,373  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 5 ms
2017-07-01 18:26:49,376  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 131.0 in stage 19.0 (TID 548). 1609 bytes result sent to driver
2017-07-01 18:26:49,376  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 130.0 in stage 19.0 (TID 547). 1609 bytes result sent to driver
2017-07-01 18:26:49,379  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 132.0 in stage 19.0 (TID 549, localhost, partition 133,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,380  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 133.0 in stage 19.0 (TID 550, localhost, partition 134,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,380  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 131.0 in stage 19.0 (TID 548) in 28 ms on localhost (131/199)
2017-07-01 18:26:49,381  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 130.0 in stage 19.0 (TID 547) in 35 ms on localhost (132/199)
2017-07-01 18:26:49,381  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 133.0 in stage 19.0 (TID 550)
2017-07-01 18:26:49,382  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 132.0 in stage 19.0 (TID 549)
2017-07-01 18:26:49,395  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,395  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:49,396  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 132.0 in stage 19.0 (TID 549). 1609 bytes result sent to driver
2017-07-01 18:26:49,396  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 134.0 in stage 19.0 (TID 551, localhost, partition 135,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,400  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 134.0 in stage 19.0 (TID 551)
2017-07-01 18:26:49,408  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,408  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:49,410  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 132.0 in stage 19.0 (TID 549) in 31 ms on localhost (133/199)
2017-07-01 18:26:49,411  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 134.0 in stage 19.0 (TID 551). 1609 bytes result sent to driver
2017-07-01 18:26:49,414  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 135.0 in stage 19.0 (TID 552, localhost, partition 136,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,414  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 135.0 in stage 19.0 (TID 552)
2017-07-01 18:26:49,422  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 134.0 in stage 19.0 (TID 551) in 26 ms on localhost (134/199)
2017-07-01 18:26:49,424  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,424  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:49,425  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 135.0 in stage 19.0 (TID 552). 1609 bytes result sent to driver
2017-07-01 18:26:49,426  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 136.0 in stage 19.0 (TID 553, localhost, partition 137,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,426  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 135.0 in stage 19.0 (TID 552) in 13 ms on localhost (135/199)
2017-07-01 18:26:49,427  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 136.0 in stage 19.0 (TID 553)
2017-07-01 18:26:49,436  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,444  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 8 ms
2017-07-01 18:26:49,445  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 136.0 in stage 19.0 (TID 553). 1609 bytes result sent to driver
2017-07-01 18:26:49,452  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 137.0 in stage 19.0 (TID 554, localhost, partition 138,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,452  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 137.0 in stage 19.0 (TID 554)
2017-07-01 18:26:49,455  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,456  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:49,457  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 137.0 in stage 19.0 (TID 554). 1609 bytes result sent to driver
2017-07-01 18:26:49,458  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 136.0 in stage 19.0 (TID 553) in 33 ms on localhost (136/199)
2017-07-01 18:26:49,463  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 138.0 in stage 19.0 (TID 555, localhost, partition 139,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,463  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 138.0 in stage 19.0 (TID 555)
2017-07-01 18:26:49,463  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 137.0 in stage 19.0 (TID 554) in 12 ms on localhost (137/199)
2017-07-01 18:26:49,467  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,467  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:49,468  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 138.0 in stage 19.0 (TID 555). 1609 bytes result sent to driver
2017-07-01 18:26:49,468  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 139.0 in stage 19.0 (TID 556, localhost, partition 140,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,468  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 139.0 in stage 19.0 (TID 556)
2017-07-01 18:26:49,468  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 138.0 in stage 19.0 (TID 555) in 5 ms on localhost (138/199)
2017-07-01 18:26:49,469  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,469  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:49,470  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 133.0 in stage 19.0 (TID 550). 1609 bytes result sent to driver
2017-07-01 18:26:49,473  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,473  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:49,483  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 139.0 in stage 19.0 (TID 556). 1609 bytes result sent to driver
2017-07-01 18:26:49,479  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 140.0 in stage 19.0 (TID 557, localhost, partition 141,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,486  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 133.0 in stage 19.0 (TID 550) in 106 ms on localhost (139/199)
2017-07-01 18:26:49,488  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 140.0 in stage 19.0 (TID 557)
2017-07-01 18:26:49,491  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 141.0 in stage 19.0 (TID 558, localhost, partition 142,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,493  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 141.0 in stage 19.0 (TID 558)
2017-07-01 18:26:49,499  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,501  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:49,503  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 141.0 in stage 19.0 (TID 558). 1609 bytes result sent to driver
2017-07-01 18:26:49,500  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,505  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 5 ms
2017-07-01 18:26:49,507  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 140.0 in stage 19.0 (TID 557). 1609 bytes result sent to driver
2017-07-01 18:26:49,508  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 142.0 in stage 19.0 (TID 559, localhost, partition 143,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,515  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 139.0 in stage 19.0 (TID 556) in 47 ms on localhost (140/199)
2017-07-01 18:26:49,515  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 141.0 in stage 19.0 (TID 558) in 24 ms on localhost (141/199)
2017-07-01 18:26:49,517  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 142.0 in stage 19.0 (TID 559)
2017-07-01 18:26:49,518  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 143.0 in stage 19.0 (TID 560, localhost, partition 144,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,519  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 143.0 in stage 19.0 (TID 560)
2017-07-01 18:26:49,527  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,530  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:26:49,532  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 143.0 in stage 19.0 (TID 560). 1609 bytes result sent to driver
2017-07-01 18:26:49,534  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 140.0 in stage 19.0 (TID 557) in 55 ms on localhost (142/199)
2017-07-01 18:26:49,535  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 144.0 in stage 19.0 (TID 561, localhost, partition 145,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,535  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 143.0 in stage 19.0 (TID 560) in 18 ms on localhost (143/199)
2017-07-01 18:26:49,533  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,536  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:26:49,538  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 142.0 in stage 19.0 (TID 559). 1609 bytes result sent to driver
2017-07-01 18:26:49,538  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 144.0 in stage 19.0 (TID 561)
2017-07-01 18:26:49,540  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 145.0 in stage 19.0 (TID 562, localhost, partition 146,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,542  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 145.0 in stage 19.0 (TID 562)
2017-07-01 18:26:49,546  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,546  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:49,547  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 145.0 in stage 19.0 (TID 562). 1609 bytes result sent to driver
2017-07-01 18:26:49,548  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 146.0 in stage 19.0 (TID 563, localhost, partition 147,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,548  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 146.0 in stage 19.0 (TID 563)
2017-07-01 18:26:49,550  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 142.0 in stage 19.0 (TID 559) in 42 ms on localhost (144/199)
2017-07-01 18:26:49,550  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 145.0 in stage 19.0 (TID 562) in 10 ms on localhost (145/199)
2017-07-01 18:26:49,552  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,552  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:49,554  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 146.0 in stage 19.0 (TID 563). 1609 bytes result sent to driver
2017-07-01 18:26:49,554  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 147.0 in stage 19.0 (TID 564, localhost, partition 148,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,555  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 147.0 in stage 19.0 (TID 564)
2017-07-01 18:26:49,558  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 146.0 in stage 19.0 (TID 563) in 10 ms on localhost (146/199)
2017-07-01 18:26:49,560  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,574  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 14 ms
2017-07-01 18:26:49,578  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 147.0 in stage 19.0 (TID 564). 1609 bytes result sent to driver
2017-07-01 18:26:49,579  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,580  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 148.0 in stage 19.0 (TID 565, localhost, partition 149,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,586  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 147.0 in stage 19.0 (TID 564) in 32 ms on localhost (147/199)
2017-07-01 18:26:49,587  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 148.0 in stage 19.0 (TID 565)
2017-07-01 18:26:49,588  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 9 ms
2017-07-01 18:26:49,592  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 144.0 in stage 19.0 (TID 561). 1609 bytes result sent to driver
2017-07-01 18:26:49,592  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 149.0 in stage 19.0 (TID 566, localhost, partition 150,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,593  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 144.0 in stage 19.0 (TID 561) in 57 ms on localhost (148/199)
2017-07-01 18:26:49,593  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 149.0 in stage 19.0 (TID 566)
2017-07-01 18:26:49,602  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,604  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:49,606  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 149.0 in stage 19.0 (TID 566). 1609 bytes result sent to driver
2017-07-01 18:26:49,608  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 150.0 in stage 19.0 (TID 567, localhost, partition 151,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,608  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 150.0 in stage 19.0 (TID 567)
2017-07-01 18:26:49,616  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,618  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:49,622  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 150.0 in stage 19.0 (TID 567). 1609 bytes result sent to driver
2017-07-01 18:26:49,624  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 151.0 in stage 19.0 (TID 568, localhost, partition 152,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,631  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,632  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 41 ms
2017-07-01 18:26:49,634  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 149.0 in stage 19.0 (TID 566) in 42 ms on localhost (149/199)
2017-07-01 18:26:49,634  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 150.0 in stage 19.0 (TID 567) in 26 ms on localhost (150/199)
2017-07-01 18:26:49,634  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 151.0 in stage 19.0 (TID 568)
2017-07-01 18:26:49,635  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 148.0 in stage 19.0 (TID 565). 1609 bytes result sent to driver
2017-07-01 18:26:49,635  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 152.0 in stage 19.0 (TID 569, localhost, partition 153,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,635  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 152.0 in stage 19.0 (TID 569)
2017-07-01 18:26:49,637  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 148.0 in stage 19.0 (TID 565) in 57 ms on localhost (151/199)
2017-07-01 18:26:49,639  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,639  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:49,644  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,647  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:26:49,652  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 152.0 in stage 19.0 (TID 569). 1609 bytes result sent to driver
2017-07-01 18:26:49,654  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 153.0 in stage 19.0 (TID 570, localhost, partition 154,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,657  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 153.0 in stage 19.0 (TID 570)
2017-07-01 18:26:49,663  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,667  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:26:49,670  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 152.0 in stage 19.0 (TID 569) in 35 ms on localhost (152/199)
2017-07-01 18:26:49,671  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 153.0 in stage 19.0 (TID 570). 1609 bytes result sent to driver
2017-07-01 18:26:49,673  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 154.0 in stage 19.0 (TID 571, localhost, partition 155,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,674  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 154.0 in stage 19.0 (TID 571)
2017-07-01 18:26:49,679  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,682  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:26:49,684  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 154.0 in stage 19.0 (TID 571). 1609 bytes result sent to driver
2017-07-01 18:26:49,686  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 151.0 in stage 19.0 (TID 568). 1965 bytes result sent to driver
2017-07-01 18:26:49,685  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 153.0 in stage 19.0 (TID 570) in 31 ms on localhost (153/199)
2017-07-01 18:26:49,696  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 155.0 in stage 19.0 (TID 572, localhost, partition 156,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,696  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 156.0 in stage 19.0 (TID 573, localhost, partition 157,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,697  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 154.0 in stage 19.0 (TID 571) in 24 ms on localhost (154/199)
2017-07-01 18:26:49,697  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 151.0 in stage 19.0 (TID 568) in 73 ms on localhost (155/199)
2017-07-01 18:26:49,697  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 155.0 in stage 19.0 (TID 572)
2017-07-01 18:26:49,698  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 156.0 in stage 19.0 (TID 573)
2017-07-01 18:26:49,705  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,706  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:26:49,707  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 156.0 in stage 19.0 (TID 573). 1609 bytes result sent to driver
2017-07-01 18:26:49,708  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 157.0 in stage 19.0 (TID 574, localhost, partition 158,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,708  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 157.0 in stage 19.0 (TID 574)
2017-07-01 18:26:49,710  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 156.0 in stage 19.0 (TID 573) in 14 ms on localhost (156/199)
2017-07-01 18:26:49,719  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,719  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:49,720  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,720  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:49,720  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 155.0 in stage 19.0 (TID 572). 1609 bytes result sent to driver
2017-07-01 18:26:49,722  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 158.0 in stage 19.0 (TID 575, localhost, partition 159,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,723  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 157.0 in stage 19.0 (TID 574). 1609 bytes result sent to driver
2017-07-01 18:26:49,725  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 159.0 in stage 19.0 (TID 576, localhost, partition 160,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,725  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 159.0 in stage 19.0 (TID 576)
2017-07-01 18:26:49,729  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,730  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:49,731  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 159.0 in stage 19.0 (TID 576). 1609 bytes result sent to driver
2017-07-01 18:26:49,732  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 160.0 in stage 19.0 (TID 577, localhost, partition 161,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,732  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 160.0 in stage 19.0 (TID 577)
2017-07-01 18:26:49,737  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 155.0 in stage 19.0 (TID 572) in 42 ms on localhost (157/199)
2017-07-01 18:26:49,738  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 159.0 in stage 19.0 (TID 576) in 13 ms on localhost (158/199)
2017-07-01 18:26:49,739  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 157.0 in stage 19.0 (TID 574) in 31 ms on localhost (159/199)
2017-07-01 18:26:49,752  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,754  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:49,755  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 160.0 in stage 19.0 (TID 577). 1609 bytes result sent to driver
2017-07-01 18:26:49,760  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 161.0 in stage 19.0 (TID 578, localhost, partition 162,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,760  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 160.0 in stage 19.0 (TID 577) in 28 ms on localhost (160/199)
2017-07-01 18:26:49,760  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 161.0 in stage 19.0 (TID 578)
2017-07-01 18:26:49,764  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,764  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:49,768  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 161.0 in stage 19.0 (TID 578). 1609 bytes result sent to driver
2017-07-01 18:26:49,770  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 162.0 in stage 19.0 (TID 579, localhost, partition 163,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,771  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 161.0 in stage 19.0 (TID 578) in 12 ms on localhost (161/199)
2017-07-01 18:26:49,771  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 162.0 in stage 19.0 (TID 579)
2017-07-01 18:26:49,782  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,788  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 6 ms
2017-07-01 18:26:49,790  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 162.0 in stage 19.0 (TID 579). 1609 bytes result sent to driver
2017-07-01 18:26:49,764  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 158.0 in stage 19.0 (TID 575)
2017-07-01 18:26:49,794  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 163.0 in stage 19.0 (TID 580, localhost, partition 164,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,797  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 163.0 in stage 19.0 (TID 580)
2017-07-01 18:26:49,805  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,810  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 5 ms
2017-07-01 18:26:49,812  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 158.0 in stage 19.0 (TID 575). 1609 bytes result sent to driver
2017-07-01 18:26:49,797  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 162.0 in stage 19.0 (TID 579) in 28 ms on localhost (162/199)
2017-07-01 18:26:49,809  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,836  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 27 ms
2017-07-01 18:26:49,837  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 163.0 in stage 19.0 (TID 580). 1609 bytes result sent to driver
2017-07-01 18:26:49,839  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 164.0 in stage 19.0 (TID 581, localhost, partition 165,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,839  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 165.0 in stage 19.0 (TID 582, localhost, partition 166,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,840  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 165.0 in stage 19.0 (TID 582)
2017-07-01 18:26:49,842  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 164.0 in stage 19.0 (TID 581)
2017-07-01 18:26:49,843  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 158.0 in stage 19.0 (TID 575) in 122 ms on localhost (163/199)
2017-07-01 18:26:49,843  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 163.0 in stage 19.0 (TID 580) in 49 ms on localhost (164/199)
2017-07-01 18:26:49,847  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,849  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:49,848  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,849  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:49,850  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 165.0 in stage 19.0 (TID 582). 1609 bytes result sent to driver
2017-07-01 18:26:49,851  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 166.0 in stage 19.0 (TID 583, localhost, partition 167,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,851  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 165.0 in stage 19.0 (TID 582) in 12 ms on localhost (165/199)
2017-07-01 18:26:49,852  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 166.0 in stage 19.0 (TID 583)
2017-07-01 18:26:49,864  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,866  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:49,869  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 166.0 in stage 19.0 (TID 583). 1609 bytes result sent to driver
2017-07-01 18:26:49,872  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 167.0 in stage 19.0 (TID 584, localhost, partition 168,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,875  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 167.0 in stage 19.0 (TID 584)
2017-07-01 18:26:49,878  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 164.0 in stage 19.0 (TID 581). 1609 bytes result sent to driver
2017-07-01 18:26:49,876  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 166.0 in stage 19.0 (TID 583) in 25 ms on localhost (166/199)
2017-07-01 18:26:49,894  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 168.0 in stage 19.0 (TID 585, localhost, partition 169,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,895  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 164.0 in stage 19.0 (TID 581) in 58 ms on localhost (167/199)
2017-07-01 18:26:49,897  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 168.0 in stage 19.0 (TID 585)
2017-07-01 18:26:49,904  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,904  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:49,910  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,910  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:49,914  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 167.0 in stage 19.0 (TID 584). 1609 bytes result sent to driver
2017-07-01 18:26:49,919  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 168.0 in stage 19.0 (TID 585). 1609 bytes result sent to driver
2017-07-01 18:26:49,920  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 169.0 in stage 19.0 (TID 586, localhost, partition 170,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,924  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 169.0 in stage 19.0 (TID 586)
2017-07-01 18:26:49,927  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 170.0 in stage 19.0 (TID 587, localhost, partition 171,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,928  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 170.0 in stage 19.0 (TID 587)
2017-07-01 18:26:49,928  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 167.0 in stage 19.0 (TID 584) in 56 ms on localhost (168/199)
2017-07-01 18:26:49,929  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 168.0 in stage 19.0 (TID 585) in 36 ms on localhost (169/199)
2017-07-01 18:26:49,933  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,934  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:49,935  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 170.0 in stage 19.0 (TID 587). 1609 bytes result sent to driver
2017-07-01 18:26:49,936  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 171.0 in stage 19.0 (TID 588, localhost, partition 172,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,936  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 171.0 in stage 19.0 (TID 588)
2017-07-01 18:26:49,943  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 170.0 in stage 19.0 (TID 587) in 18 ms on localhost (170/199)
2017-07-01 18:26:49,951  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,953  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:49,954  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 169.0 in stage 19.0 (TID 586). 1609 bytes result sent to driver
2017-07-01 18:26:49,955  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,957  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:49,966  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 172.0 in stage 19.0 (TID 589, localhost, partition 173,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,967  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 171.0 in stage 19.0 (TID 588). 1609 bytes result sent to driver
2017-07-01 18:26:49,967  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 172.0 in stage 19.0 (TID 589)
2017-07-01 18:26:49,970  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 173.0 in stage 19.0 (TID 590, localhost, partition 174,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,971  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 173.0 in stage 19.0 (TID 590)
2017-07-01 18:26:49,971  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 169.0 in stage 19.0 (TID 586) in 51 ms on localhost (171/199)
2017-07-01 18:26:49,971  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 171.0 in stage 19.0 (TID 588) in 36 ms on localhost (172/199)
2017-07-01 18:26:49,975  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,976  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:49,977  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 173.0 in stage 19.0 (TID 590). 1609 bytes result sent to driver
2017-07-01 18:26:49,978  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 174.0 in stage 19.0 (TID 591, localhost, partition 175,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,978  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 173.0 in stage 19.0 (TID 590) in 8 ms on localhost (173/199)
2017-07-01 18:26:49,978  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 174.0 in stage 19.0 (TID 591)
2017-07-01 18:26:49,984  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:49,984  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:49,985  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 174.0 in stage 19.0 (TID 591). 1609 bytes result sent to driver
2017-07-01 18:26:49,989  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 175.0 in stage 19.0 (TID 592, localhost, partition 176,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:49,991  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 175.0 in stage 19.0 (TID 592)
2017-07-01 18:26:49,992  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 174.0 in stage 19.0 (TID 591) in 15 ms on localhost (174/199)
2017-07-01 18:26:50,004  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:50,013  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 9 ms
2017-07-01 18:26:50,011  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:50,015  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:26:50,017  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 172.0 in stage 19.0 (TID 589). 1609 bytes result sent to driver
2017-07-01 18:26:50,017  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 175.0 in stage 19.0 (TID 592). 1609 bytes result sent to driver
2017-07-01 18:26:50,018  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 176.0 in stage 19.0 (TID 593, localhost, partition 177,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:50,019  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 176.0 in stage 19.0 (TID 593)
2017-07-01 18:26:50,021  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 177.0 in stage 19.0 (TID 594, localhost, partition 178,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:50,022  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 177.0 in stage 19.0 (TID 594)
2017-07-01 18:26:50,027  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 175.0 in stage 19.0 (TID 592) in 38 ms on localhost (175/199)
2017-07-01 18:26:50,028  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 172.0 in stage 19.0 (TID 589) in 63 ms on localhost (176/199)
2017-07-01 18:26:50,032  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:50,032  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:50,034  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:50,035  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:50,036  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 176.0 in stage 19.0 (TID 593). 1609 bytes result sent to driver
2017-07-01 18:26:50,035  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 177.0 in stage 19.0 (TID 594). 1609 bytes result sent to driver
2017-07-01 18:26:50,044  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 178.0 in stage 19.0 (TID 595, localhost, partition 179,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:50,045  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 176.0 in stage 19.0 (TID 593) in 27 ms on localhost (177/199)
2017-07-01 18:26:50,046  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 178.0 in stage 19.0 (TID 595)
2017-07-01 18:26:50,048  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 179.0 in stage 19.0 (TID 596, localhost, partition 180,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:50,049  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 177.0 in stage 19.0 (TID 594) in 28 ms on localhost (178/199)
2017-07-01 18:26:50,049  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 179.0 in stage 19.0 (TID 596)
2017-07-01 18:26:50,060  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:50,061  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:50,060  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:50,061  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:50,062  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 179.0 in stage 19.0 (TID 596). 1609 bytes result sent to driver
2017-07-01 18:26:50,067  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 180.0 in stage 19.0 (TID 597, localhost, partition 181,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:50,067  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 180.0 in stage 19.0 (TID 597)
2017-07-01 18:26:50,074  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 179.0 in stage 19.0 (TID 596) in 26 ms on localhost (179/199)
2017-07-01 18:26:50,077  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:50,077  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:50,078  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 180.0 in stage 19.0 (TID 597). 1609 bytes result sent to driver
2017-07-01 18:26:50,087  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 181.0 in stage 19.0 (TID 598, localhost, partition 182,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:50,089  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 181.0 in stage 19.0 (TID 598)
2017-07-01 18:26:50,092  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 180.0 in stage 19.0 (TID 597) in 25 ms on localhost (180/199)
2017-07-01 18:26:50,097  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:50,098  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:50,100  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 181.0 in stage 19.0 (TID 598). 1609 bytes result sent to driver
2017-07-01 18:26:50,066  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 178.0 in stage 19.0 (TID 595). 1609 bytes result sent to driver
2017-07-01 18:26:50,104  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 182.0 in stage 19.0 (TID 599, localhost, partition 183,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:50,104  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 181.0 in stage 19.0 (TID 598) in 23 ms on localhost (181/199)
2017-07-01 18:26:50,107  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 182.0 in stage 19.0 (TID 599)
2017-07-01 18:26:50,111  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 183.0 in stage 19.0 (TID 600, localhost, partition 184,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:50,112  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 178.0 in stage 19.0 (TID 595) in 68 ms on localhost (182/199)
2017-07-01 18:26:50,113  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 183.0 in stage 19.0 (TID 600)
2017-07-01 18:26:50,124  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:50,126  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:50,137  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 11 ms
2017-07-01 18:26:50,141  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 17 ms
2017-07-01 18:26:50,145  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 182.0 in stage 19.0 (TID 599). 1609 bytes result sent to driver
2017-07-01 18:26:50,150  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 184.0 in stage 19.0 (TID 601, localhost, partition 185,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:50,152  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 184.0 in stage 19.0 (TID 601)
2017-07-01 18:26:50,152  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 182.0 in stage 19.0 (TID 599) in 49 ms on localhost (183/199)
2017-07-01 18:26:50,158  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:50,159  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:50,165  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 184.0 in stage 19.0 (TID 601). 1609 bytes result sent to driver
2017-07-01 18:26:50,146  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 183.0 in stage 19.0 (TID 600). 1609 bytes result sent to driver
2017-07-01 18:26:50,171  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 185.0 in stage 19.0 (TID 602, localhost, partition 186,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:50,172  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 185.0 in stage 19.0 (TID 602)
2017-07-01 18:26:50,174  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 186.0 in stage 19.0 (TID 603, localhost, partition 187,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:50,175  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 183.0 in stage 19.0 (TID 600) in 65 ms on localhost (184/199)
2017-07-01 18:26:50,177  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 184.0 in stage 19.0 (TID 601) in 27 ms on localhost (185/199)
2017-07-01 18:26:50,182  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 186.0 in stage 19.0 (TID 603)
2017-07-01 18:26:50,195  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:50,196  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:50,195  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:50,196  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:50,200  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 185.0 in stage 19.0 (TID 602). 1609 bytes result sent to driver
2017-07-01 18:26:50,201  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 186.0 in stage 19.0 (TID 603). 1609 bytes result sent to driver
2017-07-01 18:26:50,204  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 187.0 in stage 19.0 (TID 604, localhost, partition 188,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:50,204  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 187.0 in stage 19.0 (TID 604)
2017-07-01 18:26:50,204  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 185.0 in stage 19.0 (TID 602) in 33 ms on localhost (186/199)
2017-07-01 18:26:50,210  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:50,210  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:26:50,211  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 187.0 in stage 19.0 (TID 604). 1609 bytes result sent to driver
2017-07-01 18:26:50,212  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 188.0 in stage 19.0 (TID 605, localhost, partition 189,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:50,212  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 188.0 in stage 19.0 (TID 605)
2017-07-01 18:26:50,213  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 187.0 in stage 19.0 (TID 604) in 9 ms on localhost (187/199)
2017-07-01 18:26:50,213  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 189.0 in stage 19.0 (TID 606, localhost, partition 190,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:50,214  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 186.0 in stage 19.0 (TID 603) in 40 ms on localhost (188/199)
2017-07-01 18:26:50,214  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 189.0 in stage 19.0 (TID 606)
2017-07-01 18:26:50,225  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:50,226  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:50,228  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 188.0 in stage 19.0 (TID 605). 1609 bytes result sent to driver
2017-07-01 18:26:50,230  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 190.0 in stage 19.0 (TID 607, localhost, partition 191,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:50,230  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 190.0 in stage 19.0 (TID 607)
2017-07-01 18:26:50,231  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 188.0 in stage 19.0 (TID 605) in 19 ms on localhost (189/199)
2017-07-01 18:26:50,242  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:50,244  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:50,243  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:50,245  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:50,254  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 189.0 in stage 19.0 (TID 606). 1609 bytes result sent to driver
2017-07-01 18:26:50,255  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 191.0 in stage 19.0 (TID 608, localhost, partition 192,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:50,255  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 191.0 in stage 19.0 (TID 608)
2017-07-01 18:26:50,256  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 190.0 in stage 19.0 (TID 607). 1609 bytes result sent to driver
2017-07-01 18:26:50,260  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:50,261  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:50,261  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 189.0 in stage 19.0 (TID 606) in 48 ms on localhost (190/199)
2017-07-01 18:26:50,262  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 191.0 in stage 19.0 (TID 608). 1609 bytes result sent to driver
2017-07-01 18:26:50,263  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 192.0 in stage 19.0 (TID 609, localhost, partition 193,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:50,264  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 192.0 in stage 19.0 (TID 609)
2017-07-01 18:26:50,265  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 193.0 in stage 19.0 (TID 610, localhost, partition 194,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:50,266  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 193.0 in stage 19.0 (TID 610)
2017-07-01 18:26:50,270  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 191.0 in stage 19.0 (TID 608) in 16 ms on localhost (191/199)
2017-07-01 18:26:50,271  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 190.0 in stage 19.0 (TID 607) in 42 ms on localhost (192/199)
2017-07-01 18:26:50,276  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:50,279  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:26:50,280  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 192.0 in stage 19.0 (TID 609). 1609 bytes result sent to driver
2017-07-01 18:26:50,279  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:50,282  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:26:50,283  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 193.0 in stage 19.0 (TID 610). 1609 bytes result sent to driver
2017-07-01 18:26:50,284  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 194.0 in stage 19.0 (TID 611, localhost, partition 195,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:50,284  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 194.0 in stage 19.0 (TID 611)
2017-07-01 18:26:50,285  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 195.0 in stage 19.0 (TID 612, localhost, partition 196,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:50,292  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 192.0 in stage 19.0 (TID 609) in 30 ms on localhost (193/199)
2017-07-01 18:26:50,292  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 193.0 in stage 19.0 (TID 610) in 27 ms on localhost (194/199)
2017-07-01 18:26:50,293  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 195.0 in stage 19.0 (TID 612)
2017-07-01 18:26:50,306  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:50,307  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:50,307  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:50,309  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:50,311  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 194.0 in stage 19.0 (TID 611). 1609 bytes result sent to driver
2017-07-01 18:26:50,312  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 195.0 in stage 19.0 (TID 612). 1609 bytes result sent to driver
2017-07-01 18:26:50,314  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 196.0 in stage 19.0 (TID 613, localhost, partition 197,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:50,315  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 196.0 in stage 19.0 (TID 613)
2017-07-01 18:26:50,316  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 197.0 in stage 19.0 (TID 614, localhost, partition 198,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:50,316  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 197.0 in stage 19.0 (TID 614)
2017-07-01 18:26:50,325  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 194.0 in stage 19.0 (TID 611) in 41 ms on localhost (195/199)
2017-07-01 18:26:50,326  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 195.0 in stage 19.0 (TID 612) in 42 ms on localhost (196/199)
2017-07-01 18:26:50,334  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:50,336  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:50,335  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:50,337  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:26:50,339  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 197.0 in stage 19.0 (TID 614). 1609 bytes result sent to driver
2017-07-01 18:26:50,340  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 196.0 in stage 19.0 (TID 613). 1609 bytes result sent to driver
2017-07-01 18:26:50,341  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 198.0 in stage 19.0 (TID 615, localhost, partition 199,NODE_LOCAL, 2044 bytes)
2017-07-01 18:26:50,342  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 198.0 in stage 19.0 (TID 615)
2017-07-01 18:26:50,344  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 197.0 in stage 19.0 (TID 614) in 28 ms on localhost (197/199)
2017-07-01 18:26:50,344  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 196.0 in stage 19.0 (TID 613) in 30 ms on localhost (198/199)
2017-07-01 18:26:50,347  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:26:50,348  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:26:50,349  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 198.0 in stage 19.0 (TID 615). 1609 bytes result sent to driver
2017-07-01 18:26:50,351  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 198.0 in stage 19.0 (TID 615) in 10 ms on localhost (199/199)
2017-07-01 18:26:50,352  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 19.0, whose tasks have all completed, from pool 
2017-07-01 18:26:50,352  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 19 (show at <console>:65) finished in 2,406 s
2017-07-01 18:26:50,352  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.scheduler.DAGScheduler) - Job 13 finished: show at <console>:65, took 2,461113 s
2017-07-01 18:26:51,099  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_31_piece0 on localhost:56220 in memory (size: 7.0 KB, free: 116.4 MB)
2017-07-01 18:26:51,102  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 48
2017-07-01 18:26:51,104  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned shuffle 2
2017-07-01 18:26:51,104  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 45
2017-07-01 18:26:51,104  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 44
2017-07-01 18:26:51,104  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 43
2017-07-01 18:26:51,104  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 42
2017-07-01 18:26:51,104  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 41
2017-07-01 18:26:51,105  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 40
2017-07-01 18:26:51,105  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 39
2017-07-01 18:26:51,105  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 38
2017-07-01 18:26:51,108  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_28_piece0 on localhost:56220 in memory (size: 19.6 KB, free: 116.4 MB)
2017-07-01 18:27:00,155  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_32 stored as values in memory (estimated size 187.4 KB, free 187.4 KB)
2017-07-01 18:27:00,220  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_32_piece0 stored as bytes in memory (estimated size 19.5 KB, free 206.9 KB)
2017-07-01 18:27:00,223  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_32_piece0 in memory on localhost:56220 (size: 19.5 KB, free: 116.4 MB)
2017-07-01 18:27:00,237  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 32 from show at <console>:63
2017-07-01 18:27:00,251  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_33 stored as values in memory (estimated size 188.0 KB, free 394.9 KB)
2017-07-01 18:27:00,277  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_33_piece0 stored as bytes in memory (estimated size 19.6 KB, free 414.5 KB)
2017-07-01 18:27:00,278  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_33_piece0 in memory on localhost:56220 (size: 19.6 KB, free: 116.4 MB)
2017-07-01 18:27:00,281  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 33 from show at <console>:63
2017-07-01 18:27:00,319  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.hadoop.mapred.FileInputFormat) - Total input paths to process : 1
2017-07-01 18:27:00,324  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: show at <console>:63
2017-07-01 18:27:00,331  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 14 (show at <console>:63) with 1 output partitions
2017-07-01 18:27:00,331  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 20 (show at <console>:63)
2017-07-01 18:27:00,331  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2017-07-01 18:27:00,331  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2017-07-01 18:27:00,332  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 20 (MapPartitionsRDD[68] at show at <console>:63), which has no missing parents
2017-07-01 18:27:00,337  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_34 stored as values in memory (estimated size 8.5 KB, free 423.1 KB)
2017-07-01 18:27:00,342  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_34_piece0 stored as bytes in memory (estimated size 4.5 KB, free 427.5 KB)
2017-07-01 18:27:00,346  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_34_piece0 in memory on localhost:56220 (size: 4.5 KB, free: 116.4 MB)
2017-07-01 18:27:00,349  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 34 from broadcast at DAGScheduler.scala:1006
2017-07-01 18:27:00,351  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[68] at show at <console>:63)
2017-07-01 18:27:00,352  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 20.0 with 1 tasks
2017-07-01 18:27:00,355  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 20.0 (TID 616, localhost, partition 0,PROCESS_LOCAL, 2198 bytes)
2017-07-01 18:27:00,356  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 20.0 (TID 616)
2017-07-01 18:27:00,359  INFO [Executor task launch worker-8] (org.apache.spark.rdd.HadoopRDD) - Input split: file:/home/turmasabado/spark-notebook/produtos.json:0+500
2017-07-01 18:27:00,369  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 20.0 (TID 616). 3221 bytes result sent to driver
2017-07-01 18:27:00,375  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 20.0 (TID 616) in 20 ms on localhost (1/1)
2017-07-01 18:27:00,375  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 20.0, whose tasks have all completed, from pool 
2017-07-01 18:27:00,375  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 20 (show at <console>:63) finished in 0,010 s
2017-07-01 18:27:00,376  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 14 finished: show at <console>:63, took 0,046388 s
2017-07-01 18:27:00,383  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: show at <console>:63
2017-07-01 18:27:00,383  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 15 (show at <console>:63) with 1 output partitions
2017-07-01 18:27:00,383  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 21 (show at <console>:63)
2017-07-01 18:27:00,383  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2017-07-01 18:27:00,384  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2017-07-01 18:27:00,384  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 21 (MapPartitionsRDD[68] at show at <console>:63), which has no missing parents
2017-07-01 18:27:00,386  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_35 stored as values in memory (estimated size 8.5 KB, free 436.1 KB)
2017-07-01 18:27:00,392  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_35_piece0 stored as bytes in memory (estimated size 4.5 KB, free 440.5 KB)
2017-07-01 18:27:00,393  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_35_piece0 in memory on localhost:56220 (size: 4.5 KB, free: 116.4 MB)
2017-07-01 18:27:00,393  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 35 from broadcast at DAGScheduler.scala:1006
2017-07-01 18:27:00,394  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[68] at show at <console>:63)
2017-07-01 18:27:00,394  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 21.0 with 1 tasks
2017-07-01 18:27:00,397  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 21.0 (TID 617, localhost, partition 1,PROCESS_LOCAL, 2198 bytes)
2017-07-01 18:27:00,397  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 21.0 (TID 617)
2017-07-01 18:27:00,403  INFO [Executor task launch worker-8] (org.apache.spark.rdd.HadoopRDD) - Input split: file:/home/turmasabado/spark-notebook/produtos.json:500+501
2017-07-01 18:27:00,411  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 21.0 (TID 617). 2283 bytes result sent to driver
2017-07-01 18:27:00,413  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 21.0 (TID 617) in 17 ms on localhost (1/1)
2017-07-01 18:27:00,413  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 21.0, whose tasks have all completed, from pool 
2017-07-01 18:27:00,413  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 21 (show at <console>:63) finished in 0,016 s
2017-07-01 18:27:00,413  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 15 finished: show at <console>:63, took 0,030556 s
2017-07-01 18:27:01,290  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_35_piece0 on localhost:56220 in memory (size: 4.5 KB, free: 116.4 MB)
2017-07-01 18:27:01,296  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 52
2017-07-01 18:27:01,298  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_34_piece0 on localhost:56220 in memory (size: 4.5 KB, free: 116.4 MB)
2017-07-01 18:27:01,298  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 51
2017-07-01 18:27:01,299  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 50
2017-07-01 18:27:01,299  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 49
2017-07-01 18:27:01,305  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_33_piece0 on localhost:56220 in memory (size: 19.6 KB, free: 116.4 MB)
2017-07-01 18:27:01,306  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_32_piece0 on localhost:56220 in memory (size: 19.5 KB, free: 116.4 MB)
2017-07-01 18:27:02,922  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.storage.MemoryStore) - Block broadcast_36 stored as values in memory (estimated size 187.4 KB, free 187.4 KB)
2017-07-01 18:27:02,975  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.storage.MemoryStore) - Block broadcast_36_piece0 stored as bytes in memory (estimated size 19.5 KB, free 206.9 KB)
2017-07-01 18:27:02,976  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_36_piece0 in memory on localhost:56220 (size: 19.5 KB, free: 116.4 MB)
2017-07-01 18:27:02,979  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.SparkContext) - Created broadcast 36 from show at <console>:63
2017-07-01 18:27:02,988  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.storage.MemoryStore) - Block broadcast_37 stored as values in memory (estimated size 188.0 KB, free 394.9 KB)
2017-07-01 18:27:03,020  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.storage.MemoryStore) - Block broadcast_37_piece0 stored as bytes in memory (estimated size 19.6 KB, free 414.5 KB)
2017-07-01 18:27:03,021  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_37_piece0 in memory on localhost:56220 (size: 19.6 KB, free: 116.4 MB)
2017-07-01 18:27:03,023  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.SparkContext) - Created broadcast 37 from show at <console>:63
2017-07-01 18:27:03,111  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.hadoop.mapred.FileInputFormat) - Total input paths to process : 1
2017-07-01 18:27:03,123  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.SparkContext) - Starting job: show at <console>:63
2017-07-01 18:27:03,145  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 16 (show at <console>:63) with 1 output partitions
2017-07-01 18:27:03,145  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 22 (show at <console>:63)
2017-07-01 18:27:03,145  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2017-07-01 18:27:03,145  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2017-07-01 18:27:03,146  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 22 (MapPartitionsRDD[75] at show at <console>:63), which has no missing parents
2017-07-01 18:27:03,147  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_38 stored as values in memory (estimated size 8.7 KB, free 423.2 KB)
2017-07-01 18:27:03,155  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_38_piece0 stored as bytes in memory (estimated size 4.5 KB, free 427.7 KB)
2017-07-01 18:27:03,156  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_38_piece0 in memory on localhost:56220 (size: 4.5 KB, free: 116.4 MB)
2017-07-01 18:27:03,156  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 38 from broadcast at DAGScheduler.scala:1006
2017-07-01 18:27:03,156  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[75] at show at <console>:63)
2017-07-01 18:27:03,157  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 22.0 with 1 tasks
2017-07-01 18:27:03,157  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 22.0 (TID 618, localhost, partition 0,PROCESS_LOCAL, 2198 bytes)
2017-07-01 18:27:03,158  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 22.0 (TID 618)
2017-07-01 18:27:03,160  INFO [Executor task launch worker-8] (org.apache.spark.rdd.HadoopRDD) - Input split: file:/home/turmasabado/spark-notebook/produtos.json:0+500
2017-07-01 18:27:03,184  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 22.0 (TID 618). 3055 bytes result sent to driver
2017-07-01 18:27:03,186  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 22.0 (TID 618) in 29 ms on localhost (1/1)
2017-07-01 18:27:03,186  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 22.0, whose tasks have all completed, from pool 
2017-07-01 18:27:03,187  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 22 (show at <console>:63) finished in 0,028 s
2017-07-01 18:27:03,202  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.scheduler.DAGScheduler) - Job 16 finished: show at <console>:63, took 0,067336 s
2017-07-01 18:27:03,220  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.SparkContext) - Starting job: show at <console>:63
2017-07-01 18:27:03,221  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 17 (show at <console>:63) with 1 output partitions
2017-07-01 18:27:03,222  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 23 (show at <console>:63)
2017-07-01 18:27:03,222  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2017-07-01 18:27:03,222  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2017-07-01 18:27:03,223  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 23 (MapPartitionsRDD[75] at show at <console>:63), which has no missing parents
2017-07-01 18:27:03,224  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_39 stored as values in memory (estimated size 8.7 KB, free 436.4 KB)
2017-07-01 18:27:03,231  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_39_piece0 stored as bytes in memory (estimated size 4.5 KB, free 440.9 KB)
2017-07-01 18:27:03,233  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_39_piece0 in memory on localhost:56220 (size: 4.5 KB, free: 116.4 MB)
2017-07-01 18:27:03,235  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 39 from broadcast at DAGScheduler.scala:1006
2017-07-01 18:27:03,236  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[75] at show at <console>:63)
2017-07-01 18:27:03,236  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 23.0 with 1 tasks
2017-07-01 18:27:03,236  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 23.0 (TID 619, localhost, partition 1,PROCESS_LOCAL, 2198 bytes)
2017-07-01 18:27:03,237  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 23.0 (TID 619)
2017-07-01 18:27:03,240  INFO [Executor task launch worker-8] (org.apache.spark.rdd.HadoopRDD) - Input split: file:/home/turmasabado/spark-notebook/produtos.json:500+501
2017-07-01 18:27:03,249  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 23.0 (TID 619). 2283 bytes result sent to driver
2017-07-01 18:27:03,252  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 23.0 (TID 619) in 16 ms on localhost (1/1)
2017-07-01 18:27:03,252  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 23.0, whose tasks have all completed, from pool 
2017-07-01 18:27:03,252  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 23 (show at <console>:63) finished in 0,015 s
2017-07-01 18:27:03,253  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.scheduler.DAGScheduler) - Job 17 finished: show at <console>:63, took 0,032604 s
2017-07-01 18:27:03,302  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_39_piece0 on localhost:56220 in memory (size: 4.5 KB, free: 116.4 MB)
2017-07-01 18:27:03,302  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 56
2017-07-01 18:27:03,303  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_38_piece0 on localhost:56220 in memory (size: 4.5 KB, free: 116.4 MB)
2017-07-01 18:27:03,304  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 55
2017-07-01 18:27:03,304  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 54
2017-07-01 18:27:03,304  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 53
2017-07-01 18:27:03,304  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_37_piece0 on localhost:56220 in memory (size: 19.6 KB, free: 116.4 MB)
2017-07-01 18:27:03,306  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_36_piece0 on localhost:56220 in memory (size: 19.5 KB, free: 116.4 MB)
2017-07-01 18:27:05,334  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_40 stored as values in memory (estimated size 187.4 KB, free 187.4 KB)
2017-07-01 18:27:05,360  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_40_piece0 stored as bytes in memory (estimated size 19.5 KB, free 206.9 KB)
2017-07-01 18:27:05,363  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_40_piece0 in memory on localhost:56220 (size: 19.5 KB, free: 116.4 MB)
2017-07-01 18:27:05,366  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 40 from show at <console>:64
2017-07-01 18:27:05,375  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_41 stored as values in memory (estimated size 188.0 KB, free 394.9 KB)
2017-07-01 18:27:05,415  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_41_piece0 stored as bytes in memory (estimated size 19.6 KB, free 414.5 KB)
2017-07-01 18:27:05,416  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_41_piece0 in memory on localhost:56220 (size: 19.6 KB, free: 116.4 MB)
2017-07-01 18:27:05,420  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 41 from show at <console>:64
2017-07-01 18:27:05,466  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.hadoop.mapred.FileInputFormat) - Total input paths to process : 1
2017-07-01 18:27:05,472  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: show at <console>:64
2017-07-01 18:27:05,474  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 18 (show at <console>:64) with 2 output partitions
2017-07-01 18:27:05,474  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 24 (show at <console>:64)
2017-07-01 18:27:05,474  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2017-07-01 18:27:05,475  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2017-07-01 18:27:05,475  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 24 (MapPartitionsRDD[83] at show at <console>:64), which has no missing parents
2017-07-01 18:27:05,476  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_42 stored as values in memory (estimated size 9.5 KB, free 424.0 KB)
2017-07-01 18:27:05,485  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_42_piece0 stored as bytes in memory (estimated size 4.9 KB, free 428.9 KB)
2017-07-01 18:27:05,488  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_42_piece0 in memory on localhost:56220 (size: 4.9 KB, free: 116.4 MB)
2017-07-01 18:27:05,490  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 42 from broadcast at DAGScheduler.scala:1006
2017-07-01 18:27:05,491  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 24 (MapPartitionsRDD[83] at show at <console>:64)
2017-07-01 18:27:05,493  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 24.0 with 2 tasks
2017-07-01 18:27:05,496  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 24.0 (TID 620, localhost, partition 0,PROCESS_LOCAL, 2198 bytes)
2017-07-01 18:27:05,496  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 24.0 (TID 621, localhost, partition 1,PROCESS_LOCAL, 2198 bytes)
2017-07-01 18:27:05,496  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 24.0 (TID 620)
2017-07-01 18:27:05,497  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 24.0 (TID 621)
2017-07-01 18:27:05,504  INFO [Executor task launch worker-6] (org.apache.spark.rdd.HadoopRDD) - Input split: file:/home/turmasabado/spark-notebook/produtos.json:500+501
2017-07-01 18:27:05,506  INFO [Executor task launch worker-8] (org.apache.spark.rdd.HadoopRDD) - Input split: file:/home/turmasabado/spark-notebook/produtos.json:0+500
2017-07-01 18:27:05,523  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 24.0 (TID 621). 3327 bytes result sent to driver
2017-07-01 18:27:05,527  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 24.0 (TID 621) in 31 ms on localhost (1/2)
2017-07-01 18:27:05,528  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 24.0 (TID 620). 4435 bytes result sent to driver
2017-07-01 18:27:05,530  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 24.0 (TID 620) in 34 ms on localhost (2/2)
2017-07-01 18:27:05,530  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 24.0, whose tasks have all completed, from pool 
2017-07-01 18:27:05,530  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 24 (show at <console>:64) finished in 0,033 s
2017-07-01 18:27:05,531  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 18 finished: show at <console>:64, took 0,058795 s
2017-07-01 18:27:06,528  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_40_piece0 on localhost:56220 in memory (size: 19.5 KB, free: 116.4 MB)
2017-07-01 18:27:06,532  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_42_piece0 on localhost:56220 in memory (size: 4.9 KB, free: 116.4 MB)
2017-07-01 18:27:06,532  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 59
2017-07-01 18:27:06,532  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 58
2017-07-01 18:27:06,532  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 57
2017-07-01 18:27:06,535  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_41_piece0 on localhost:56220 in memory (size: 19.6 KB, free: 116.4 MB)
2017-07-01 18:27:07,226  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.storage.MemoryStore) - Block broadcast_43 stored as values in memory (estimated size 187.4 KB, free 187.4 KB)
2017-07-01 18:27:07,259  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.storage.MemoryStore) - Block broadcast_43_piece0 stored as bytes in memory (estimated size 19.5 KB, free 206.9 KB)
2017-07-01 18:27:07,259  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_43_piece0 in memory on localhost:56220 (size: 19.5 KB, free: 116.4 MB)
2017-07-01 18:27:07,261  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.SparkContext) - Created broadcast 43 from show at <console>:65
2017-07-01 18:27:07,266  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.storage.MemoryStore) - Block broadcast_44 stored as values in memory (estimated size 188.0 KB, free 394.9 KB)
2017-07-01 18:27:07,293  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.storage.MemoryStore) - Block broadcast_44_piece0 stored as bytes in memory (estimated size 19.6 KB, free 414.5 KB)
2017-07-01 18:27:07,295  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_44_piece0 in memory on localhost:56220 (size: 19.6 KB, free: 116.4 MB)
2017-07-01 18:27:07,298  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.SparkContext) - Created broadcast 44 from show at <console>:65
2017-07-01 18:27:07,350  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.hadoop.mapred.FileInputFormat) - Total input paths to process : 1
2017-07-01 18:27:07,387  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.SparkContext) - Starting job: show at <console>:65
2017-07-01 18:27:07,389  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Registering RDD 89 (show at <console>:65)
2017-07-01 18:27:07,390  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 19 (show at <console>:65) with 1 output partitions
2017-07-01 18:27:07,390  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 26 (show at <console>:65)
2017-07-01 18:27:07,390  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List(ShuffleMapStage 25)
2017-07-01 18:27:07,390  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List(ShuffleMapStage 25)
2017-07-01 18:27:07,393  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ShuffleMapStage 25 (MapPartitionsRDD[89] at show at <console>:65), which has no missing parents
2017-07-01 18:27:07,395  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_45 stored as values in memory (estimated size 11.2 KB, free 425.7 KB)
2017-07-01 18:27:07,400  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_45_piece0 stored as bytes in memory (estimated size 5.7 KB, free 431.4 KB)
2017-07-01 18:27:07,405  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_45_piece0 in memory on localhost:56220 (size: 5.7 KB, free: 116.4 MB)
2017-07-01 18:27:07,407  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 45 from broadcast at DAGScheduler.scala:1006
2017-07-01 18:27:07,408  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[89] at show at <console>:65)
2017-07-01 18:27:07,409  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 25.0 with 2 tasks
2017-07-01 18:27:07,411  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 25.0 (TID 622, localhost, partition 0,PROCESS_LOCAL, 2187 bytes)
2017-07-01 18:27:07,411  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 25.0 (TID 623, localhost, partition 1,PROCESS_LOCAL, 2187 bytes)
2017-07-01 18:27:07,411  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 25.0 (TID 622)
2017-07-01 18:27:07,413  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 25.0 (TID 623)
2017-07-01 18:27:07,419  INFO [Executor task launch worker-8] (org.apache.spark.rdd.HadoopRDD) - Input split: file:/home/turmasabado/spark-notebook/produtos.json:0+500
2017-07-01 18:27:07,420  INFO [Executor task launch worker-6] (org.apache.spark.rdd.HadoopRDD) - Input split: file:/home/turmasabado/spark-notebook/produtos.json:500+501
2017-07-01 18:27:07,428  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 25.0 (TID 623). 2702 bytes result sent to driver
2017-07-01 18:27:07,431  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 25.0 (TID 623) in 20 ms on localhost (1/2)
2017-07-01 18:27:07,490  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_43_piece0 on localhost:56220 in memory (size: 19.5 KB, free: 116.4 MB)
2017-07-01 18:27:07,533  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 25.0 (TID 622). 2702 bytes result sent to driver
2017-07-01 18:27:07,536  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 25.0 (TID 622) in 124 ms on localhost (2/2)
2017-07-01 18:27:07,536  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 25.0, whose tasks have all completed, from pool 
2017-07-01 18:27:07,536  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ShuffleMapStage 25 (show at <console>:65) finished in 0,126 s
2017-07-01 18:27:07,536  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - looking for newly runnable stages
2017-07-01 18:27:07,536  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - running: Set()
2017-07-01 18:27:07,536  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - waiting: Set(ResultStage 26)
2017-07-01 18:27:07,536  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - failed: Set()
2017-07-01 18:27:07,536  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 26 (MapPartitionsRDD[93] at show at <console>:65), which has no missing parents
2017-07-01 18:27:07,539  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_46 stored as values in memory (estimated size 13.1 KB, free 237.6 KB)
2017-07-01 18:27:07,544  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_46_piece0 stored as bytes in memory (estimated size 7.0 KB, free 244.6 KB)
2017-07-01 18:27:07,545  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_46_piece0 in memory on localhost:56220 (size: 7.0 KB, free: 116.4 MB)
2017-07-01 18:27:07,547  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 46 from broadcast at DAGScheduler.scala:1006
2017-07-01 18:27:07,548  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[93] at show at <console>:65)
2017-07-01 18:27:07,549  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 26.0 with 1 tasks
2017-07-01 18:27:07,551  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 26.0 (TID 624, localhost, partition 0,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:07,552  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 26.0 (TID 624)
2017-07-01 18:27:07,556  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:07,557  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:07,559  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 26.0 (TID 624). 1609 bytes result sent to driver
2017-07-01 18:27:07,561  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 26.0 (TID 624) in 11 ms on localhost (1/1)
2017-07-01 18:27:07,561  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 26.0, whose tasks have all completed, from pool 
2017-07-01 18:27:07,563  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 26 (show at <console>:65) finished in 0,009 s
2017-07-01 18:27:07,564  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.scheduler.DAGScheduler) - Job 19 finished: show at <console>:65, took 0,175637 s
2017-07-01 18:27:07,574  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.SparkContext) - Starting job: show at <console>:65
2017-07-01 18:27:07,576  INFO [dag-scheduler-event-loop] (org.apache.spark.MapOutputTrackerMaster) - Size of output statuses for shuffle 3 is 169 bytes
2017-07-01 18:27:07,578  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 20 (show at <console>:65) with 199 output partitions
2017-07-01 18:27:07,578  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 28 (show at <console>:65)
2017-07-01 18:27:07,579  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List(ShuffleMapStage 27)
2017-07-01 18:27:07,580  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2017-07-01 18:27:07,581  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 28 (MapPartitionsRDD[93] at show at <console>:65), which has no missing parents
2017-07-01 18:27:07,607  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_47 stored as values in memory (estimated size 13.1 KB, free 257.7 KB)
2017-07-01 18:27:07,612  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_47_piece0 stored as bytes in memory (estimated size 7.0 KB, free 264.7 KB)
2017-07-01 18:27:07,614  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_47_piece0 in memory on localhost:56220 (size: 7.0 KB, free: 116.4 MB)
2017-07-01 18:27:07,615  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 47 from broadcast at DAGScheduler.scala:1006
2017-07-01 18:27:07,621  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 199 missing tasks from ResultStage 28 (MapPartitionsRDD[93] at show at <console>:65)
2017-07-01 18:27:07,623  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 28.0 with 199 tasks
2017-07-01 18:27:07,630  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 28.0 (TID 625, localhost, partition 1,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:07,630  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 28.0 (TID 626, localhost, partition 2,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:07,630  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 28.0 (TID 625)
2017-07-01 18:27:07,633  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 28.0 (TID 626)
2017-07-01 18:27:07,647  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:07,650  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:27:07,653  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 28.0 (TID 626). 1609 bytes result sent to driver
2017-07-01 18:27:07,649  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:07,655  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 6 ms
2017-07-01 18:27:07,656  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 28.0 (TID 625). 1609 bytes result sent to driver
2017-07-01 18:27:07,657  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 2.0 in stage 28.0 (TID 627, localhost, partition 3,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:07,660  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 2.0 in stage 28.0 (TID 627)
2017-07-01 18:27:07,661  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 28.0 (TID 626) in 29 ms on localhost (1/199)
2017-07-01 18:27:07,663  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 3.0 in stage 28.0 (TID 628, localhost, partition 4,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:07,664  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 28.0 (TID 625) in 34 ms on localhost (2/199)
2017-07-01 18:27:07,664  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 3.0 in stage 28.0 (TID 628)
2017-07-01 18:27:07,673  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:07,673  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:07,676  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 3.0 in stage 28.0 (TID 628). 1609 bytes result sent to driver
2017-07-01 18:27:07,678  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 4.0 in stage 28.0 (TID 629, localhost, partition 5,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:07,678  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 3.0 in stage 28.0 (TID 628) in 15 ms on localhost (3/199)
2017-07-01 18:27:07,679  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 4.0 in stage 28.0 (TID 629)
2017-07-01 18:27:07,690  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:07,692  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:27:07,692  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:07,693  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:07,696  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 4.0 in stage 28.0 (TID 629). 1609 bytes result sent to driver
2017-07-01 18:27:07,698  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 5.0 in stage 28.0 (TID 630, localhost, partition 6,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:07,700  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 4.0 in stage 28.0 (TID 629) in 23 ms on localhost (4/199)
2017-07-01 18:27:07,701  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 5.0 in stage 28.0 (TID 630)
2017-07-01 18:27:07,706  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:07,707  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:07,709  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 5.0 in stage 28.0 (TID 630). 1609 bytes result sent to driver
2017-07-01 18:27:07,710  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 6.0 in stage 28.0 (TID 631, localhost, partition 7,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:07,710  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 6.0 in stage 28.0 (TID 631)
2017-07-01 18:27:07,711  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 5.0 in stage 28.0 (TID 630) in 13 ms on localhost (5/199)
2017-07-01 18:27:07,717  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:07,717  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:07,719  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 6.0 in stage 28.0 (TID 631). 1609 bytes result sent to driver
2017-07-01 18:27:07,720  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 7.0 in stage 28.0 (TID 632, localhost, partition 8,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:07,720  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 6.0 in stage 28.0 (TID 631) in 10 ms on localhost (6/199)
2017-07-01 18:27:07,720  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 7.0 in stage 28.0 (TID 632)
2017-07-01 18:27:07,726  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:07,727  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:07,729  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 7.0 in stage 28.0 (TID 632). 1609 bytes result sent to driver
2017-07-01 18:27:07,730  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 8.0 in stage 28.0 (TID 633, localhost, partition 9,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:07,731  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 8.0 in stage 28.0 (TID 633)
2017-07-01 18:27:07,732  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 7.0 in stage 28.0 (TID 632) in 12 ms on localhost (7/199)
2017-07-01 18:27:07,737  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:07,738  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:07,740  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 8.0 in stage 28.0 (TID 633). 1609 bytes result sent to driver
2017-07-01 18:27:07,741  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 9.0 in stage 28.0 (TID 634, localhost, partition 10,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:07,742  INFO [Executor task launch worker-9] (org.apache.spark.executor.Executor) - Running task 9.0 in stage 28.0 (TID 634)
2017-07-01 18:27:07,742  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 8.0 in stage 28.0 (TID 633) in 12 ms on localhost (8/199)
2017-07-01 18:27:07,748  INFO [Executor task launch worker-9] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:07,749  INFO [Executor task launch worker-9] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:07,750  INFO [Executor task launch worker-9] (org.apache.spark.executor.Executor) - Finished task 9.0 in stage 28.0 (TID 634). 1609 bytes result sent to driver
2017-07-01 18:27:07,752  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 10.0 in stage 28.0 (TID 635, localhost, partition 11,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:07,753  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 10.0 in stage 28.0 (TID 635)
2017-07-01 18:27:07,697  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 2.0 in stage 28.0 (TID 627). 1609 bytes result sent to driver
2017-07-01 18:27:07,753  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 9.0 in stage 28.0 (TID 634) in 12 ms on localhost (9/199)
2017-07-01 18:27:07,761  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 11.0 in stage 28.0 (TID 636, localhost, partition 12,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:07,761  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 2.0 in stage 28.0 (TID 627) in 104 ms on localhost (10/199)
2017-07-01 18:27:07,763  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 11.0 in stage 28.0 (TID 636)
2017-07-01 18:27:07,769  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:07,772  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:27:07,774  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 10.0 in stage 28.0 (TID 635). 1609 bytes result sent to driver
2017-07-01 18:27:07,777  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:07,778  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 12.0 in stage 28.0 (TID 637, localhost, partition 13,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:07,780  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 10.0 in stage 28.0 (TID 635) in 28 ms on localhost (11/199)
2017-07-01 18:27:07,781  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 12.0 in stage 28.0 (TID 637)
2017-07-01 18:27:07,783  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 6 ms
2017-07-01 18:27:07,786  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 11.0 in stage 28.0 (TID 636). 1609 bytes result sent to driver
2017-07-01 18:27:07,789  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 13.0 in stage 28.0 (TID 638, localhost, partition 14,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:07,790  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 11.0 in stage 28.0 (TID 636) in 29 ms on localhost (12/199)
2017-07-01 18:27:07,791  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 13.0 in stage 28.0 (TID 638)
2017-07-01 18:27:07,798  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:07,799  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:07,808  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:07,809  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:07,813  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 12.0 in stage 28.0 (TID 637). 1609 bytes result sent to driver
2017-07-01 18:27:07,813  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 13.0 in stage 28.0 (TID 638). 1963 bytes result sent to driver
2017-07-01 18:27:07,815  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 14.0 in stage 28.0 (TID 639, localhost, partition 15,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:07,815  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 12.0 in stage 28.0 (TID 637) in 37 ms on localhost (13/199)
2017-07-01 18:27:07,816  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 14.0 in stage 28.0 (TID 639)
2017-07-01 18:27:07,821  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 15.0 in stage 28.0 (TID 640, localhost, partition 16,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:07,822  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 13.0 in stage 28.0 (TID 638) in 33 ms on localhost (14/199)
2017-07-01 18:27:07,822  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 15.0 in stage 28.0 (TID 640)
2017-07-01 18:27:07,823  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:07,828  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 5 ms
2017-07-01 18:27:07,829  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 14.0 in stage 28.0 (TID 639). 1609 bytes result sent to driver
2017-07-01 18:27:07,831  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 16.0 in stage 28.0 (TID 641, localhost, partition 17,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:07,832  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 16.0 in stage 28.0 (TID 641)
2017-07-01 18:27:07,834  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 14.0 in stage 28.0 (TID 639) in 19 ms on localhost (15/199)
2017-07-01 18:27:07,838  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:07,838  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:07,838  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:07,838  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:07,839  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 15.0 in stage 28.0 (TID 640). 1609 bytes result sent to driver
2017-07-01 18:27:07,840  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 16.0 in stage 28.0 (TID 641). 1609 bytes result sent to driver
2017-07-01 18:27:07,842  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 17.0 in stage 28.0 (TID 642, localhost, partition 18,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:07,842  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 15.0 in stage 28.0 (TID 640) in 21 ms on localhost (16/199)
2017-07-01 18:27:07,843  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 17.0 in stage 28.0 (TID 642)
2017-07-01 18:27:07,846  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 18.0 in stage 28.0 (TID 643, localhost, partition 19,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:07,846  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 16.0 in stage 28.0 (TID 641) in 15 ms on localhost (17/199)
2017-07-01 18:27:07,846  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 18.0 in stage 28.0 (TID 643)
2017-07-01 18:27:07,852  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:07,852  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:07,854  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 17.0 in stage 28.0 (TID 642). 1609 bytes result sent to driver
2017-07-01 18:27:07,858  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 19.0 in stage 28.0 (TID 644, localhost, partition 20,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:07,860  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 17.0 in stage 28.0 (TID 642) in 19 ms on localhost (18/199)
2017-07-01 18:27:07,861  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 19.0 in stage 28.0 (TID 644)
2017-07-01 18:27:07,870  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:07,870  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:07,872  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:27:07,872  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:27:07,876  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 18.0 in stage 28.0 (TID 643). 1609 bytes result sent to driver
2017-07-01 18:27:07,877  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 19.0 in stage 28.0 (TID 644). 1609 bytes result sent to driver
2017-07-01 18:27:07,878  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 20.0 in stage 28.0 (TID 645, localhost, partition 21,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:07,878  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 18.0 in stage 28.0 (TID 643) in 32 ms on localhost (19/199)
2017-07-01 18:27:07,879  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 20.0 in stage 28.0 (TID 645)
2017-07-01 18:27:07,882  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 21.0 in stage 28.0 (TID 646, localhost, partition 22,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:07,882  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 19.0 in stage 28.0 (TID 644) in 24 ms on localhost (20/199)
2017-07-01 18:27:07,882  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 21.0 in stage 28.0 (TID 646)
2017-07-01 18:27:07,886  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:07,886  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:07,887  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 21.0 in stage 28.0 (TID 646). 1609 bytes result sent to driver
2017-07-01 18:27:07,888  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 22.0 in stage 28.0 (TID 647, localhost, partition 23,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:07,888  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Running task 22.0 in stage 28.0 (TID 647)
2017-07-01 18:27:07,888  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 21.0 in stage 28.0 (TID 646) in 7 ms on localhost (21/199)
2017-07-01 18:27:07,891  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:07,891  INFO [Executor task launch worker-7] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:07,892  INFO [Executor task launch worker-7] (org.apache.spark.executor.Executor) - Finished task 22.0 in stage 28.0 (TID 647). 1609 bytes result sent to driver
2017-07-01 18:27:07,893  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 23.0 in stage 28.0 (TID 648, localhost, partition 24,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:07,893  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 23.0 in stage 28.0 (TID 648)
2017-07-01 18:27:07,894  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 22.0 in stage 28.0 (TID 647) in 7 ms on localhost (22/199)
2017-07-01 18:27:07,899  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:07,900  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:07,902  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 23.0 in stage 28.0 (TID 648). 1609 bytes result sent to driver
2017-07-01 18:27:07,903  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 24.0 in stage 28.0 (TID 649, localhost, partition 25,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:07,904  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 23.0 in stage 28.0 (TID 648) in 11 ms on localhost (23/199)
2017-07-01 18:27:07,905  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 24.0 in stage 28.0 (TID 649)
2017-07-01 18:27:07,910  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:07,914  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:27:07,917  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:07,918  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 7 ms
2017-07-01 18:27:07,921  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 20.0 in stage 28.0 (TID 645). 1609 bytes result sent to driver
2017-07-01 18:27:07,923  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 25.0 in stage 28.0 (TID 650, localhost, partition 26,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:07,924  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 20.0 in stage 28.0 (TID 645) in 46 ms on localhost (24/199)
2017-07-01 18:27:07,925  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 25.0 in stage 28.0 (TID 650)
2017-07-01 18:27:07,935  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 24.0 in stage 28.0 (TID 649). 1609 bytes result sent to driver
2017-07-01 18:27:07,941  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 26.0 in stage 28.0 (TID 651, localhost, partition 27,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:07,942  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 24.0 in stage 28.0 (TID 649) in 39 ms on localhost (25/199)
2017-07-01 18:27:07,943  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 26.0 in stage 28.0 (TID 651)
2017-07-01 18:27:07,936  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:07,953  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 17 ms
2017-07-01 18:27:07,956  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 25.0 in stage 28.0 (TID 650). 1609 bytes result sent to driver
2017-07-01 18:27:07,968  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 27.0 in stage 28.0 (TID 652, localhost, partition 28,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:07,968  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 25.0 in stage 28.0 (TID 650) in 45 ms on localhost (26/199)
2017-07-01 18:27:07,969  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:07,969  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:07,970  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 26.0 in stage 28.0 (TID 651). 1609 bytes result sent to driver
2017-07-01 18:27:07,974  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 27.0 in stage 28.0 (TID 652)
2017-07-01 18:27:07,977  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 28.0 in stage 28.0 (TID 653, localhost, partition 29,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:07,980  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 26.0 in stage 28.0 (TID 651) in 39 ms on localhost (27/199)
2017-07-01 18:27:07,991  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 28.0 in stage 28.0 (TID 653)
2017-07-01 18:27:08,004  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,004  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:08,016  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 27.0 in stage 28.0 (TID 652). 1609 bytes result sent to driver
2017-07-01 18:27:08,017  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 29.0 in stage 28.0 (TID 654, localhost, partition 30,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,019  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 27.0 in stage 28.0 (TID 652) in 52 ms on localhost (28/199)
2017-07-01 18:27:08,026  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,026  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:08,026  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 29.0 in stage 28.0 (TID 654)
2017-07-01 18:27:08,044  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,044  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:08,048  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 28.0 in stage 28.0 (TID 653). 1609 bytes result sent to driver
2017-07-01 18:27:08,053  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 30.0 in stage 28.0 (TID 655, localhost, partition 31,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,053  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 30.0 in stage 28.0 (TID 655)
2017-07-01 18:27:08,054  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 28.0 in stage 28.0 (TID 653) in 77 ms on localhost (29/199)
2017-07-01 18:27:08,062  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 29.0 in stage 28.0 (TID 654). 1609 bytes result sent to driver
2017-07-01 18:27:08,063  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 31.0 in stage 28.0 (TID 656, localhost, partition 32,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,063  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 29.0 in stage 28.0 (TID 654) in 46 ms on localhost (30/199)
2017-07-01 18:27:08,066  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 31.0 in stage 28.0 (TID 656)
2017-07-01 18:27:08,070  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,070  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:27:08,071  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 30.0 in stage 28.0 (TID 655). 1609 bytes result sent to driver
2017-07-01 18:27:08,072  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 32.0 in stage 28.0 (TID 657, localhost, partition 33,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,072  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 30.0 in stage 28.0 (TID 655) in 19 ms on localhost (31/199)
2017-07-01 18:27:08,080  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 32.0 in stage 28.0 (TID 657)
2017-07-01 18:27:08,087  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,087  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:08,093  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 31.0 in stage 28.0 (TID 656). 1609 bytes result sent to driver
2017-07-01 18:27:08,094  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 33.0 in stage 28.0 (TID 658, localhost, partition 34,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,097  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 31.0 in stage 28.0 (TID 656) in 34 ms on localhost (32/199)
2017-07-01 18:27:08,106  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 33.0 in stage 28.0 (TID 658)
2017-07-01 18:27:08,108  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,110  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:27:08,121  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,121  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:08,136  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 33.0 in stage 28.0 (TID 658). 1609 bytes result sent to driver
2017-07-01 18:27:08,137  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 34.0 in stage 28.0 (TID 659, localhost, partition 35,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,138  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 33.0 in stage 28.0 (TID 658) in 44 ms on localhost (33/199)
2017-07-01 18:27:08,151  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 34.0 in stage 28.0 (TID 659)
2017-07-01 18:27:08,157  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 32.0 in stage 28.0 (TID 657). 1963 bytes result sent to driver
2017-07-01 18:27:08,159  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 35.0 in stage 28.0 (TID 660, localhost, partition 36,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,160  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 32.0 in stage 28.0 (TID 657) in 88 ms on localhost (34/199)
2017-07-01 18:27:08,163  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,169  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 6 ms
2017-07-01 18:27:08,164  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 35.0 in stage 28.0 (TID 660)
2017-07-01 18:27:08,180  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,182  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:27:08,184  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 35.0 in stage 28.0 (TID 660). 1609 bytes result sent to driver
2017-07-01 18:27:08,186  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 36.0 in stage 28.0 (TID 661, localhost, partition 37,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,187  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 35.0 in stage 28.0 (TID 660) in 28 ms on localhost (35/199)
2017-07-01 18:27:08,189  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 36.0 in stage 28.0 (TID 661)
2017-07-01 18:27:08,196  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 34.0 in stage 28.0 (TID 659). 1609 bytes result sent to driver
2017-07-01 18:27:08,202  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 37.0 in stage 28.0 (TID 662, localhost, partition 38,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,203  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 34.0 in stage 28.0 (TID 659) in 66 ms on localhost (36/199)
2017-07-01 18:27:08,208  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 37.0 in stage 28.0 (TID 662)
2017-07-01 18:27:08,212  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,218  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 6 ms
2017-07-01 18:27:08,220  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 36.0 in stage 28.0 (TID 661). 1609 bytes result sent to driver
2017-07-01 18:27:08,227  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 38.0 in stage 28.0 (TID 663, localhost, partition 39,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,227  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 36.0 in stage 28.0 (TID 661) in 41 ms on localhost (37/199)
2017-07-01 18:27:08,229  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 38.0 in stage 28.0 (TID 663)
2017-07-01 18:27:08,226  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,242  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 16 ms
2017-07-01 18:27:08,244  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 37.0 in stage 28.0 (TID 662). 1609 bytes result sent to driver
2017-07-01 18:27:08,252  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,258  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 6 ms
2017-07-01 18:27:08,258  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 39.0 in stage 28.0 (TID 664, localhost, partition 40,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,259  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 37.0 in stage 28.0 (TID 662) in 57 ms on localhost (38/199)
2017-07-01 18:27:08,260  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 39.0 in stage 28.0 (TID 664)
2017-07-01 18:27:08,262  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 38.0 in stage 28.0 (TID 663). 1609 bytes result sent to driver
2017-07-01 18:27:08,267  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 40.0 in stage 28.0 (TID 665, localhost, partition 41,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,267  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 38.0 in stage 28.0 (TID 663) in 40 ms on localhost (39/199)
2017-07-01 18:27:08,268  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 40.0 in stage 28.0 (TID 665)
2017-07-01 18:27:08,276  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,277  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:08,276  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,279  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:27:08,279  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 40.0 in stage 28.0 (TID 665). 1609 bytes result sent to driver
2017-07-01 18:27:08,280  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 41.0 in stage 28.0 (TID 666, localhost, partition 42,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,280  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 40.0 in stage 28.0 (TID 665) in 14 ms on localhost (40/199)
2017-07-01 18:27:08,281  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 41.0 in stage 28.0 (TID 666)
2017-07-01 18:27:08,281  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 39.0 in stage 28.0 (TID 664). 1609 bytes result sent to driver
2017-07-01 18:27:08,302  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 42.0 in stage 28.0 (TID 667, localhost, partition 43,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,303  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 42.0 in stage 28.0 (TID 667)
2017-07-01 18:27:08,307  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 39.0 in stage 28.0 (TID 664) in 49 ms on localhost (41/199)
2017-07-01 18:27:08,310  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,311  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:08,316  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 42.0 in stage 28.0 (TID 667). 1609 bytes result sent to driver
2017-07-01 18:27:08,319  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,325  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 43.0 in stage 28.0 (TID 668, localhost, partition 44,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,326  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 43.0 in stage 28.0 (TID 668)
2017-07-01 18:27:08,326  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 8 ms
2017-07-01 18:27:08,328  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 42.0 in stage 28.0 (TID 667) in 26 ms on localhost (42/199)
2017-07-01 18:27:08,342  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 41.0 in stage 28.0 (TID 666). 1609 bytes result sent to driver
2017-07-01 18:27:08,342  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 44.0 in stage 28.0 (TID 669, localhost, partition 45,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,343  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 44.0 in stage 28.0 (TID 669)
2017-07-01 18:27:08,346  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 41.0 in stage 28.0 (TID 666) in 66 ms on localhost (43/199)
2017-07-01 18:27:08,350  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,351  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:08,355  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 44.0 in stage 28.0 (TID 669). 1609 bytes result sent to driver
2017-07-01 18:27:08,356  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 45.0 in stage 28.0 (TID 670, localhost, partition 46,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,357  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 44.0 in stage 28.0 (TID 669) in 15 ms on localhost (44/199)
2017-07-01 18:27:08,358  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 45.0 in stage 28.0 (TID 670)
2017-07-01 18:27:08,360  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,360  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:08,361  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 43.0 in stage 28.0 (TID 668). 1609 bytes result sent to driver
2017-07-01 18:27:08,367  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,367  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:27:08,369  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 45.0 in stage 28.0 (TID 670). 1609 bytes result sent to driver
2017-07-01 18:27:08,374  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 46.0 in stage 28.0 (TID 671, localhost, partition 47,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,375  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 43.0 in stage 28.0 (TID 668) in 50 ms on localhost (45/199)
2017-07-01 18:27:08,378  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 46.0 in stage 28.0 (TID 671)
2017-07-01 18:27:08,379  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 47.0 in stage 28.0 (TID 672, localhost, partition 48,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,380  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 45.0 in stage 28.0 (TID 670) in 25 ms on localhost (46/199)
2017-07-01 18:27:08,380  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 47.0 in stage 28.0 (TID 672)
2017-07-01 18:27:08,386  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,387  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:08,388  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 47.0 in stage 28.0 (TID 672). 1609 bytes result sent to driver
2017-07-01 18:27:08,389  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 48.0 in stage 28.0 (TID 673, localhost, partition 49,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,389  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 48.0 in stage 28.0 (TID 673)
2017-07-01 18:27:08,390  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 47.0 in stage 28.0 (TID 672) in 11 ms on localhost (47/199)
2017-07-01 18:27:08,398  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,400  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:27:08,401  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 46.0 in stage 28.0 (TID 671). 1609 bytes result sent to driver
2017-07-01 18:27:08,398  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,401  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:27:08,402  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 48.0 in stage 28.0 (TID 673). 1609 bytes result sent to driver
2017-07-01 18:27:08,403  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 49.0 in stage 28.0 (TID 674, localhost, partition 50,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,403  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 49.0 in stage 28.0 (TID 674)
2017-07-01 18:27:08,405  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 46.0 in stage 28.0 (TID 671) in 30 ms on localhost (48/199)
2017-07-01 18:27:08,405  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 50.0 in stage 28.0 (TID 675, localhost, partition 51,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,406  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 48.0 in stage 28.0 (TID 673) in 18 ms on localhost (49/199)
2017-07-01 18:27:08,406  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 50.0 in stage 28.0 (TID 675)
2017-07-01 18:27:08,420  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,420  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:08,422  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,423  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:08,422  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 49.0 in stage 28.0 (TID 674). 1609 bytes result sent to driver
2017-07-01 18:27:08,423  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 51.0 in stage 28.0 (TID 676, localhost, partition 52,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,424  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 51.0 in stage 28.0 (TID 676)
2017-07-01 18:27:08,426  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 49.0 in stage 28.0 (TID 674) in 24 ms on localhost (50/199)
2017-07-01 18:27:08,434  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,434  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:08,439  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 50.0 in stage 28.0 (TID 675). 1609 bytes result sent to driver
2017-07-01 18:27:08,439  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 51.0 in stage 28.0 (TID 676). 1609 bytes result sent to driver
2017-07-01 18:27:08,440  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 52.0 in stage 28.0 (TID 677, localhost, partition 53,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,440  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 52.0 in stage 28.0 (TID 677)
2017-07-01 18:27:08,440  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 50.0 in stage 28.0 (TID 675) in 35 ms on localhost (51/199)
2017-07-01 18:27:08,445  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 53.0 in stage 28.0 (TID 678, localhost, partition 54,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,446  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 51.0 in stage 28.0 (TID 676) in 23 ms on localhost (52/199)
2017-07-01 18:27:08,445  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,446  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:08,453  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 52.0 in stage 28.0 (TID 677). 1609 bytes result sent to driver
2017-07-01 18:27:08,455  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 54.0 in stage 28.0 (TID 679, localhost, partition 55,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,455  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 52.0 in stage 28.0 (TID 677) in 16 ms on localhost (53/199)
2017-07-01 18:27:08,457  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 53.0 in stage 28.0 (TID 678)
2017-07-01 18:27:08,461  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 54.0 in stage 28.0 (TID 679)
2017-07-01 18:27:08,471  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,475  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:27:08,476  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 54.0 in stage 28.0 (TID 679). 1609 bytes result sent to driver
2017-07-01 18:27:08,472  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,477  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 5 ms
2017-07-01 18:27:08,483  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 53.0 in stage 28.0 (TID 678). 1609 bytes result sent to driver
2017-07-01 18:27:08,485  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 55.0 in stage 28.0 (TID 680, localhost, partition 56,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,486  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 56.0 in stage 28.0 (TID 681, localhost, partition 57,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,486  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 54.0 in stage 28.0 (TID 679) in 32 ms on localhost (54/199)
2017-07-01 18:27:08,486  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 56.0 in stage 28.0 (TID 681)
2017-07-01 18:27:08,486  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 53.0 in stage 28.0 (TID 678) in 41 ms on localhost (55/199)
2017-07-01 18:27:08,489  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 55.0 in stage 28.0 (TID 680)
2017-07-01 18:27:08,509  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,514  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 6 ms
2017-07-01 18:27:08,519  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 55.0 in stage 28.0 (TID 680). 1609 bytes result sent to driver
2017-07-01 18:27:08,526  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 57.0 in stage 28.0 (TID 682, localhost, partition 58,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,526  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 55.0 in stage 28.0 (TID 680) in 41 ms on localhost (56/199)
2017-07-01 18:27:08,527  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 57.0 in stage 28.0 (TID 682)
2017-07-01 18:27:08,519  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,528  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 9 ms
2017-07-01 18:27:08,530  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 56.0 in stage 28.0 (TID 681). 1609 bytes result sent to driver
2017-07-01 18:27:08,542  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 58.0 in stage 28.0 (TID 683, localhost, partition 59,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,542  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 56.0 in stage 28.0 (TID 681) in 57 ms on localhost (57/199)
2017-07-01 18:27:08,543  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 58.0 in stage 28.0 (TID 683)
2017-07-01 18:27:08,552  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,553  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:08,555  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 58.0 in stage 28.0 (TID 683). 1609 bytes result sent to driver
2017-07-01 18:27:08,552  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,555  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:27:08,560  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 59.0 in stage 28.0 (TID 684, localhost, partition 60,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,560  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 58.0 in stage 28.0 (TID 683) in 19 ms on localhost (58/199)
2017-07-01 18:27:08,562  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 59.0 in stage 28.0 (TID 684)
2017-07-01 18:27:08,563  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 57.0 in stage 28.0 (TID 682). 1609 bytes result sent to driver
2017-07-01 18:27:08,574  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 60.0 in stage 28.0 (TID 685, localhost, partition 61,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,570  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,576  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 8 ms
2017-07-01 18:27:08,578  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 59.0 in stage 28.0 (TID 684). 1609 bytes result sent to driver
2017-07-01 18:27:08,578  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 61.0 in stage 28.0 (TID 686, localhost, partition 62,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,579  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 60.0 in stage 28.0 (TID 685)
2017-07-01 18:27:08,579  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 59.0 in stage 28.0 (TID 684) in 19 ms on localhost (59/199)
2017-07-01 18:27:08,579  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 57.0 in stage 28.0 (TID 682) in 54 ms on localhost (60/199)
2017-07-01 18:27:08,582  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 61.0 in stage 28.0 (TID 686)
2017-07-01 18:27:08,596  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,602  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 6 ms
2017-07-01 18:27:08,598  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,606  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 8 ms
2017-07-01 18:27:08,610  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 61.0 in stage 28.0 (TID 686). 1609 bytes result sent to driver
2017-07-01 18:27:08,612  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 60.0 in stage 28.0 (TID 685). 1609 bytes result sent to driver
2017-07-01 18:27:08,616  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 62.0 in stage 28.0 (TID 687, localhost, partition 63,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,617  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 61.0 in stage 28.0 (TID 686) in 39 ms on localhost (61/199)
2017-07-01 18:27:08,618  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 62.0 in stage 28.0 (TID 687)
2017-07-01 18:27:08,619  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 63.0 in stage 28.0 (TID 688, localhost, partition 64,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,619  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 63.0 in stage 28.0 (TID 688)
2017-07-01 18:27:08,622  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 60.0 in stage 28.0 (TID 685) in 48 ms on localhost (62/199)
2017-07-01 18:27:08,624  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,625  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:08,626  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 62.0 in stage 28.0 (TID 687). 1609 bytes result sent to driver
2017-07-01 18:27:08,627  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 64.0 in stage 28.0 (TID 689, localhost, partition 65,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,627  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 64.0 in stage 28.0 (TID 689)
2017-07-01 18:27:08,629  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 62.0 in stage 28.0 (TID 687) in 13 ms on localhost (63/199)
2017-07-01 18:27:08,637  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,637  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:08,640  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,641  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:08,642  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 63.0 in stage 28.0 (TID 688). 1609 bytes result sent to driver
2017-07-01 18:27:08,643  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 65.0 in stage 28.0 (TID 690, localhost, partition 66,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,644  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 65.0 in stage 28.0 (TID 690)
2017-07-01 18:27:08,645  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 63.0 in stage 28.0 (TID 688) in 26 ms on localhost (64/199)
2017-07-01 18:27:08,648  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,649  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:08,650  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 65.0 in stage 28.0 (TID 690). 1609 bytes result sent to driver
2017-07-01 18:27:08,650  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 66.0 in stage 28.0 (TID 691, localhost, partition 67,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,651  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 65.0 in stage 28.0 (TID 690) in 8 ms on localhost (65/199)
2017-07-01 18:27:08,651  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 66.0 in stage 28.0 (TID 691)
2017-07-01 18:27:08,666  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,666  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:08,667  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 66.0 in stage 28.0 (TID 691). 1609 bytes result sent to driver
2017-07-01 18:27:08,668  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 67.0 in stage 28.0 (TID 692, localhost, partition 68,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,643  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 64.0 in stage 28.0 (TID 689). 1609 bytes result sent to driver
2017-07-01 18:27:08,669  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 68.0 in stage 28.0 (TID 693, localhost, partition 69,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,669  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 67.0 in stage 28.0 (TID 692)
2017-07-01 18:27:08,669  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 68.0 in stage 28.0 (TID 693)
2017-07-01 18:27:08,674  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 64.0 in stage 28.0 (TID 689) in 48 ms on localhost (66/199)
2017-07-01 18:27:08,677  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 66.0 in stage 28.0 (TID 691) in 27 ms on localhost (67/199)
2017-07-01 18:27:08,678  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,678  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:08,679  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 68.0 in stage 28.0 (TID 693). 1609 bytes result sent to driver
2017-07-01 18:27:08,683  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 69.0 in stage 28.0 (TID 694, localhost, partition 70,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,683  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 69.0 in stage 28.0 (TID 694)
2017-07-01 18:27:08,687  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,687  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:08,691  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 69.0 in stage 28.0 (TID 694). 1609 bytes result sent to driver
2017-07-01 18:27:08,692  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 70.0 in stage 28.0 (TID 695, localhost, partition 71,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,693  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 69.0 in stage 28.0 (TID 694) in 11 ms on localhost (68/199)
2017-07-01 18:27:08,693  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 68.0 in stage 28.0 (TID 693) in 25 ms on localhost (69/199)
2017-07-01 18:27:08,703  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 70.0 in stage 28.0 (TID 695)
2017-07-01 18:27:08,681  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,709  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 28 ms
2017-07-01 18:27:08,712  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,716  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:27:08,717  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 70.0 in stage 28.0 (TID 695). 1609 bytes result sent to driver
2017-07-01 18:27:08,723  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 71.0 in stage 28.0 (TID 696, localhost, partition 72,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,724  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 71.0 in stage 28.0 (TID 696)
2017-07-01 18:27:08,726  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 70.0 in stage 28.0 (TID 695) in 34 ms on localhost (70/199)
2017-07-01 18:27:08,722  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 67.0 in stage 28.0 (TID 692). 1609 bytes result sent to driver
2017-07-01 18:27:08,735  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 72.0 in stage 28.0 (TID 697, localhost, partition 73,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,736  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 67.0 in stage 28.0 (TID 692) in 68 ms on localhost (71/199)
2017-07-01 18:27:08,740  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 72.0 in stage 28.0 (TID 697)
2017-07-01 18:27:08,748  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,754  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 6 ms
2017-07-01 18:27:08,755  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 71.0 in stage 28.0 (TID 696). 1609 bytes result sent to driver
2017-07-01 18:27:08,761  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 73.0 in stage 28.0 (TID 698, localhost, partition 74,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,763  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 71.0 in stage 28.0 (TID 696) in 40 ms on localhost (72/199)
2017-07-01 18:27:08,765  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 73.0 in stage 28.0 (TID 698)
2017-07-01 18:27:08,772  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,772  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:08,783  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,783  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:08,784  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 73.0 in stage 28.0 (TID 698). 1609 bytes result sent to driver
2017-07-01 18:27:08,790  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 72.0 in stage 28.0 (TID 697). 1609 bytes result sent to driver
2017-07-01 18:27:08,791  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 74.0 in stage 28.0 (TID 699, localhost, partition 75,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,792  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 73.0 in stage 28.0 (TID 698) in 31 ms on localhost (73/199)
2017-07-01 18:27:08,795  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 74.0 in stage 28.0 (TID 699)
2017-07-01 18:27:08,797  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 75.0 in stage 28.0 (TID 700, localhost, partition 76,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,798  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 75.0 in stage 28.0 (TID 700)
2017-07-01 18:27:08,800  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 72.0 in stage 28.0 (TID 697) in 64 ms on localhost (74/199)
2017-07-01 18:27:08,802  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,803  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:08,806  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 75.0 in stage 28.0 (TID 700). 1609 bytes result sent to driver
2017-07-01 18:27:08,807  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 76.0 in stage 28.0 (TID 701, localhost, partition 77,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,808  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 75.0 in stage 28.0 (TID 700) in 11 ms on localhost (75/199)
2017-07-01 18:27:08,808  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 76.0 in stage 28.0 (TID 701)
2017-07-01 18:27:08,813  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,813  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:27:08,814  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 74.0 in stage 28.0 (TID 699). 1609 bytes result sent to driver
2017-07-01 18:27:08,815  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,815  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:08,816  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 77.0 in stage 28.0 (TID 702, localhost, partition 78,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,816  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 74.0 in stage 28.0 (TID 699) in 25 ms on localhost (76/199)
2017-07-01 18:27:08,821  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 77.0 in stage 28.0 (TID 702)
2017-07-01 18:27:08,827  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 76.0 in stage 28.0 (TID 701). 1609 bytes result sent to driver
2017-07-01 18:27:08,830  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 78.0 in stage 28.0 (TID 703, localhost, partition 79,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,830  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 76.0 in stage 28.0 (TID 701) in 23 ms on localhost (77/199)
2017-07-01 18:27:08,830  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 78.0 in stage 28.0 (TID 703)
2017-07-01 18:27:08,847  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,857  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 10 ms
2017-07-01 18:27:08,854  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,858  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:27:08,859  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 78.0 in stage 28.0 (TID 703). 1609 bytes result sent to driver
2017-07-01 18:27:08,860  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 79.0 in stage 28.0 (TID 704, localhost, partition 80,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,860  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 79.0 in stage 28.0 (TID 704)
2017-07-01 18:27:08,862  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 78.0 in stage 28.0 (TID 703) in 33 ms on localhost (78/199)
2017-07-01 18:27:08,864  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,865  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:08,866  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 79.0 in stage 28.0 (TID 704). 1609 bytes result sent to driver
2017-07-01 18:27:08,866  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 80.0 in stage 28.0 (TID 705, localhost, partition 81,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,867  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 80.0 in stage 28.0 (TID 705)
2017-07-01 18:27:08,870  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,872  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:27:08,873  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 79.0 in stage 28.0 (TID 704) in 10 ms on localhost (79/199)
2017-07-01 18:27:08,874  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 77.0 in stage 28.0 (TID 702). 1609 bytes result sent to driver
2017-07-01 18:27:08,883  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 81.0 in stage 28.0 (TID 706, localhost, partition 82,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,885  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 81.0 in stage 28.0 (TID 706)
2017-07-01 18:27:08,887  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 77.0 in stage 28.0 (TID 702) in 72 ms on localhost (80/199)
2017-07-01 18:27:08,888  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 80.0 in stage 28.0 (TID 705). 1609 bytes result sent to driver
2017-07-01 18:27:08,889  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 82.0 in stage 28.0 (TID 707, localhost, partition 83,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,890  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 82.0 in stage 28.0 (TID 707)
2017-07-01 18:27:08,896  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 80.0 in stage 28.0 (TID 705) in 30 ms on localhost (81/199)
2017-07-01 18:27:08,920  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,920  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:08,921  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 82.0 in stage 28.0 (TID 707). 1609 bytes result sent to driver
2017-07-01 18:27:08,922  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 83.0 in stage 28.0 (TID 708, localhost, partition 84,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,923  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 82.0 in stage 28.0 (TID 707) in 34 ms on localhost (82/199)
2017-07-01 18:27:08,925  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 83.0 in stage 28.0 (TID 708)
2017-07-01 18:27:08,932  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,936  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:27:08,939  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 81.0 in stage 28.0 (TID 706). 1609 bytes result sent to driver
2017-07-01 18:27:08,940  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 84.0 in stage 28.0 (TID 709, localhost, partition 85,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,940  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 81.0 in stage 28.0 (TID 706) in 57 ms on localhost (83/199)
2017-07-01 18:27:08,941  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 84.0 in stage 28.0 (TID 709)
2017-07-01 18:27:08,945  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,945  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:08,947  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,948  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:08,950  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 84.0 in stage 28.0 (TID 709). 1609 bytes result sent to driver
2017-07-01 18:27:08,951  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 85.0 in stage 28.0 (TID 710, localhost, partition 86,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,951  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 84.0 in stage 28.0 (TID 709) in 12 ms on localhost (84/199)
2017-07-01 18:27:08,952  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 85.0 in stage 28.0 (TID 710)
2017-07-01 18:27:08,957  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 83.0 in stage 28.0 (TID 708). 1609 bytes result sent to driver
2017-07-01 18:27:08,958  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 86.0 in stage 28.0 (TID 711, localhost, partition 87,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,959  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 83.0 in stage 28.0 (TID 708) in 37 ms on localhost (85/199)
2017-07-01 18:27:08,960  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,961  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:08,962  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 85.0 in stage 28.0 (TID 710). 1609 bytes result sent to driver
2017-07-01 18:27:08,962  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 87.0 in stage 28.0 (TID 712, localhost, partition 88,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,963  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 85.0 in stage 28.0 (TID 710) in 12 ms on localhost (86/199)
2017-07-01 18:27:08,963  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 86.0 in stage 28.0 (TID 711)
2017-07-01 18:27:08,964  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 87.0 in stage 28.0 (TID 712)
2017-07-01 18:27:08,970  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,972  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:27:08,973  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 87.0 in stage 28.0 (TID 712). 1609 bytes result sent to driver
2017-07-01 18:27:08,975  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,975  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:08,976  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 88.0 in stage 28.0 (TID 713, localhost, partition 89,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,976  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 87.0 in stage 28.0 (TID 712) in 14 ms on localhost (87/199)
2017-07-01 18:27:08,977  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 88.0 in stage 28.0 (TID 713)
2017-07-01 18:27:08,980  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,980  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:08,981  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 88.0 in stage 28.0 (TID 713). 1609 bytes result sent to driver
2017-07-01 18:27:08,982  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 89.0 in stage 28.0 (TID 714, localhost, partition 90,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,982  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 89.0 in stage 28.0 (TID 714)
2017-07-01 18:27:08,982  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 88.0 in stage 28.0 (TID 713) in 6 ms on localhost (88/199)
2017-07-01 18:27:08,985  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 86.0 in stage 28.0 (TID 711). 1609 bytes result sent to driver
2017-07-01 18:27:08,986  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 90.0 in stage 28.0 (TID 715, localhost, partition 91,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,986  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 86.0 in stage 28.0 (TID 711) in 28 ms on localhost (89/199)
2017-07-01 18:27:08,986  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 90.0 in stage 28.0 (TID 715)
2017-07-01 18:27:08,988  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,988  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:08,990  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 89.0 in stage 28.0 (TID 714). 1609 bytes result sent to driver
2017-07-01 18:27:08,992  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,992  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:08,992  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 91.0 in stage 28.0 (TID 716, localhost, partition 92,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:08,993  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 89.0 in stage 28.0 (TID 714) in 11 ms on localhost (90/199)
2017-07-01 18:27:08,993  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 91.0 in stage 28.0 (TID 716)
2017-07-01 18:27:08,997  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:08,998  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:08,998  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 90.0 in stage 28.0 (TID 715). 1609 bytes result sent to driver
2017-07-01 18:27:08,999  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 91.0 in stage 28.0 (TID 716). 1609 bytes result sent to driver
2017-07-01 18:27:09,000  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 92.0 in stage 28.0 (TID 717, localhost, partition 93,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,000  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 90.0 in stage 28.0 (TID 715) in 15 ms on localhost (91/199)
2017-07-01 18:27:09,000  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 92.0 in stage 28.0 (TID 717)
2017-07-01 18:27:09,006  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 93.0 in stage 28.0 (TID 718, localhost, partition 94,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,006  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 93.0 in stage 28.0 (TID 718)
2017-07-01 18:27:09,010  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 91.0 in stage 28.0 (TID 716) in 17 ms on localhost (92/199)
2017-07-01 18:27:09,026  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,026  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:09,026  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,026  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:09,031  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 92.0 in stage 28.0 (TID 717). 1609 bytes result sent to driver
2017-07-01 18:27:09,031  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 94.0 in stage 28.0 (TID 719, localhost, partition 95,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,032  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 92.0 in stage 28.0 (TID 717) in 33 ms on localhost (93/199)
2017-07-01 18:27:09,033  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 94.0 in stage 28.0 (TID 719)
2017-07-01 18:27:09,036  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,036  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:09,037  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 93.0 in stage 28.0 (TID 718). 1609 bytes result sent to driver
2017-07-01 18:27:09,038  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 94.0 in stage 28.0 (TID 719). 1609 bytes result sent to driver
2017-07-01 18:27:09,038  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 95.0 in stage 28.0 (TID 720, localhost, partition 96,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,038  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 93.0 in stage 28.0 (TID 718) in 32 ms on localhost (94/199)
2017-07-01 18:27:09,039  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 95.0 in stage 28.0 (TID 720)
2017-07-01 18:27:09,041  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 96.0 in stage 28.0 (TID 721, localhost, partition 97,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,041  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 94.0 in stage 28.0 (TID 719) in 10 ms on localhost (95/199)
2017-07-01 18:27:09,042  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 96.0 in stage 28.0 (TID 721)
2017-07-01 18:27:09,045  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,045  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:09,050  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,050  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:09,059  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 95.0 in stage 28.0 (TID 720). 1609 bytes result sent to driver
2017-07-01 18:27:09,062  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 97.0 in stage 28.0 (TID 722, localhost, partition 98,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,062  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 95.0 in stage 28.0 (TID 720) in 24 ms on localhost (96/199)
2017-07-01 18:27:09,065  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 97.0 in stage 28.0 (TID 722)
2017-07-01 18:27:09,068  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,069  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:09,078  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 97.0 in stage 28.0 (TID 722). 1609 bytes result sent to driver
2017-07-01 18:27:09,078  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 96.0 in stage 28.0 (TID 721). 1609 bytes result sent to driver
2017-07-01 18:27:09,078  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 98.0 in stage 28.0 (TID 723, localhost, partition 99,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,079  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 97.0 in stage 28.0 (TID 722) in 17 ms on localhost (97/199)
2017-07-01 18:27:09,079  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 98.0 in stage 28.0 (TID 723)
2017-07-01 18:27:09,081  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 99.0 in stage 28.0 (TID 724, localhost, partition 100,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,082  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 96.0 in stage 28.0 (TID 721) in 42 ms on localhost (98/199)
2017-07-01 18:27:09,082  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 99.0 in stage 28.0 (TID 724)
2017-07-01 18:27:09,086  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,086  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:09,087  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,087  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:09,088  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 98.0 in stage 28.0 (TID 723). 1609 bytes result sent to driver
2017-07-01 18:27:09,088  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 100.0 in stage 28.0 (TID 725, localhost, partition 101,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,088  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 98.0 in stage 28.0 (TID 723) in 10 ms on localhost (99/199)
2017-07-01 18:27:09,089  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 100.0 in stage 28.0 (TID 725)
2017-07-01 18:27:09,092  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,092  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:09,093  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 100.0 in stage 28.0 (TID 725). 1609 bytes result sent to driver
2017-07-01 18:27:09,093  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 99.0 in stage 28.0 (TID 724). 1609 bytes result sent to driver
2017-07-01 18:27:09,094  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 101.0 in stage 28.0 (TID 726, localhost, partition 102,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,094  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 101.0 in stage 28.0 (TID 726)
2017-07-01 18:27:09,094  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 100.0 in stage 28.0 (TID 725) in 6 ms on localhost (100/199)
2017-07-01 18:27:09,098  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 102.0 in stage 28.0 (TID 727, localhost, partition 103,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,098  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 99.0 in stage 28.0 (TID 724) in 17 ms on localhost (101/199)
2017-07-01 18:27:09,098  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 102.0 in stage 28.0 (TID 727)
2017-07-01 18:27:09,112  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,112  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:09,117  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,118  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:09,118  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 101.0 in stage 28.0 (TID 726). 1609 bytes result sent to driver
2017-07-01 18:27:09,119  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 103.0 in stage 28.0 (TID 728, localhost, partition 104,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,119  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 101.0 in stage 28.0 (TID 726) in 25 ms on localhost (102/199)
2017-07-01 18:27:09,122  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 103.0 in stage 28.0 (TID 728)
2017-07-01 18:27:09,127  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,129  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:27:09,131  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 103.0 in stage 28.0 (TID 728). 1609 bytes result sent to driver
2017-07-01 18:27:09,128  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 102.0 in stage 28.0 (TID 727). 1609 bytes result sent to driver
2017-07-01 18:27:09,132  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 104.0 in stage 28.0 (TID 729, localhost, partition 105,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,133  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 103.0 in stage 28.0 (TID 728) in 14 ms on localhost (103/199)
2017-07-01 18:27:09,133  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 104.0 in stage 28.0 (TID 729)
2017-07-01 18:27:09,139  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,140  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:09,140  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 105.0 in stage 28.0 (TID 730, localhost, partition 106,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,141  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 105.0 in stage 28.0 (TID 730)
2017-07-01 18:27:09,141  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 102.0 in stage 28.0 (TID 727) in 44 ms on localhost (104/199)
2017-07-01 18:27:09,147  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,148  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:09,150  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 104.0 in stage 28.0 (TID 729). 1609 bytes result sent to driver
2017-07-01 18:27:09,151  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 106.0 in stage 28.0 (TID 731, localhost, partition 107,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,151  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 104.0 in stage 28.0 (TID 729) in 19 ms on localhost (105/199)
2017-07-01 18:27:09,152  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 106.0 in stage 28.0 (TID 731)
2017-07-01 18:27:09,158  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,159  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:09,162  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 106.0 in stage 28.0 (TID 731). 1609 bytes result sent to driver
2017-07-01 18:27:09,164  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 105.0 in stage 28.0 (TID 730). 1609 bytes result sent to driver
2017-07-01 18:27:09,164  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 107.0 in stage 28.0 (TID 732, localhost, partition 108,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,165  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 106.0 in stage 28.0 (TID 731) in 14 ms on localhost (106/199)
2017-07-01 18:27:09,166  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 107.0 in stage 28.0 (TID 732)
2017-07-01 18:27:09,169  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 108.0 in stage 28.0 (TID 733, localhost, partition 109,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,170  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 105.0 in stage 28.0 (TID 730) in 30 ms on localhost (107/199)
2017-07-01 18:27:09,170  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 108.0 in stage 28.0 (TID 733)
2017-07-01 18:27:09,179  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,179  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:09,180  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 107.0 in stage 28.0 (TID 732). 1609 bytes result sent to driver
2017-07-01 18:27:09,182  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,182  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:09,183  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 109.0 in stage 28.0 (TID 734, localhost, partition 110,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,183  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 109.0 in stage 28.0 (TID 734)
2017-07-01 18:27:09,183  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 107.0 in stage 28.0 (TID 732) in 19 ms on localhost (108/199)
2017-07-01 18:27:09,187  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,187  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:09,188  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 109.0 in stage 28.0 (TID 734). 1609 bytes result sent to driver
2017-07-01 18:27:09,188  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 108.0 in stage 28.0 (TID 733). 1609 bytes result sent to driver
2017-07-01 18:27:09,189  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 110.0 in stage 28.0 (TID 735, localhost, partition 111,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,189  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 109.0 in stage 28.0 (TID 734) in 6 ms on localhost (109/199)
2017-07-01 18:27:09,190  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 110.0 in stage 28.0 (TID 735)
2017-07-01 18:27:09,193  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 111.0 in stage 28.0 (TID 736, localhost, partition 112,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,194  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 108.0 in stage 28.0 (TID 733) in 25 ms on localhost (110/199)
2017-07-01 18:27:09,194  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 111.0 in stage 28.0 (TID 736)
2017-07-01 18:27:09,197  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,197  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:27:09,198  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 110.0 in stage 28.0 (TID 735). 1609 bytes result sent to driver
2017-07-01 18:27:09,198  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,199  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:09,199  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 112.0 in stage 28.0 (TID 737, localhost, partition 113,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,199  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 110.0 in stage 28.0 (TID 735) in 11 ms on localhost (111/199)
2017-07-01 18:27:09,200  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 112.0 in stage 28.0 (TID 737)
2017-07-01 18:27:09,203  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,204  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:09,215  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 112.0 in stage 28.0 (TID 737). 1609 bytes result sent to driver
2017-07-01 18:27:09,222  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 111.0 in stage 28.0 (TID 736). 1609 bytes result sent to driver
2017-07-01 18:27:09,222  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 113.0 in stage 28.0 (TID 738, localhost, partition 114,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,223  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 113.0 in stage 28.0 (TID 738)
2017-07-01 18:27:09,223  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 112.0 in stage 28.0 (TID 737) in 24 ms on localhost (112/199)
2017-07-01 18:27:09,230  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 114.0 in stage 28.0 (TID 739, localhost, partition 115,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,230  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 111.0 in stage 28.0 (TID 736) in 37 ms on localhost (113/199)
2017-07-01 18:27:09,231  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 114.0 in stage 28.0 (TID 739)
2017-07-01 18:27:09,235  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,235  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:09,241  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,241  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:09,246  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 113.0 in stage 28.0 (TID 738). 1609 bytes result sent to driver
2017-07-01 18:27:09,250  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 115.0 in stage 28.0 (TID 740, localhost, partition 116,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,250  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 113.0 in stage 28.0 (TID 738) in 28 ms on localhost (114/199)
2017-07-01 18:27:09,251  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 115.0 in stage 28.0 (TID 740)
2017-07-01 18:27:09,254  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,254  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:09,255  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 115.0 in stage 28.0 (TID 740). 1609 bytes result sent to driver
2017-07-01 18:27:09,256  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 116.0 in stage 28.0 (TID 741, localhost, partition 117,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,256  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 115.0 in stage 28.0 (TID 740) in 7 ms on localhost (115/199)
2017-07-01 18:27:09,257  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 116.0 in stage 28.0 (TID 741)
2017-07-01 18:27:09,257  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 114.0 in stage 28.0 (TID 739). 1609 bytes result sent to driver
2017-07-01 18:27:09,261  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 117.0 in stage 28.0 (TID 742, localhost, partition 118,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,261  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 114.0 in stage 28.0 (TID 739) in 32 ms on localhost (116/199)
2017-07-01 18:27:09,260  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,264  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:27:09,261  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 117.0 in stage 28.0 (TID 742)
2017-07-01 18:27:09,265  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 116.0 in stage 28.0 (TID 741). 1609 bytes result sent to driver
2017-07-01 18:27:09,265  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 118.0 in stage 28.0 (TID 743, localhost, partition 119,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,265  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 116.0 in stage 28.0 (TID 741) in 9 ms on localhost (117/199)
2017-07-01 18:27:09,266  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 118.0 in stage 28.0 (TID 743)
2017-07-01 18:27:09,270  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,270  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:09,271  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,271  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:09,272  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 117.0 in stage 28.0 (TID 742). 1609 bytes result sent to driver
2017-07-01 18:27:09,272  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 119.0 in stage 28.0 (TID 744, localhost, partition 120,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,272  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 117.0 in stage 28.0 (TID 742) in 12 ms on localhost (118/199)
2017-07-01 18:27:09,274  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 118.0 in stage 28.0 (TID 743). 1609 bytes result sent to driver
2017-07-01 18:27:09,274  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 119.0 in stage 28.0 (TID 744)
2017-07-01 18:27:09,274  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 120.0 in stage 28.0 (TID 745, localhost, partition 121,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,275  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 118.0 in stage 28.0 (TID 743) in 10 ms on localhost (119/199)
2017-07-01 18:27:09,277  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 120.0 in stage 28.0 (TID 745)
2017-07-01 18:27:09,288  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,289  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:27:09,292  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 120.0 in stage 28.0 (TID 745). 1609 bytes result sent to driver
2017-07-01 18:27:09,292  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 121.0 in stage 28.0 (TID 746, localhost, partition 122,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,293  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 120.0 in stage 28.0 (TID 745) in 19 ms on localhost (120/199)
2017-07-01 18:27:09,300  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 121.0 in stage 28.0 (TID 746)
2017-07-01 18:27:09,304  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,307  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:27:09,307  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,310  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:27:09,314  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 119.0 in stage 28.0 (TID 744). 1609 bytes result sent to driver
2017-07-01 18:27:09,314  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 121.0 in stage 28.0 (TID 746). 1609 bytes result sent to driver
2017-07-01 18:27:09,316  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 122.0 in stage 28.0 (TID 747, localhost, partition 123,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,316  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 123.0 in stage 28.0 (TID 748, localhost, partition 124,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,318  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 119.0 in stage 28.0 (TID 744) in 46 ms on localhost (121/199)
2017-07-01 18:27:09,319  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 121.0 in stage 28.0 (TID 746) in 27 ms on localhost (122/199)
2017-07-01 18:27:09,321  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 123.0 in stage 28.0 (TID 748)
2017-07-01 18:27:09,325  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 122.0 in stage 28.0 (TID 747)
2017-07-01 18:27:09,328  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,329  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:09,330  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 122.0 in stage 28.0 (TID 747). 1609 bytes result sent to driver
2017-07-01 18:27:09,329  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,330  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:09,331  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 123.0 in stage 28.0 (TID 748). 1609 bytes result sent to driver
2017-07-01 18:27:09,331  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 124.0 in stage 28.0 (TID 749, localhost, partition 125,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,332  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 124.0 in stage 28.0 (TID 749)
2017-07-01 18:27:09,332  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 122.0 in stage 28.0 (TID 747) in 16 ms on localhost (123/199)
2017-07-01 18:27:09,334  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 125.0 in stage 28.0 (TID 750, localhost, partition 126,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,337  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 125.0 in stage 28.0 (TID 750)
2017-07-01 18:27:09,339  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 123.0 in stage 28.0 (TID 748) in 23 ms on localhost (124/199)
2017-07-01 18:27:09,352  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,352  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:09,365  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 125.0 in stage 28.0 (TID 750). 1609 bytes result sent to driver
2017-07-01 18:27:09,365  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 125.0 in stage 28.0 (TID 750) in 31 ms on localhost (125/199)
2017-07-01 18:27:09,366  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 126.0 in stage 28.0 (TID 751, localhost, partition 127,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,366  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 126.0 in stage 28.0 (TID 751)
2017-07-01 18:27:09,372  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,372  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:09,374  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 126.0 in stage 28.0 (TID 751). 1609 bytes result sent to driver
2017-07-01 18:27:09,375  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 127.0 in stage 28.0 (TID 752, localhost, partition 128,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,375  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 126.0 in stage 28.0 (TID 751) in 9 ms on localhost (126/199)
2017-07-01 18:27:09,376  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 127.0 in stage 28.0 (TID 752)
2017-07-01 18:27:09,379  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,381  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:27:09,382  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 127.0 in stage 28.0 (TID 752). 1609 bytes result sent to driver
2017-07-01 18:27:09,383  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 128.0 in stage 28.0 (TID 753, localhost, partition 129,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,384  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 127.0 in stage 28.0 (TID 752) in 10 ms on localhost (127/199)
2017-07-01 18:27:09,385  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 128.0 in stage 28.0 (TID 753)
2017-07-01 18:27:09,388  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,388  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:09,389  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 128.0 in stage 28.0 (TID 753). 1609 bytes result sent to driver
2017-07-01 18:27:09,392  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 129.0 in stage 28.0 (TID 754, localhost, partition 130,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,393  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 129.0 in stage 28.0 (TID 754)
2017-07-01 18:27:09,390  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,397  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 128.0 in stage 28.0 (TID 753) in 14 ms on localhost (128/199)
2017-07-01 18:27:09,398  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 8 ms
2017-07-01 18:27:09,399  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 124.0 in stage 28.0 (TID 749). 1609 bytes result sent to driver
2017-07-01 18:27:09,401  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 130.0 in stage 28.0 (TID 755, localhost, partition 131,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,402  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 124.0 in stage 28.0 (TID 749) in 71 ms on localhost (129/199)
2017-07-01 18:27:09,403  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 130.0 in stage 28.0 (TID 755)
2017-07-01 18:27:09,406  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,407  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:09,408  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 130.0 in stage 28.0 (TID 755). 1609 bytes result sent to driver
2017-07-01 18:27:09,409  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 131.0 in stage 28.0 (TID 756, localhost, partition 132,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,410  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 130.0 in stage 28.0 (TID 755) in 9 ms on localhost (130/199)
2017-07-01 18:27:09,410  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 131.0 in stage 28.0 (TID 756)
2017-07-01 18:27:09,414  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,415  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:09,416  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 131.0 in stage 28.0 (TID 756). 1609 bytes result sent to driver
2017-07-01 18:27:09,415  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,417  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:27:09,417  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 129.0 in stage 28.0 (TID 754). 1609 bytes result sent to driver
2017-07-01 18:27:09,418  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 132.0 in stage 28.0 (TID 757, localhost, partition 133,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,418  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 132.0 in stage 28.0 (TID 757)
2017-07-01 18:27:09,418  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 131.0 in stage 28.0 (TID 756) in 9 ms on localhost (131/199)
2017-07-01 18:27:09,422  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,422  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:09,423  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 132.0 in stage 28.0 (TID 757). 1609 bytes result sent to driver
2017-07-01 18:27:09,423  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 133.0 in stage 28.0 (TID 758, localhost, partition 134,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,423  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 133.0 in stage 28.0 (TID 758)
2017-07-01 18:27:09,424  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 132.0 in stage 28.0 (TID 757) in 6 ms on localhost (132/199)
2017-07-01 18:27:09,425  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 134.0 in stage 28.0 (TID 759, localhost, partition 135,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,425  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 134.0 in stage 28.0 (TID 759)
2017-07-01 18:27:09,425  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 129.0 in stage 28.0 (TID 754) in 33 ms on localhost (133/199)
2017-07-01 18:27:09,429  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,429  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,429  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:09,429  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:09,430  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 133.0 in stage 28.0 (TID 758). 1609 bytes result sent to driver
2017-07-01 18:27:09,431  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 135.0 in stage 28.0 (TID 760, localhost, partition 136,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,431  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 133.0 in stage 28.0 (TID 758) in 8 ms on localhost (134/199)
2017-07-01 18:27:09,431  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 134.0 in stage 28.0 (TID 759). 1609 bytes result sent to driver
2017-07-01 18:27:09,432  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 136.0 in stage 28.0 (TID 761, localhost, partition 137,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,432  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 134.0 in stage 28.0 (TID 759) in 7 ms on localhost (135/199)
2017-07-01 18:27:09,431  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 135.0 in stage 28.0 (TID 760)
2017-07-01 18:27:09,432  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 136.0 in stage 28.0 (TID 761)
2017-07-01 18:27:09,457  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,457  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:09,460  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,461  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:09,462  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 135.0 in stage 28.0 (TID 760). 1609 bytes result sent to driver
2017-07-01 18:27:09,462  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 136.0 in stage 28.0 (TID 761). 1609 bytes result sent to driver
2017-07-01 18:27:09,462  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 137.0 in stage 28.0 (TID 762, localhost, partition 138,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,463  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 135.0 in stage 28.0 (TID 760) in 32 ms on localhost (136/199)
2017-07-01 18:27:09,463  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 137.0 in stage 28.0 (TID 762)
2017-07-01 18:27:09,466  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 138.0 in stage 28.0 (TID 763, localhost, partition 139,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,466  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 136.0 in stage 28.0 (TID 761) in 34 ms on localhost (137/199)
2017-07-01 18:27:09,467  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 138.0 in stage 28.0 (TID 763)
2017-07-01 18:27:09,470  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,471  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:09,472  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 137.0 in stage 28.0 (TID 762). 1609 bytes result sent to driver
2017-07-01 18:27:09,472  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 139.0 in stage 28.0 (TID 764, localhost, partition 140,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,472  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 137.0 in stage 28.0 (TID 762) in 10 ms on localhost (138/199)
2017-07-01 18:27:09,473  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 139.0 in stage 28.0 (TID 764)
2017-07-01 18:27:09,476  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,485  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 9 ms
2017-07-01 18:27:09,485  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,488  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:27:09,492  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 139.0 in stage 28.0 (TID 764). 1609 bytes result sent to driver
2017-07-01 18:27:09,493  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 140.0 in stage 28.0 (TID 765, localhost, partition 141,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,493  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 139.0 in stage 28.0 (TID 764) in 21 ms on localhost (139/199)
2017-07-01 18:27:09,494  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 140.0 in stage 28.0 (TID 765)
2017-07-01 18:27:09,492  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 138.0 in stage 28.0 (TID 763). 1609 bytes result sent to driver
2017-07-01 18:27:09,502  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 141.0 in stage 28.0 (TID 766, localhost, partition 142,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,502  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 138.0 in stage 28.0 (TID 763) in 36 ms on localhost (140/199)
2017-07-01 18:27:09,503  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 141.0 in stage 28.0 (TID 766)
2017-07-01 18:27:09,511  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,512  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,513  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:09,515  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 140.0 in stage 28.0 (TID 765). 1609 bytes result sent to driver
2017-07-01 18:27:09,516  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 142.0 in stage 28.0 (TID 767, localhost, partition 143,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,516  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 140.0 in stage 28.0 (TID 765) in 24 ms on localhost (141/199)
2017-07-01 18:27:09,528  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 142.0 in stage 28.0 (TID 767)
2017-07-01 18:27:09,551  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 40 ms
2017-07-01 18:27:09,552  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 141.0 in stage 28.0 (TID 766). 1609 bytes result sent to driver
2017-07-01 18:27:09,561  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 143.0 in stage 28.0 (TID 768, localhost, partition 144,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,561  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 141.0 in stage 28.0 (TID 766) in 60 ms on localhost (142/199)
2017-07-01 18:27:09,562  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 143.0 in stage 28.0 (TID 768)
2017-07-01 18:27:09,567  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,567  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:09,568  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 143.0 in stage 28.0 (TID 768). 1609 bytes result sent to driver
2017-07-01 18:27:09,554  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,568  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 14 ms
2017-07-01 18:27:09,569  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 142.0 in stage 28.0 (TID 767). 1609 bytes result sent to driver
2017-07-01 18:27:09,569  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 144.0 in stage 28.0 (TID 769, localhost, partition 145,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,570  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 144.0 in stage 28.0 (TID 769)
2017-07-01 18:27:09,570  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 142.0 in stage 28.0 (TID 767) in 54 ms on localhost (143/199)
2017-07-01 18:27:09,573  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,574  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 145.0 in stage 28.0 (TID 770, localhost, partition 146,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,575  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 143.0 in stage 28.0 (TID 768) in 14 ms on localhost (144/199)
2017-07-01 18:27:09,575  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 145.0 in stage 28.0 (TID 770)
2017-07-01 18:27:09,581  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 8 ms
2017-07-01 18:27:09,582  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 144.0 in stage 28.0 (TID 769). 1609 bytes result sent to driver
2017-07-01 18:27:09,582  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 146.0 in stage 28.0 (TID 771, localhost, partition 147,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,583  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 144.0 in stage 28.0 (TID 769) in 14 ms on localhost (145/199)
2017-07-01 18:27:09,583  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 146.0 in stage 28.0 (TID 771)
2017-07-01 18:27:09,586  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,587  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:09,587  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 146.0 in stage 28.0 (TID 771). 1609 bytes result sent to driver
2017-07-01 18:27:09,589  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 147.0 in stage 28.0 (TID 772, localhost, partition 148,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,589  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 147.0 in stage 28.0 (TID 772)
2017-07-01 18:27:09,588  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,591  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:27:09,593  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,604  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 11 ms
2017-07-01 18:27:09,594  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 146.0 in stage 28.0 (TID 771) in 12 ms on localhost (146/199)
2017-07-01 18:27:09,604  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 145.0 in stage 28.0 (TID 770). 1609 bytes result sent to driver
2017-07-01 18:27:09,609  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 148.0 in stage 28.0 (TID 773, localhost, partition 149,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,609  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 145.0 in stage 28.0 (TID 770) in 35 ms on localhost (147/199)
2017-07-01 18:27:09,614  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 148.0 in stage 28.0 (TID 773)
2017-07-01 18:27:09,623  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 147.0 in stage 28.0 (TID 772). 1609 bytes result sent to driver
2017-07-01 18:27:09,624  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 149.0 in stage 28.0 (TID 774, localhost, partition 150,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,624  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 147.0 in stage 28.0 (TID 772) in 35 ms on localhost (148/199)
2017-07-01 18:27:09,625  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 149.0 in stage 28.0 (TID 774)
2017-07-01 18:27:09,654  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,657  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:27:09,655  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,663  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 8 ms
2017-07-01 18:27:09,668  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 148.0 in stage 28.0 (TID 773). 1609 bytes result sent to driver
2017-07-01 18:27:09,674  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 150.0 in stage 28.0 (TID 775, localhost, partition 151,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,675  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 148.0 in stage 28.0 (TID 773) in 66 ms on localhost (149/199)
2017-07-01 18:27:09,678  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 150.0 in stage 28.0 (TID 775)
2017-07-01 18:27:09,690  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,692  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:27:09,691  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 149.0 in stage 28.0 (TID 774). 1609 bytes result sent to driver
2017-07-01 18:27:09,700  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 151.0 in stage 28.0 (TID 776, localhost, partition 152,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,701  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 149.0 in stage 28.0 (TID 774) in 77 ms on localhost (150/199)
2017-07-01 18:27:09,701  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 151.0 in stage 28.0 (TID 776)
2017-07-01 18:27:09,713  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,713  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:09,717  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 150.0 in stage 28.0 (TID 775). 1609 bytes result sent to driver
2017-07-01 18:27:09,722  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 152.0 in stage 28.0 (TID 777, localhost, partition 153,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,722  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 150.0 in stage 28.0 (TID 775) in 48 ms on localhost (151/199)
2017-07-01 18:27:09,725  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 152.0 in stage 28.0 (TID 777)
2017-07-01 18:27:09,747  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,749  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:27:09,751  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 152.0 in stage 28.0 (TID 777). 1609 bytes result sent to driver
2017-07-01 18:27:09,752  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 153.0 in stage 28.0 (TID 778, localhost, partition 154,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,754  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 153.0 in stage 28.0 (TID 778)
2017-07-01 18:27:09,756  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 152.0 in stage 28.0 (TID 777) in 35 ms on localhost (152/199)
2017-07-01 18:27:09,764  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 151.0 in stage 28.0 (TID 776). 1965 bytes result sent to driver
2017-07-01 18:27:09,769  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 154.0 in stage 28.0 (TID 779, localhost, partition 155,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,770  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 151.0 in stage 28.0 (TID 776) in 70 ms on localhost (153/199)
2017-07-01 18:27:09,771  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 154.0 in stage 28.0 (TID 779)
2017-07-01 18:27:09,777  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,779  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:27:09,781  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 154.0 in stage 28.0 (TID 779). 1609 bytes result sent to driver
2017-07-01 18:27:09,782  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 155.0 in stage 28.0 (TID 780, localhost, partition 156,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,783  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 154.0 in stage 28.0 (TID 779) in 14 ms on localhost (154/199)
2017-07-01 18:27:09,785  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 155.0 in stage 28.0 (TID 780)
2017-07-01 18:27:09,788  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,789  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:09,791  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 153.0 in stage 28.0 (TID 778). 1609 bytes result sent to driver
2017-07-01 18:27:09,795  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,796  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:09,796  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 156.0 in stage 28.0 (TID 781, localhost, partition 157,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,796  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 156.0 in stage 28.0 (TID 781)
2017-07-01 18:27:09,797  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 153.0 in stage 28.0 (TID 778) in 45 ms on localhost (155/199)
2017-07-01 18:27:09,812  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,813  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 155.0 in stage 28.0 (TID 780). 1609 bytes result sent to driver
2017-07-01 18:27:09,816  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:27:09,820  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 155.0 in stage 28.0 (TID 780) in 37 ms on localhost (156/199)
2017-07-01 18:27:09,826  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 157.0 in stage 28.0 (TID 782, localhost, partition 158,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,826  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 157.0 in stage 28.0 (TID 782)
2017-07-01 18:27:09,830  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,832  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:27:09,832  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 156.0 in stage 28.0 (TID 781). 1609 bytes result sent to driver
2017-07-01 18:27:09,836  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 158.0 in stage 28.0 (TID 783, localhost, partition 159,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,837  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 156.0 in stage 28.0 (TID 781) in 41 ms on localhost (157/199)
2017-07-01 18:27:09,838  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 158.0 in stage 28.0 (TID 783)
2017-07-01 18:27:09,838  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 157.0 in stage 28.0 (TID 782). 1609 bytes result sent to driver
2017-07-01 18:27:09,841  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 159.0 in stage 28.0 (TID 784, localhost, partition 160,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,842  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 157.0 in stage 28.0 (TID 782) in 16 ms on localhost (158/199)
2017-07-01 18:27:09,842  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 159.0 in stage 28.0 (TID 784)
2017-07-01 18:27:09,847  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,847  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:09,848  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 159.0 in stage 28.0 (TID 784). 1609 bytes result sent to driver
2017-07-01 18:27:09,849  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 160.0 in stage 28.0 (TID 785, localhost, partition 161,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,849  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 159.0 in stage 28.0 (TID 784) in 8 ms on localhost (159/199)
2017-07-01 18:27:09,850  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 160.0 in stage 28.0 (TID 785)
2017-07-01 18:27:09,854  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,857  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:27:09,856  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,859  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:27:09,859  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 160.0 in stage 28.0 (TID 785). 1609 bytes result sent to driver
2017-07-01 18:27:09,860  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 158.0 in stage 28.0 (TID 783). 1609 bytes result sent to driver
2017-07-01 18:27:09,865  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 160.0 in stage 28.0 (TID 785) in 16 ms on localhost (160/199)
2017-07-01 18:27:09,866  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 161.0 in stage 28.0 (TID 786, localhost, partition 162,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,866  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 162.0 in stage 28.0 (TID 787, localhost, partition 163,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,867  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 158.0 in stage 28.0 (TID 783) in 31 ms on localhost (161/199)
2017-07-01 18:27:09,868  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 162.0 in stage 28.0 (TID 787)
2017-07-01 18:27:09,873  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 161.0 in stage 28.0 (TID 786)
2017-07-01 18:27:09,873  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,876  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:27:09,878  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 162.0 in stage 28.0 (TID 787). 1609 bytes result sent to driver
2017-07-01 18:27:09,878  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 163.0 in stage 28.0 (TID 788, localhost, partition 164,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,879  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 163.0 in stage 28.0 (TID 788)
2017-07-01 18:27:09,885  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 162.0 in stage 28.0 (TID 787) in 13 ms on localhost (162/199)
2017-07-01 18:27:09,889  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,889  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:09,892  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 163.0 in stage 28.0 (TID 788). 1609 bytes result sent to driver
2017-07-01 18:27:09,893  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 164.0 in stage 28.0 (TID 789, localhost, partition 165,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,893  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 164.0 in stage 28.0 (TID 789)
2017-07-01 18:27:09,889  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,894  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 5 ms
2017-07-01 18:27:09,899  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 161.0 in stage 28.0 (TID 786). 1609 bytes result sent to driver
2017-07-01 18:27:09,900  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 163.0 in stage 28.0 (TID 788) in 17 ms on localhost (163/199)
2017-07-01 18:27:09,900  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 165.0 in stage 28.0 (TID 790, localhost, partition 166,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,901  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 161.0 in stage 28.0 (TID 786) in 35 ms on localhost (164/199)
2017-07-01 18:27:09,901  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 165.0 in stage 28.0 (TID 790)
2017-07-01 18:27:09,905  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,906  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:09,908  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 164.0 in stage 28.0 (TID 789). 1609 bytes result sent to driver
2017-07-01 18:27:09,910  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 166.0 in stage 28.0 (TID 791, localhost, partition 167,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,910  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 164.0 in stage 28.0 (TID 789) in 17 ms on localhost (165/199)
2017-07-01 18:27:09,910  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 166.0 in stage 28.0 (TID 791)
2017-07-01 18:27:09,917  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,925  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 8 ms
2017-07-01 18:27:09,918  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,926  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 8 ms
2017-07-01 18:27:09,927  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 166.0 in stage 28.0 (TID 791). 1609 bytes result sent to driver
2017-07-01 18:27:09,928  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 165.0 in stage 28.0 (TID 790). 1609 bytes result sent to driver
2017-07-01 18:27:09,928  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 167.0 in stage 28.0 (TID 792, localhost, partition 168,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,930  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 167.0 in stage 28.0 (TID 792)
2017-07-01 18:27:09,930  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 168.0 in stage 28.0 (TID 793, localhost, partition 169,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,931  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 165.0 in stage 28.0 (TID 790) in 31 ms on localhost (166/199)
2017-07-01 18:27:09,933  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 166.0 in stage 28.0 (TID 791) in 23 ms on localhost (167/199)
2017-07-01 18:27:09,934  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 168.0 in stage 28.0 (TID 793)
2017-07-01 18:27:09,941  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,941  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:09,943  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 168.0 in stage 28.0 (TID 793). 1609 bytes result sent to driver
2017-07-01 18:27:09,944  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 169.0 in stage 28.0 (TID 794, localhost, partition 170,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,944  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 169.0 in stage 28.0 (TID 794)
2017-07-01 18:27:09,945  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 168.0 in stage 28.0 (TID 793) in 15 ms on localhost (168/199)
2017-07-01 18:27:09,947  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,947  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:09,948  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 167.0 in stage 28.0 (TID 792). 1609 bytes result sent to driver
2017-07-01 18:27:09,948  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 170.0 in stage 28.0 (TID 795, localhost, partition 171,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,949  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 170.0 in stage 28.0 (TID 795)
2017-07-01 18:27:09,949  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 167.0 in stage 28.0 (TID 792) in 21 ms on localhost (169/199)
2017-07-01 18:27:09,952  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,953  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:09,955  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 169.0 in stage 28.0 (TID 794). 1609 bytes result sent to driver
2017-07-01 18:27:09,956  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 171.0 in stage 28.0 (TID 796, localhost, partition 172,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,957  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 169.0 in stage 28.0 (TID 794) in 13 ms on localhost (170/199)
2017-07-01 18:27:09,960  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 171.0 in stage 28.0 (TID 796)
2017-07-01 18:27:09,964  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,965  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:09,969  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 171.0 in stage 28.0 (TID 796). 1609 bytes result sent to driver
2017-07-01 18:27:09,969  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 172.0 in stage 28.0 (TID 797, localhost, partition 173,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,970  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 171.0 in stage 28.0 (TID 796) in 14 ms on localhost (171/199)
2017-07-01 18:27:09,970  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 172.0 in stage 28.0 (TID 797)
2017-07-01 18:27:09,975  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,976  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:09,978  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 172.0 in stage 28.0 (TID 797). 1609 bytes result sent to driver
2017-07-01 18:27:09,979  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 173.0 in stage 28.0 (TID 798, localhost, partition 174,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,980  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 172.0 in stage 28.0 (TID 797) in 11 ms on localhost (172/199)
2017-07-01 18:27:09,982  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 173.0 in stage 28.0 (TID 798)
2017-07-01 18:27:09,987  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,988  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:09,988  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:09,991  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:27:09,995  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 170.0 in stage 28.0 (TID 795). 1609 bytes result sent to driver
2017-07-01 18:27:09,996  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 173.0 in stage 28.0 (TID 798). 1609 bytes result sent to driver
2017-07-01 18:27:09,997  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 174.0 in stage 28.0 (TID 799, localhost, partition 175,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,997  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 175.0 in stage 28.0 (TID 800, localhost, partition 176,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:09,998  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 170.0 in stage 28.0 (TID 795) in 50 ms on localhost (173/199)
2017-07-01 18:27:09,999  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 174.0 in stage 28.0 (TID 799)
2017-07-01 18:27:09,999  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 173.0 in stage 28.0 (TID 798) in 20 ms on localhost (174/199)
2017-07-01 18:27:10,000  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 175.0 in stage 28.0 (TID 800)
2017-07-01 18:27:10,004  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:10,007  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:27:10,008  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 174.0 in stage 28.0 (TID 799). 1609 bytes result sent to driver
2017-07-01 18:27:10,008  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 176.0 in stage 28.0 (TID 801, localhost, partition 177,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:10,009  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 174.0 in stage 28.0 (TID 799) in 12 ms on localhost (175/199)
2017-07-01 18:27:10,011  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:10,011  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:10,012  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 175.0 in stage 28.0 (TID 800). 1609 bytes result sent to driver
2017-07-01 18:27:10,013  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 177.0 in stage 28.0 (TID 802, localhost, partition 178,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:10,013  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 175.0 in stage 28.0 (TID 800) in 16 ms on localhost (176/199)
2017-07-01 18:27:10,013  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 177.0 in stage 28.0 (TID 802)
2017-07-01 18:27:10,013  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 176.0 in stage 28.0 (TID 801)
2017-07-01 18:27:10,018  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:10,020  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 2 ms
2017-07-01 18:27:10,021  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 177.0 in stage 28.0 (TID 802). 1609 bytes result sent to driver
2017-07-01 18:27:10,020  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:10,021  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:10,022  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 176.0 in stage 28.0 (TID 801). 1609 bytes result sent to driver
2017-07-01 18:27:10,022  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 178.0 in stage 28.0 (TID 803, localhost, partition 179,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:10,023  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 178.0 in stage 28.0 (TID 803)
2017-07-01 18:27:10,023  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 177.0 in stage 28.0 (TID 802) in 11 ms on localhost (177/199)
2017-07-01 18:27:10,024  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 179.0 in stage 28.0 (TID 804, localhost, partition 180,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:10,024  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 179.0 in stage 28.0 (TID 804)
2017-07-01 18:27:10,025  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 176.0 in stage 28.0 (TID 801) in 17 ms on localhost (178/199)
2017-07-01 18:27:10,028  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:10,028  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:10,028  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:10,028  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:10,029  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 179.0 in stage 28.0 (TID 804). 1609 bytes result sent to driver
2017-07-01 18:27:10,030  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 180.0 in stage 28.0 (TID 805, localhost, partition 181,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:10,030  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 179.0 in stage 28.0 (TID 804) in 6 ms on localhost (179/199)
2017-07-01 18:27:10,029  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 178.0 in stage 28.0 (TID 803). 1609 bytes result sent to driver
2017-07-01 18:27:10,031  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 180.0 in stage 28.0 (TID 805)
2017-07-01 18:27:10,032  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 181.0 in stage 28.0 (TID 806, localhost, partition 182,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:10,032  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 181.0 in stage 28.0 (TID 806)
2017-07-01 18:27:10,033  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 178.0 in stage 28.0 (TID 803) in 11 ms on localhost (180/199)
2017-07-01 18:27:10,035  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:10,036  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:10,037  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 180.0 in stage 28.0 (TID 805). 1609 bytes result sent to driver
2017-07-01 18:27:10,037  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 182.0 in stage 28.0 (TID 807, localhost, partition 183,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:10,038  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 180.0 in stage 28.0 (TID 805) in 8 ms on localhost (181/199)
2017-07-01 18:27:10,040  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 182.0 in stage 28.0 (TID 807)
2017-07-01 18:27:10,044  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:10,045  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:10,046  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 182.0 in stage 28.0 (TID 807). 1609 bytes result sent to driver
2017-07-01 18:27:10,046  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 183.0 in stage 28.0 (TID 808, localhost, partition 184,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:10,047  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 182.0 in stage 28.0 (TID 807) in 10 ms on localhost (182/199)
2017-07-01 18:27:10,047  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:10,047  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:10,047  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 183.0 in stage 28.0 (TID 808)
2017-07-01 18:27:10,055  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 181.0 in stage 28.0 (TID 806). 1609 bytes result sent to driver
2017-07-01 18:27:10,058  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 184.0 in stage 28.0 (TID 809, localhost, partition 185,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:10,058  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 181.0 in stage 28.0 (TID 806) in 26 ms on localhost (183/199)
2017-07-01 18:27:10,061  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 184.0 in stage 28.0 (TID 809)
2017-07-01 18:27:10,069  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:10,069  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:10,072  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 184.0 in stage 28.0 (TID 809). 1609 bytes result sent to driver
2017-07-01 18:27:10,073  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 185.0 in stage 28.0 (TID 810, localhost, partition 186,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:10,073  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 185.0 in stage 28.0 (TID 810)
2017-07-01 18:27:10,073  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 184.0 in stage 28.0 (TID 809) in 16 ms on localhost (184/199)
2017-07-01 18:27:10,132  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:10,132  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:10,137  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:10,138  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_46_piece0 on localhost:56220 in memory (size: 7.0 KB, free: 116.4 MB)
2017-07-01 18:27:10,138  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 183.0 in stage 28.0 (TID 808). 1609 bytes result sent to driver
2017-07-01 18:27:10,142  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 69
2017-07-01 18:27:10,142  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 186.0 in stage 28.0 (TID 811, localhost, partition 187,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:10,143  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 6 ms
2017-07-01 18:27:10,143  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 183.0 in stage 28.0 (TID 808) in 97 ms on localhost (185/199)
2017-07-01 18:27:10,143  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 186.0 in stage 28.0 (TID 811)
2017-07-01 18:27:10,144  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 185.0 in stage 28.0 (TID 810). 1609 bytes result sent to driver
2017-07-01 18:27:10,144  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 187.0 in stage 28.0 (TID 812, localhost, partition 188,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:10,145  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 185.0 in stage 28.0 (TID 810) in 71 ms on localhost (186/199)
2017-07-01 18:27:10,145  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 187.0 in stage 28.0 (TID 812)
2017-07-01 18:27:10,147  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:10,147  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:10,148  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 186.0 in stage 28.0 (TID 811). 1609 bytes result sent to driver
2017-07-01 18:27:10,149  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:10,150  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:10,151  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 187.0 in stage 28.0 (TID 812). 1609 bytes result sent to driver
2017-07-01 18:27:10,151  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 188.0 in stage 28.0 (TID 813, localhost, partition 189,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:10,152  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 186.0 in stage 28.0 (TID 811) in 11 ms on localhost (187/199)
2017-07-01 18:27:10,152  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 188.0 in stage 28.0 (TID 813)
2017-07-01 18:27:10,153  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 189.0 in stage 28.0 (TID 814, localhost, partition 190,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:10,154  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 187.0 in stage 28.0 (TID 812) in 10 ms on localhost (188/199)
2017-07-01 18:27:10,156  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 189.0 in stage 28.0 (TID 814)
2017-07-01 18:27:10,156  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_45_piece0 on localhost:56220 in memory (size: 5.7 KB, free: 116.4 MB)
2017-07-01 18:27:10,156  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 68
2017-07-01 18:27:10,160  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:10,160  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:10,162  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:10,163  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:10,164  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 189.0 in stage 28.0 (TID 814). 1609 bytes result sent to driver
2017-07-01 18:27:10,163  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 188.0 in stage 28.0 (TID 813). 1609 bytes result sent to driver
2017-07-01 18:27:10,165  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 190.0 in stage 28.0 (TID 815, localhost, partition 191,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:10,165  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 190.0 in stage 28.0 (TID 815)
2017-07-01 18:27:10,166  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 189.0 in stage 28.0 (TID 814) in 12 ms on localhost (189/199)
2017-07-01 18:27:10,168  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:10,168  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:10,176  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 190.0 in stage 28.0 (TID 815). 1609 bytes result sent to driver
2017-07-01 18:27:10,177  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 191.0 in stage 28.0 (TID 816, localhost, partition 192,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:10,180  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 188.0 in stage 28.0 (TID 813) in 29 ms on localhost (190/199)
2017-07-01 18:27:10,181  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 191.0 in stage 28.0 (TID 816)
2017-07-01 18:27:10,183  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 192.0 in stage 28.0 (TID 817, localhost, partition 193,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:10,183  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 192.0 in stage 28.0 (TID 817)
2017-07-01 18:27:10,184  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 190.0 in stage 28.0 (TID 815) in 18 ms on localhost (191/199)
2017-07-01 18:27:10,188  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:10,192  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 4 ms
2017-07-01 18:27:10,196  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 192.0 in stage 28.0 (TID 817). 1609 bytes result sent to driver
2017-07-01 18:27:10,198  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 193.0 in stage 28.0 (TID 818, localhost, partition 194,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:10,198  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 192.0 in stage 28.0 (TID 817) in 16 ms on localhost (192/199)
2017-07-01 18:27:10,199  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 193.0 in stage 28.0 (TID 818)
2017-07-01 18:27:10,189  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:10,207  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 18 ms
2017-07-01 18:27:10,209  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:10,211  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 6 ms
2017-07-01 18:27:10,214  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 191.0 in stage 28.0 (TID 816). 1609 bytes result sent to driver
2017-07-01 18:27:10,217  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 194.0 in stage 28.0 (TID 819, localhost, partition 195,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:10,219  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Running task 194.0 in stage 28.0 (TID 819)
2017-07-01 18:27:10,223  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 191.0 in stage 28.0 (TID 816) in 46 ms on localhost (193/199)
2017-07-01 18:27:10,225  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 193.0 in stage 28.0 (TID 818). 1609 bytes result sent to driver
2017-07-01 18:27:10,228  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 195.0 in stage 28.0 (TID 820, localhost, partition 196,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:10,228  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 193.0 in stage 28.0 (TID 818) in 31 ms on localhost (194/199)
2017-07-01 18:27:10,230  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Running task 195.0 in stage 28.0 (TID 820)
2017-07-01 18:27:10,232  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:10,235  INFO [Executor task launch worker-8] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 3 ms
2017-07-01 18:27:10,241  INFO [Executor task launch worker-8] (org.apache.spark.executor.Executor) - Finished task 194.0 in stage 28.0 (TID 819). 1609 bytes result sent to driver
2017-07-01 18:27:10,243  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 196.0 in stage 28.0 (TID 821, localhost, partition 197,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:10,243  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 194.0 in stage 28.0 (TID 819) in 26 ms on localhost (195/199)
2017-07-01 18:27:10,244  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Running task 196.0 in stage 28.0 (TID 821)
2017-07-01 18:27:10,250  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:10,251  INFO [Executor task launch worker-6] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:10,252  INFO [Executor task launch worker-6] (org.apache.spark.executor.Executor) - Finished task 196.0 in stage 28.0 (TID 821). 1609 bytes result sent to driver
2017-07-01 18:27:10,252  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 197.0 in stage 28.0 (TID 822, localhost, partition 198,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:10,253  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 196.0 in stage 28.0 (TID 821) in 11 ms on localhost (196/199)
2017-07-01 18:27:10,253  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Running task 197.0 in stage 28.0 (TID 822)
2017-07-01 18:27:10,256  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:10,256  INFO [Executor task launch worker-4] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:10,257  INFO [Executor task launch worker-4] (org.apache.spark.executor.Executor) - Finished task 197.0 in stage 28.0 (TID 822). 1609 bytes result sent to driver
2017-07-01 18:27:10,258  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 198.0 in stage 28.0 (TID 823, localhost, partition 199,NODE_LOCAL, 2044 bytes)
2017-07-01 18:27:10,258  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 197.0 in stage 28.0 (TID 822) in 6 ms on localhost (197/199)
2017-07-01 18:27:10,259  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 198.0 in stage 28.0 (TID 823)
2017-07-01 18:27:10,260  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:10,260  INFO [Executor task launch worker-5] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2017-07-01 18:27:10,260  INFO [Executor task launch worker-5] (org.apache.spark.executor.Executor) - Finished task 195.0 in stage 28.0 (TID 820). 1609 bytes result sent to driver
2017-07-01 18:27:10,261  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 195.0 in stage 28.0 (TID 820) in 33 ms on localhost (198/199)
2017-07-01 18:27:10,262  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 1 non-empty blocks out of 2 blocks
2017-07-01 18:27:10,262  INFO [Executor task launch worker-10] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2017-07-01 18:27:10,263  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 198.0 in stage 28.0 (TID 823). 1609 bytes result sent to driver
2017-07-01 18:27:10,264  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 198.0 in stage 28.0 (TID 823) in 6 ms on localhost (199/199)
2017-07-01 18:27:10,264  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 28 (show at <console>:65) finished in 2,596 s
2017-07-01 18:27:10,264  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.scheduler.DAGScheduler) - Job 20 finished: show at <console>:65, took 2,690045 s
2017-07-01 18:27:10,264  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 28.0, whose tasks have all completed, from pool 
2017-07-01 18:27:12,874  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_47_piece0 on localhost:56220 in memory (size: 7.0 KB, free: 116.4 MB)
2017-07-01 18:27:12,876  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 70
2017-07-01 18:27:12,879  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned shuffle 3
2017-07-01 18:27:12,879  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 67
2017-07-01 18:27:12,879  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 66
2017-07-01 18:27:12,879  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 65
2017-07-01 18:27:12,879  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 64
2017-07-01 18:27:12,882  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 63
2017-07-01 18:27:12,882  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 62
2017-07-01 18:27:12,882  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 61
2017-07-01 18:27:12,882  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 60
2017-07-01 18:27:12,883  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_44_piece0 on localhost:56220 in memory (size: 19.6 KB, free: 116.4 MB)
2017-07-01 18:27:13,436  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.storage.MemoryStore) - Block broadcast_48 stored as values in memory (estimated size 187.4 KB, free 187.4 KB)
2017-07-01 18:27:13,459  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.storage.MemoryStore) - Block broadcast_48_piece0 stored as bytes in memory (estimated size 19.5 KB, free 206.9 KB)
2017-07-01 18:27:13,460  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_48_piece0 in memory on localhost:56220 (size: 19.5 KB, free: 116.4 MB)
2017-07-01 18:27:13,464  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.SparkContext) - Created broadcast 48 from show at <console>:64
2017-07-01 18:27:13,471  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.storage.MemoryStore) - Block broadcast_49 stored as values in memory (estimated size 188.0 KB, free 394.9 KB)
2017-07-01 18:27:13,496  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.storage.MemoryStore) - Block broadcast_49_piece0 stored as bytes in memory (estimated size 19.6 KB, free 414.5 KB)
2017-07-01 18:27:13,497  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_49_piece0 in memory on localhost:56220 (size: 19.6 KB, free: 116.4 MB)
2017-07-01 18:27:13,500  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.SparkContext) - Created broadcast 49 from show at <console>:64
2017-07-01 18:27:13,532  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.hadoop.mapred.FileInputFormat) - Total input paths to process : 1
2017-07-01 18:27:13,537  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.SparkContext) - Starting job: show at <console>:64
2017-07-01 18:27:13,539  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 21 (show at <console>:64) with 1 output partitions
2017-07-01 18:27:13,539  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 29 (show at <console>:64)
2017-07-01 18:27:13,539  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2017-07-01 18:27:13,539  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2017-07-01 18:27:13,539  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 29 (MapPartitionsRDD[100] at show at <console>:64), which has no missing parents
2017-07-01 18:27:13,540  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_50 stored as values in memory (estimated size 8.4 KB, free 422.9 KB)
2017-07-01 18:27:13,547  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_50_piece0 stored as bytes in memory (estimated size 4.4 KB, free 427.4 KB)
2017-07-01 18:27:13,548  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_50_piece0 in memory on localhost:56220 (size: 4.4 KB, free: 116.4 MB)
2017-07-01 18:27:13,552  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 50 from broadcast at DAGScheduler.scala:1006
2017-07-01 18:27:13,554  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[100] at show at <console>:64)
2017-07-01 18:27:13,555  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 29.0 with 1 tasks
2017-07-01 18:27:13,557  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 29.0 (TID 824, localhost, partition 0,PROCESS_LOCAL, 2198 bytes)
2017-07-01 18:27:13,557  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 29.0 (TID 824)
2017-07-01 18:27:13,566  INFO [Executor task launch worker-10] (org.apache.spark.rdd.HadoopRDD) - Input split: file:/home/turmasabado/spark-notebook/produtos.json:0+500
2017-07-01 18:27:13,576  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 29.0 (TID 824). 3221 bytes result sent to driver
2017-07-01 18:27:13,578  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 29.0 (TID 824) in 21 ms on localhost (1/1)
2017-07-01 18:27:13,578  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 29.0, whose tasks have all completed, from pool 
2017-07-01 18:27:13,578  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 29 (show at <console>:64) finished in 0,020 s
2017-07-01 18:27:13,579  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.scheduler.DAGScheduler) - Job 21 finished: show at <console>:64, took 0,041915 s
2017-07-01 18:27:13,585  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.SparkContext) - Starting job: show at <console>:64
2017-07-01 18:27:13,587  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 22 (show at <console>:64) with 1 output partitions
2017-07-01 18:27:13,587  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 30 (show at <console>:64)
2017-07-01 18:27:13,587  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2017-07-01 18:27:13,589  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2017-07-01 18:27:13,589  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 30 (MapPartitionsRDD[100] at show at <console>:64), which has no missing parents
2017-07-01 18:27:13,592  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_51 stored as values in memory (estimated size 8.4 KB, free 435.8 KB)
2017-07-01 18:27:13,596  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_51_piece0 stored as bytes in memory (estimated size 4.4 KB, free 440.2 KB)
2017-07-01 18:27:13,598  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_51_piece0 in memory on localhost:56220 (size: 4.4 KB, free: 116.4 MB)
2017-07-01 18:27:13,599  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 51 from broadcast at DAGScheduler.scala:1006
2017-07-01 18:27:13,600  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[100] at show at <console>:64)
2017-07-01 18:27:13,600  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 30.0 with 1 tasks
2017-07-01 18:27:13,601  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 30.0 (TID 825, localhost, partition 1,PROCESS_LOCAL, 2198 bytes)
2017-07-01 18:27:13,602  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 30.0 (TID 825)
2017-07-01 18:27:13,607  INFO [Executor task launch worker-10] (org.apache.spark.rdd.HadoopRDD) - Input split: file:/home/turmasabado/spark-notebook/produtos.json:500+501
2017-07-01 18:27:13,614  INFO [Executor task launch worker-10] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 30.0 (TID 825). 2283 bytes result sent to driver
2017-07-01 18:27:13,615  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 30.0 (TID 825) in 14 ms on localhost (1/1)
2017-07-01 18:27:13,617  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 30.0, whose tasks have all completed, from pool 
2017-07-01 18:27:13,616  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 30 (show at <console>:64) finished in 0,015 s
2017-07-01 18:27:13,618  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.scheduler.DAGScheduler) - Job 22 finished: show at <console>:64, took 0,031324 s
2017-07-01 18:27:14,818  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_51_piece0 on localhost:56220 in memory (size: 4.4 KB, free: 116.4 MB)
2017-07-01 18:27:14,823  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 74
2017-07-01 18:27:14,824  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_50_piece0 on localhost:56220 in memory (size: 4.4 KB, free: 116.4 MB)
2017-07-01 18:27:14,825  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 73
2017-07-01 18:27:14,825  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 72
2017-07-01 18:27:14,825  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 71
2017-07-01 18:27:14,826  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_49_piece0 on localhost:56220 in memory (size: 19.6 KB, free: 116.4 MB)
2017-07-01 18:27:14,829  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_48_piece0 on localhost:56220 in memory (size: 19.5 KB, free: 116.4 MB)
2017-07-01 18:28:06,999  INFO [Thread-1] (org.apache.spark.SparkContext) - Invoking stop() from shutdown hook
2017-07-01 18:28:07,297  INFO [Thread-1] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/static/sql,null}
2017-07-01 18:28:07,298  INFO [Thread-1] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/SQL1/execution/json,null}
2017-07-01 18:28:07,298  INFO [Thread-1] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/SQL1/execution,null}
2017-07-01 18:28:07,299  INFO [Thread-1] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/SQL1/json,null}
2017-07-01 18:28:07,299  INFO [Thread-1] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/SQL1,null}
2017-07-01 18:28:07,300  INFO [Thread-1] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/static/sql,null}
2017-07-01 18:28:07,302  INFO [Thread-1] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/SQL/execution/json,null}
2017-07-01 18:28:07,302  INFO [Thread-1] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/SQL/execution,null}
2017-07-01 18:28:07,303  INFO [Thread-1] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/SQL/json,null}
2017-07-01 18:28:07,304  INFO [Thread-1] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/SQL,null}
2017-07-01 18:28:07,304  INFO [Thread-1] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2017-07-01 18:28:07,320  INFO [Thread-1] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2017-07-01 18:28:07,322  INFO [Thread-1] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/api,null}
2017-07-01 18:28:07,324  INFO [Thread-1] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/,null}
2017-07-01 18:28:07,329  INFO [Thread-1] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/static,null}
2017-07-01 18:28:07,334  INFO [Thread-1] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2017-07-01 18:28:07,337  INFO [Thread-1] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2017-07-01 18:28:07,339  INFO [Thread-1] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2017-07-01 18:28:07,342  INFO [Thread-1] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/executors,null}
2017-07-01 18:28:07,347  INFO [Thread-1] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2017-07-01 18:28:07,348  INFO [Thread-1] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/environment,null}
2017-07-01 18:28:07,349  INFO [Thread-1] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2017-07-01 18:28:07,352  INFO [Thread-1] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2017-07-01 18:28:07,354  INFO [Thread-1] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2017-07-01 18:28:07,357  INFO [Thread-1] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/storage,null}
2017-07-01 18:28:07,358  INFO [Thread-1] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2017-07-01 18:28:07,360  INFO [Thread-1] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2017-07-01 18:28:07,362  INFO [Thread-1] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2017-07-01 18:28:07,363  INFO [Thread-1] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2017-07-01 18:28:07,365  INFO [Thread-1] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2017-07-01 18:28:07,368  INFO [Thread-1] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages,null}
2017-07-01 18:28:07,369  INFO [Thread-1] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2017-07-01 18:28:07,369  INFO [Thread-1] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2017-07-01 18:28:07,370  INFO [Thread-1] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2017-07-01 18:28:07,370  INFO [Thread-1] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2017-07-01 18:28:07,509  INFO [Thread-1] (org.apache.spark.ui.SparkUI) - Stopped Spark web UI at http://192.168.1.114:4042
2017-07-01 18:28:08,739  INFO [dispatcher-event-loop-1] (org.apache.spark.MapOutputTrackerMasterEndpoint) - MapOutputTrackerMasterEndpoint stopped!
2017-07-01 18:28:09,187  INFO [Thread-1] (org.apache.spark.storage.MemoryStore) - MemoryStore cleared
2017-07-01 18:28:09,240  INFO [Thread-1] (org.apache.spark.storage.BlockManager) - BlockManager stopped
2017-07-01 18:28:09,244  INFO [Thread-1] (org.apache.spark.storage.BlockManagerMaster) - BlockManagerMaster stopped
2017-07-01 18:28:09,255  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint) - OutputCommitCoordinator stopped!
2017-07-01 18:28:09,340  INFO [Thread-1] (org.apache.spark.SparkContext) - Successfully stopped SparkContext
2017-07-01 18:28:09,367  INFO [Thread-1] (org.apache.spark.util.ShutdownHookManager) - Shutdown hook called
2017-07-01 18:28:09,392  INFO [Thread-1] (org.apache.spark.util.ShutdownHookManager) - Deleting directory /tmp/spark-notebook-repl-9ca338a3-1a45-4f96-acaf-85047e764238
2017-07-01 18:28:09,469  INFO [sparkDriverActorSystem-akka.actor.default-dispatcher-17] (akka.remote.RemoteActorRefProvider$RemotingTerminator) - Shutting down remote daemon.
2017-07-01 18:28:09,515  INFO [sparkDriverActorSystem-akka.actor.default-dispatcher-4] (akka.remote.RemoteActorRefProvider$RemotingTerminator) - Remote daemon shut down; proceeding with flushing remote transports.
2017-07-01 18:28:10,155  WARN [main] (notebook.kernel.pfork.BetterFork$) - Parent process stopped; exiting.
2017-07-01 18:28:11,214  WARN [Remote-akka.actor.default-dispatcher-16] (akka.remote.ReliableDeliverySupervisor) - Association with remote system [akka.tcp://NotebookServer@127.0.0.1:44074] has failed, address is now gated for [5000] ms. Reason: [Disassociated] 
2017-07-01 18:28:11,216  INFO [sparkDriverActorSystem-akka.actor.default-dispatcher-4] (akka.remote.RemoteActorRefProvider$RemotingTerminator) - Remoting shut down.
2017-07-01 18:28:11,405  INFO [Thread-1] (org.apache.spark.util.ShutdownHookManager) - Deleting directory /tmp/spark-f6c047ca-ab83-47c8-b3ad-d994b0d5c50e
2017-07-01 18:28:11,483  INFO [Remote-akka.actor.default-dispatcher-16] (akka.actor.LocalActorRef) - Message [akka.remote.EndpointWriter$AckIdleCheckTimer$] from Actor[akka://Remote/system/endpointManager/reliableEndpointWriter-akka.tcp%3A%2F%2FNotebookServer%40127.0.0.1%3A44074-0/endpointWriter#2050423643] to Actor[akka://Remote/system/endpointManager/reliableEndpointWriter-akka.tcp%3A%2F%2FNotebookServer%40127.0.0.1%3A44074-0/endpointWriter#2050423643] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2017-07-01 18:28:11,483  INFO [Remote-akka.actor.default-dispatcher-16] (akka.actor.LocalActorRef) - Message [akka.remote.EndpointWriter$AckIdleCheckTimer$] from Actor[akka://Remote/system/endpointManager/reliableEndpointWriter-akka.tcp%3A%2F%2FNotebookServer%40127.0.0.1%3A44074-0/endpointWriter#2050423643] to Actor[akka://Remote/system/endpointManager/reliableEndpointWriter-akka.tcp%3A%2F%2FNotebookServer%40127.0.0.1%3A44074-0/endpointWriter#2050423643] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2017-07-01 18:28:11,506  INFO [Remote-akka.actor.default-dispatcher-3] (akka.remote.RemoteActorRefProvider$RemoteDeadLetterActorRef) - Message [notebook.ObservableVMToBrowser] from Actor[akka://Remote/remote/akka.tcp/NotebookServer@127.0.0.1:44074/user/$l/$a#-88797134] to Actor[akka://Remote/deadLetters] was not delivered. [3] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2017-07-01 18:28:11,527  INFO [Thread-1] (org.apache.spark.util.ShutdownHookManager) - Deleting directory /tmp/spark-f6c047ca-ab83-47c8-b3ad-d994b0d5c50e/httpd-4700cb92-1b0c-4820-8297-f509d557a827
2017-07-01 18:28:11,579  INFO [Remote-akka.actor.default-dispatcher-3] (akka.remote.RemoteActorRefProvider$RemoteDeadLetterActorRef) - Message [org.apache.log4j.spi.LoggingEvent] from Actor[akka://Remote/user/remote-logger#1485619253] to Actor[akka://Remote/deadLetters] was not delivered. [4] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2017-07-01 18:28:11,580  INFO [Remote-akka.actor.default-dispatcher-3] (akka.remote.RemoteActorRefProvider$RemoteDeadLetterActorRef) - Message [org.apache.log4j.spi.LoggingEvent] from Actor[akka://Remote/user/remote-logger#1485619253] to Actor[akka://Remote/deadLetters] was not delivered. [5] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2017-07-01 18:28:11,580  INFO [Remote-akka.actor.default-dispatcher-3] (akka.remote.RemoteActorRefProvider$RemoteDeadLetterActorRef) - Message [org.apache.log4j.spi.LoggingEvent] from Actor[akka://Remote/user/remote-logger#1485619253] to Actor[akka://Remote/deadLetters] was not delivered. [6] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2017-07-01 18:28:11,580  INFO [Remote-akka.actor.default-dispatcher-16] (akka.remote.RemoteActorRefProvider$RemoteDeadLetterActorRef) - Message [akka.remote.RemoteWatcher$Heartbeat$] from Actor[akka://Remote/system/remote-watcher#1409424279] to Actor[akka://Remote/deadLetters] was not delivered. [7] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2017-07-01 18:28:11,581  INFO [Remote-akka.actor.default-dispatcher-16] (akka.remote.RemoteActorRefProvider$RemoteDeadLetterActorRef) - Message [org.apache.log4j.spi.LoggingEvent] from Actor[akka://Remote/user/remote-logger#1485619253] to Actor[akka://Remote/deadLetters] was not delivered. [8] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2017-07-01 18:28:11,581  INFO [Remote-akka.actor.default-dispatcher-16] (akka.remote.RemoteActorRefProvider$RemoteDeadLetterActorRef) - Message [org.apache.log4j.spi.LoggingEvent] from Actor[akka://Remote/user/remote-logger#1485619253] to Actor[akka://Remote/deadLetters] was not delivered. [9] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2017-07-01 18:28:11,582  INFO [Remote-akka.actor.default-dispatcher-6] (akka.remote.RemoteActorRefProvider$RemoteDeadLetterActorRef) - Message [org.apache.log4j.spi.LoggingEvent] from Actor[akka://Remote/user/remote-logger#1485619253] to Actor[akka://Remote/deadLetters] was not delivered. [10] dead letters encountered, no more dead letters will be logged. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
